{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "31a927b3-981e-4a76-baf5-bec4fd20c7e7",
   "metadata": {},
   "source": [
    "# å‘é‡åµŒå…¥å’Œæ£€ç´¢"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29347e45-9d3e-473f-ade6-35413199191e",
   "metadata": {},
   "source": [
    "## BM25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bd7733fc-e8c6-4690-9180-b5888bf7f3a5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ”¥ BM25 ç¨€ç–åµŒå…¥ä¸æ£€ç´¢æ¼”ç¤º\n",
      "================================================================================\n",
      "\n",
      "ã€æ­¥éª¤ 1ã€‘è®­ç»ƒ BM25 æ¨¡å‹\n",
      "--------------------------------------------------------------------------------\n",
      "âœ“ BM25 æ¨¡å‹è®­ç»ƒå®Œæˆ\n",
      "  - æ–‡æ¡£æ•°é‡: 5\n",
      "  - è¯è¡¨å¤§å°: 35\n",
      "  - å¹³å‡æ–‡æ¡£é•¿åº¦: 9.40\n",
      "  - å‚æ•°: k1=1.5, b=0.75\n",
      "\n",
      "================================================================================\n",
      "BM25 ç¨€ç–åµŒå…¥è¯¦æƒ…\n",
      "================================================================================\n",
      "\n",
      "ğŸ“„ æ–‡æ¡£ 1:\n",
      "   å†…å®¹: çŒ¢ç‹²ï¼Œæ–½å±•ï¼Œçƒˆç„°æ‹³ï¼Œå‡»é€€ï¼Œå¦–æ€ªï¼›éšåå¼€å¯ï¼Œé‡‘åˆšä½“ï¼ŒæŠµæŒ¡ï¼Œç¥å…µï¼Œæ”»å‡»ã€‚\n",
      "   åµŒå…¥ç»´åº¦: 35 (ç¨€ç–åº¦: 9/35)\n",
      "   éé›¶å…ƒç´ : 9\n",
      "   Top-5 å…³é”®è¯:\n",
      "     - æ–½å±•: 1.4134\n",
      "     - å‡»é€€: 1.4134\n",
      "     - å¦–æ€ªï¼›éšåå¼€å¯: 1.4134\n",
      "     - æŠµæŒ¡: 1.4134\n",
      "     - ç¥å…µ: 1.4134\n",
      "\n",
      "ğŸ“„ æ–‡æ¡£ 2:\n",
      "   å†…å®¹: å¦–æ€ªï¼Œä½¿ç”¨ï¼Œå¯’å†°ç®­ï¼Œæ”»å‡»ï¼ŒçŒ¢ç‹²ï¼Œä½†è¢«ï¼Œçƒˆç„°æ‹³ï¼Œåå‡»ï¼Œå‡»æºƒã€‚\n",
      "   åµŒå…¥ç»´åº¦: 35 (ç¨€ç–åº¦: 9/35)\n",
      "   éé›¶å…ƒç´ : 9\n",
      "   Top-5 å…³é”®è¯:\n",
      "     - å¯’å†°ç®­: 1.4134\n",
      "     - ä½†è¢«: 1.4134\n",
      "     - åå‡»: 1.4134\n",
      "     - å‡»æºƒã€‚: 1.4134\n",
      "     - å¦–æ€ª: 0.8926\n",
      "\n",
      "ğŸ“„ æ–‡æ¡£ 3:\n",
      "   å†…å®¹: çŒ¢ç‹²ï¼Œå¬å”¤ï¼Œçƒˆç„°æ‹³ï¼Œä¸ï¼Œæ¯ç­å’†å“®ï¼Œå‡»è´¥ï¼Œå¦–æ€ªï¼Œéšåï¼Œæ”¶é›†ï¼Œå¦–æ€ªï¼Œç²¾åã€‚\n",
      "   åµŒå…¥ç»´åº¦: 35 (ç¨€ç–åº¦: 10/35)\n",
      "   éé›¶å…ƒç´ : 10\n",
      "   Top-5 å…³é”®è¯:\n",
      "     - å¬å”¤: 1.2877\n",
      "     - æ¯ç­å’†å“®: 1.2877\n",
      "     - å‡»è´¥: 1.2877\n",
      "     - éšå: 1.2877\n",
      "     - æ”¶é›†: 1.2877\n",
      "\n",
      "ğŸ“„ æ–‡æ¡£ 4:\n",
      "   å†…å®¹: çŒ¢ç‹²ï¼Œä½¿ç”¨ï¼Œé‡‘åˆšä½“ï¼Œé˜²å¾¡ï¼Œæ•Œäººï¼Œæ”»å‡»ï¼ŒæˆåŠŸï¼Œä¿æŠ¤ï¼Œé˜Ÿå‹ã€‚\n",
      "   åµŒå…¥ç»´åº¦: 35 (ç¨€ç–åº¦: 9/35)\n",
      "   éé›¶å…ƒç´ : 9\n",
      "   Top-5 å…³é”®è¯:\n",
      "     - é˜²å¾¡: 1.4134\n",
      "     - æ•Œäºº: 1.4134\n",
      "     - æˆåŠŸ: 1.4134\n",
      "     - ä¿æŠ¤: 1.4134\n",
      "     - é˜Ÿå‹ã€‚: 1.4134\n",
      "\n",
      "ğŸ“„ æ–‡æ¡£ 5:\n",
      "   å†…å®¹: æˆ˜æ–—ï¼Œç»“æŸï¼ŒçŒ¢ç‹²ï¼Œè·å¾—ï¼Œç»éªŒå€¼ï¼Œä¸ï¼Œæˆ˜åˆ©å“ï¼Œæå‡ï¼Œç­‰çº§ã€‚\n",
      "   åµŒå…¥ç»´åº¦: 35 (ç¨€ç–åº¦: 9/35)\n",
      "   éé›¶å…ƒç´ : 9\n",
      "   Top-5 å…³é”®è¯:\n",
      "     - æˆ˜æ–—: 1.4134\n",
      "     - ç»“æŸ: 1.4134\n",
      "     - è·å¾—: 1.4134\n",
      "     - ç»éªŒå€¼: 1.4134\n",
      "     - æˆ˜åˆ©å“: 1.4134\n",
      "\n",
      "================================================================================\n",
      "ã€æ­¥éª¤ 2ã€‘æ‰§è¡Œæ£€ç´¢æŸ¥è¯¢\n",
      "================================================================================\n",
      "\n",
      "ğŸ” æŸ¥è¯¢: çŒ¢ç‹²ï¼Œçƒˆç„°æ‹³ï¼Œæ”»å‡»\n",
      "--------------------------------------------------------------------------------\n",
      "  1. [æ–‡æ¡£ 2] ç›¸å…³æ€§åˆ†æ•°: 1.5647\n",
      "     å†…å®¹: å¦–æ€ªï¼Œä½¿ç”¨ï¼Œå¯’å†°ç®­ï¼Œæ”»å‡»ï¼ŒçŒ¢ç‹²ï¼Œä½†è¢«ï¼Œçƒˆç„°æ‹³ï¼Œåå‡»ï¼Œå‡»æºƒã€‚\n",
      "  2. [æ–‡æ¡£ 4] ç›¸å…³æ€§åˆ†æ•°: 1.1377\n",
      "     å†…å®¹: çŒ¢ç‹²ï¼Œä½¿ç”¨ï¼Œé‡‘åˆšä½“ï¼Œé˜²å¾¡ï¼Œæ•Œäººï¼Œæ”»å‡»ï¼ŒæˆåŠŸï¼Œä¿æŠ¤ï¼Œé˜Ÿå‹ã€‚\n",
      "  3. [æ–‡æ¡£ 1] ç›¸å…³æ€§åˆ†æ•°: 0.4381\n",
      "     å†…å®¹: çŒ¢ç‹²ï¼Œæ–½å±•ï¼Œçƒˆç„°æ‹³ï¼Œå‡»é€€ï¼Œå¦–æ€ªï¼›éšåå¼€å¯ï¼Œé‡‘åˆšä½“ï¼ŒæŠµæŒ¡ï¼Œç¥å…µï¼Œæ”»å‡»ã€‚\n",
      "\n",
      "ğŸ” æŸ¥è¯¢: é‡‘åˆšä½“ï¼Œé˜²å¾¡\n",
      "--------------------------------------------------------------------------------\n",
      "  1. [æ–‡æ¡£ 4] ç›¸å…³æ€§åˆ†æ•°: 4.2443\n",
      "     å†…å®¹: çŒ¢ç‹²ï¼Œä½¿ç”¨ï¼Œé‡‘åˆšä½“ï¼Œé˜²å¾¡ï¼Œæ•Œäººï¼Œæ”»å‡»ï¼ŒæˆåŠŸï¼Œä¿æŠ¤ï¼Œé˜Ÿå‹ã€‚\n",
      "  2. [æ–‡æ¡£ 1] ç›¸å…³æ€§åˆ†æ•°: 1.2101\n",
      "     å†…å®¹: çŒ¢ç‹²ï¼Œæ–½å±•ï¼Œçƒˆç„°æ‹³ï¼Œå‡»é€€ï¼Œå¦–æ€ªï¼›éšåå¼€å¯ï¼Œé‡‘åˆšä½“ï¼ŒæŠµæŒ¡ï¼Œç¥å…µï¼Œæ”»å‡»ã€‚\n",
      "  3. [æ–‡æ¡£ 2] ç›¸å…³æ€§åˆ†æ•°: 0.0000\n",
      "     å†…å®¹: å¦–æ€ªï¼Œä½¿ç”¨ï¼Œå¯’å†°ç®­ï¼Œæ”»å‡»ï¼ŒçŒ¢ç‹²ï¼Œä½†è¢«ï¼Œçƒˆç„°æ‹³ï¼Œåå‡»ï¼Œå‡»æºƒã€‚\n",
      "\n",
      "ğŸ” æŸ¥è¯¢: å¦–æ€ªï¼Œç²¾å\n",
      "--------------------------------------------------------------------------------\n",
      "  1. [æ–‡æ¡£ 3] ç›¸å…³æ€§åˆ†æ•°: 1.6076\n",
      "     å†…å®¹: çŒ¢ç‹²ï¼Œå¬å”¤ï¼Œçƒˆç„°æ‹³ï¼Œä¸ï¼Œæ¯ç­å’†å“®ï¼Œå‡»è´¥ï¼Œå¦–æ€ªï¼Œéšåï¼Œæ”¶é›†ï¼Œå¦–æ€ªï¼Œç²¾åã€‚\n",
      "  2. [æ–‡æ¡£ 2] ç›¸å…³æ€§åˆ†æ•°: 1.2101\n",
      "     å†…å®¹: å¦–æ€ªï¼Œä½¿ç”¨ï¼Œå¯’å†°ç®­ï¼Œæ”»å‡»ï¼ŒçŒ¢ç‹²ï¼Œä½†è¢«ï¼Œçƒˆç„°æ‹³ï¼Œåå‡»ï¼Œå‡»æºƒã€‚\n",
      "  3. [æ–‡æ¡£ 1] ç›¸å…³æ€§åˆ†æ•°: 0.0000\n",
      "     å†…å®¹: çŒ¢ç‹²ï¼Œæ–½å±•ï¼Œçƒˆç„°æ‹³ï¼Œå‡»é€€ï¼Œå¦–æ€ªï¼›éšåå¼€å¯ï¼Œé‡‘åˆšä½“ï¼ŒæŠµæŒ¡ï¼Œç¥å…µï¼Œæ”»å‡»ã€‚\n",
      "\n",
      "================================================================================\n",
      "ã€æ­¥éª¤ 3ã€‘è¯é‡è¦æ€§åˆ†æ (IDF å€¼)\n",
      "================================================================================\n",
      "\n",
      "Top-10 æœ€å…·åŒºåˆ†æ€§çš„è¯ (é«˜ IDF):\n",
      "  - é˜²å¾¡: 1.3863\n",
      "  - ç»“æŸ: 1.3863\n",
      "  - æå‡: 1.3863\n",
      "  - æŠµæŒ¡: 1.3863\n",
      "  - æˆ˜åˆ©å“: 1.3863\n",
      "  - ç²¾åã€‚: 1.3863\n",
      "  - ä½†è¢«: 1.3863\n",
      "  - å‡»è´¥: 1.3863\n",
      "  - é˜Ÿå‹ã€‚: 1.3863\n",
      "  - å¯’å†°ç®­: 1.3863\n",
      "\n",
      "================================================================================\n",
      "ã€æ­¥éª¤ 4ã€‘æ€§èƒ½ç»Ÿè®¡\n",
      "================================================================================\n",
      "  æ€»éé›¶å…ƒç´ æ•°: 46\n",
      "  æœ€å¤§å¯èƒ½å…ƒç´ æ•°: 175\n",
      "  ç¨€ç–åº¦: 73.71%\n",
      "  å¹³å‡æ¯æ–‡æ¡£éé›¶è¯æ•°: 9.20\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "import math\n",
    "import numpy as np\n",
    "from typing import List, Dict, Tuple\n",
    "\n",
    "\n",
    "class BM25Retriever:\n",
    "    \"\"\"\n",
    "    BM25 (Best Matching 25) æ£€ç´¢å™¨\n",
    "    \n",
    "    BM25 æ˜¯ä¸€ç§åŸºäºæ¦‚ç‡çš„ä¿¡æ¯æ£€ç´¢ç®—æ³•ï¼Œå¹¿æ³›åº”ç”¨äºæœç´¢å¼•æ“å’Œæ–‡æ¡£æ£€ç´¢ç³»ç»Ÿã€‚\n",
    "    å®ƒé€šè¿‡è®¡ç®—è¯é¢‘ (TF) å’Œé€†æ–‡æ¡£é¢‘ç‡ (IDF) æ¥è¯„ä¼°æ–‡æ¡£ä¸æŸ¥è¯¢çš„ç›¸å…³æ€§ã€‚\n",
    "    \n",
    "    å‚æ•°:\n",
    "        k1: æ§åˆ¶è¯é¢‘é¥±å’Œåº¦çš„å‚æ•°ï¼Œé€šå¸¸å–å€¼ 1.2-2.0ï¼Œé»˜è®¤ 1.5\n",
    "        b: æ§åˆ¶æ–‡æ¡£é•¿åº¦å½’ä¸€åŒ–çš„å‚æ•°ï¼Œå–å€¼ 0-1ï¼Œé»˜è®¤ 0.75\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, k1: float = 1.5, b: float = 0.75):\n",
    "        self.k1 = k1\n",
    "        self.b = b\n",
    "        self.documents = []\n",
    "        self.vocabulary = set()\n",
    "        self.vocab_to_idx = {}\n",
    "        self.idf = {}\n",
    "        self.avg_doc_len = 0\n",
    "        self.doc_embeddings = []\n",
    "        \n",
    "    def fit(self, documents: List[str], delimiter: str = \"ï¼Œ\"):\n",
    "        \"\"\"\n",
    "        è®­ç»ƒ BM25 æ¨¡å‹\n",
    "        \n",
    "        å‚æ•°:\n",
    "            documents: æ–‡æ¡£åˆ—è¡¨\n",
    "            delimiter: åˆ†è¯åˆ†éš”ç¬¦\n",
    "        \"\"\"\n",
    "        self.documents = documents\n",
    "        N = len(documents)\n",
    "        \n",
    "        # æ„å»ºè¯è¡¨\n",
    "        self.vocabulary = set(word for doc in documents for word in doc.split(delimiter))\n",
    "        self.vocab_to_idx = {word: idx for idx, word in enumerate(sorted(self.vocabulary))}\n",
    "        \n",
    "        # è®¡ç®—æ–‡æ¡£é¢‘ç‡ (DF)\n",
    "        df = Counter()\n",
    "        for doc in documents:\n",
    "            unique_words = set(doc.split(delimiter))\n",
    "            for word in unique_words:\n",
    "                df[word] += 1\n",
    "        \n",
    "        # è®¡ç®—é€†æ–‡æ¡£é¢‘ç‡ (IDF)\n",
    "        # IDF(w) = log((N - df(w) + 0.5) / (df(w) + 0.5) + 1)\n",
    "        self.idf = {\n",
    "            word: math.log((N - df[word] + 0.5) / (df[word] + 0.5) + 1) \n",
    "            for word in self.vocabulary\n",
    "        }\n",
    "        \n",
    "        # è®¡ç®—å¹³å‡æ–‡æ¡£é•¿åº¦\n",
    "        self.avg_doc_len = sum(len(doc.split(delimiter)) for doc in documents) / N\n",
    "        \n",
    "        # é¢„è®¡ç®—æ‰€æœ‰æ–‡æ¡£çš„ BM25 åµŒå…¥\n",
    "        self.doc_embeddings = [self._compute_embedding(doc, delimiter) for doc in documents]\n",
    "        \n",
    "        print(f\"âœ“ BM25 æ¨¡å‹è®­ç»ƒå®Œæˆ\")\n",
    "        print(f\"  - æ–‡æ¡£æ•°é‡: {N}\")\n",
    "        print(f\"  - è¯è¡¨å¤§å°: {len(self.vocabulary)}\")\n",
    "        print(f\"  - å¹³å‡æ–‡æ¡£é•¿åº¦: {self.avg_doc_len:.2f}\")\n",
    "        print(f\"  - å‚æ•°: k1={self.k1}, b={self.b}\")\n",
    "        \n",
    "    def _compute_embedding(self, text: str, delimiter: str = \"ï¼Œ\") -> Dict[int, float]:\n",
    "        \"\"\"\n",
    "        è®¡ç®—æ–‡æœ¬çš„ BM25 ç¨€ç–åµŒå…¥\n",
    "        \n",
    "        BM25 å…¬å¼:\n",
    "        score(w) = IDF(w) Ã— (TF(w) Ã— (k1 + 1)) / (TF(w) + k1 Ã— (1 - b + b Ã— |D| / avgdl))\n",
    "        \n",
    "        å…¶ä¸­:\n",
    "        - TF(w): è¯ w åœ¨æ–‡æ¡£ä¸­çš„é¢‘ç‡\n",
    "        - IDF(w): è¯ w çš„é€†æ–‡æ¡£é¢‘ç‡\n",
    "        - |D|: å½“å‰æ–‡æ¡£é•¿åº¦\n",
    "        - avgdl: å¹³å‡æ–‡æ¡£é•¿åº¦\n",
    "        \"\"\"\n",
    "        tf = Counter(text.split(delimiter))\n",
    "        doc_len = len(text.split(delimiter))\n",
    "        embedding = {}\n",
    "        \n",
    "        for word, freq in tf.items():\n",
    "            if word in self.vocabulary:\n",
    "                idx = self.vocab_to_idx[word]\n",
    "                # BM25 è®¡åˆ†å…¬å¼\n",
    "                numerator = self.idf[word] * freq * (self.k1 + 1)\n",
    "                denominator = freq + self.k1 * (1 - self.b + self.b * doc_len / self.avg_doc_len)\n",
    "                score = numerator / denominator\n",
    "                embedding[idx] = score\n",
    "                \n",
    "        return embedding\n",
    "    \n",
    "    def search(self, query: str, top_k: int = 3, delimiter: str = \"ï¼Œ\") -> List[Tuple[int, float, str]]:\n",
    "        \"\"\"\n",
    "        ä½¿ç”¨ BM25 æ£€ç´¢æœ€ç›¸å…³çš„æ–‡æ¡£\n",
    "        \n",
    "        å‚æ•°:\n",
    "            query: æŸ¥è¯¢æ–‡æœ¬\n",
    "            top_k: è¿”å›å‰ k ä¸ªæœ€ç›¸å…³çš„æ–‡æ¡£\n",
    "            delimiter: åˆ†è¯åˆ†éš”ç¬¦\n",
    "            \n",
    "        è¿”å›:\n",
    "            List of (æ–‡æ¡£ç´¢å¼•, ç›¸å…³æ€§åˆ†æ•°, æ–‡æ¡£å†…å®¹)\n",
    "        \"\"\"\n",
    "        # è®¡ç®—æŸ¥è¯¢çš„ BM25 åµŒå…¥\n",
    "        query_embedding = self._compute_embedding(query, delimiter)\n",
    "        \n",
    "        # è®¡ç®—æŸ¥è¯¢ä¸æ¯ä¸ªæ–‡æ¡£çš„ç›¸å…³æ€§åˆ†æ•°\n",
    "        scores = []\n",
    "        for doc_idx, doc_embedding in enumerate(self.doc_embeddings):\n",
    "            # è®¡ç®—ä¸¤ä¸ªç¨€ç–å‘é‡çš„ç‚¹ç§¯ï¼ˆå…±åŒè¯é¡¹çš„åˆ†æ•°ç›¸ä¹˜ç›¸åŠ ï¼‰\n",
    "            score = sum(\n",
    "                query_embedding.get(idx, 0) * doc_embedding.get(idx, 0)\n",
    "                for idx in set(query_embedding.keys()) | set(doc_embedding.keys())\n",
    "            )\n",
    "            scores.append((doc_idx, score, self.documents[doc_idx]))\n",
    "        \n",
    "        # æŒ‰åˆ†æ•°é™åºæ’åºå¹¶è¿”å› top_k\n",
    "        scores.sort(key=lambda x: x[1], reverse=True)\n",
    "        return scores[:top_k]\n",
    "    \n",
    "    def get_word_importance(self, doc_idx: int, top_n: int = 5) -> List[Tuple[str, float]]:\n",
    "        \"\"\"\n",
    "        è·å–æ–‡æ¡£ä¸­æœ€é‡è¦çš„è¯åŠå…¶ BM25 åˆ†æ•°\n",
    "        \n",
    "        å‚æ•°:\n",
    "            doc_idx: æ–‡æ¡£ç´¢å¼•\n",
    "            top_n: è¿”å›å‰ n ä¸ªé‡è¦è¯\n",
    "            \n",
    "        è¿”å›:\n",
    "            List of (è¯, BM25åˆ†æ•°)\n",
    "        \"\"\"\n",
    "        idx_to_vocab = {idx: word for word, idx in self.vocab_to_idx.items()}\n",
    "        embedding = self.doc_embeddings[doc_idx]\n",
    "        \n",
    "        # æŒ‰åˆ†æ•°æ’åº\n",
    "        word_scores = [(idx_to_vocab[idx], score) for idx, score in embedding.items()]\n",
    "        word_scores.sort(key=lambda x: x[1], reverse=True)\n",
    "        \n",
    "        return word_scores[:top_n]\n",
    "    \n",
    "    def print_embeddings(self, show_top_words: int = 5):\n",
    "        \"\"\"æ‰“å°æ‰€æœ‰æ–‡æ¡£çš„åµŒå…¥ä¿¡æ¯\"\"\"\n",
    "        print(f\"\\n{'='*80}\")\n",
    "        print(f\"BM25 ç¨€ç–åµŒå…¥è¯¦æƒ…\")\n",
    "        print(f\"{'='*80}\")\n",
    "        \n",
    "        for idx, (doc, embedding) in enumerate(zip(self.documents, self.doc_embeddings)):\n",
    "            print(f\"\\nğŸ“„ æ–‡æ¡£ {idx + 1}:\")\n",
    "            print(f\"   å†…å®¹: {doc}\")\n",
    "            print(f\"   åµŒå…¥ç»´åº¦: {len(self.vocabulary)} (ç¨€ç–åº¦: {len(embedding)}/{len(self.vocabulary)})\")\n",
    "            print(f\"   éé›¶å…ƒç´ : {len(embedding)}\")\n",
    "            \n",
    "            # æ˜¾ç¤ºæœ€é‡è¦çš„è¯\n",
    "            top_words = self.get_word_importance(idx, show_top_words)\n",
    "            print(f\"   Top-{show_top_words} å…³é”®è¯:\")\n",
    "            for word, score in top_words:\n",
    "                print(f\"     - {word}: {score:.4f}\")\n",
    "\n",
    "\n",
    "def main():\n",
    "    \"\"\"ä¸»å‡½æ•°ï¼šæ¼”ç¤º BM25 çš„ä½¿ç”¨\"\"\"\n",
    "    \n",
    "    # çŒ¢ç‹²çš„æˆ˜æ–—æ—¥å¿—æ•°æ®é›†\n",
    "    battle_logs = [\n",
    "        \"çŒ¢ç‹²ï¼Œæ–½å±•ï¼Œçƒˆç„°æ‹³ï¼Œå‡»é€€ï¼Œå¦–æ€ªï¼›éšåå¼€å¯ï¼Œé‡‘åˆšä½“ï¼ŒæŠµæŒ¡ï¼Œç¥å…µï¼Œæ”»å‡»ã€‚\",\n",
    "        \"å¦–æ€ªï¼Œä½¿ç”¨ï¼Œå¯’å†°ç®­ï¼Œæ”»å‡»ï¼ŒçŒ¢ç‹²ï¼Œä½†è¢«ï¼Œçƒˆç„°æ‹³ï¼Œåå‡»ï¼Œå‡»æºƒã€‚\",\n",
    "        \"çŒ¢ç‹²ï¼Œå¬å”¤ï¼Œçƒˆç„°æ‹³ï¼Œä¸ï¼Œæ¯ç­å’†å“®ï¼Œå‡»è´¥ï¼Œå¦–æ€ªï¼Œéšåï¼Œæ”¶é›†ï¼Œå¦–æ€ªï¼Œç²¾åã€‚\",\n",
    "        \"çŒ¢ç‹²ï¼Œä½¿ç”¨ï¼Œé‡‘åˆšä½“ï¼Œé˜²å¾¡ï¼Œæ•Œäººï¼Œæ”»å‡»ï¼ŒæˆåŠŸï¼Œä¿æŠ¤ï¼Œé˜Ÿå‹ã€‚\",\n",
    "        \"æˆ˜æ–—ï¼Œç»“æŸï¼ŒçŒ¢ç‹²ï¼Œè·å¾—ï¼Œç»éªŒå€¼ï¼Œä¸ï¼Œæˆ˜åˆ©å“ï¼Œæå‡ï¼Œç­‰çº§ã€‚\"\n",
    "    ]\n",
    "    \n",
    "    print(\"ğŸ”¥ BM25 ç¨€ç–åµŒå…¥ä¸æ£€ç´¢æ¼”ç¤º\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    # 1. åˆ›å»ºå¹¶è®­ç»ƒ BM25 æ£€ç´¢å™¨\n",
    "    print(\"\\nã€æ­¥éª¤ 1ã€‘è®­ç»ƒ BM25 æ¨¡å‹\")\n",
    "    print(\"-\"*80)\n",
    "    retriever = BM25Retriever(k1=1.5, b=0.75)\n",
    "    retriever.fit(battle_logs)\n",
    "    \n",
    "    # 2. æ‰“å°æ‰€æœ‰æ–‡æ¡£çš„åµŒå…¥\n",
    "    retriever.print_embeddings(show_top_words=5)\n",
    "    \n",
    "    # 3. æ‰§è¡Œæ£€ç´¢æŸ¥è¯¢\n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(\"ã€æ­¥éª¤ 2ã€‘æ‰§è¡Œæ£€ç´¢æŸ¥è¯¢\")\n",
    "    print(f\"{'='*80}\")\n",
    "    \n",
    "    queries = [\n",
    "        \"çŒ¢ç‹²ï¼Œçƒˆç„°æ‹³ï¼Œæ”»å‡»\",\n",
    "        \"é‡‘åˆšä½“ï¼Œé˜²å¾¡\",\n",
    "        \"å¦–æ€ªï¼Œç²¾å\"\n",
    "    ]\n",
    "    \n",
    "    for query in queries:\n",
    "        print(f\"\\nğŸ” æŸ¥è¯¢: {query}\")\n",
    "        print(\"-\"*80)\n",
    "        results = retriever.search(query, top_k=3)\n",
    "        \n",
    "        for rank, (doc_idx, score, doc_content) in enumerate(results, 1):\n",
    "            print(f\"  {rank}. [æ–‡æ¡£ {doc_idx + 1}] ç›¸å…³æ€§åˆ†æ•°: {score:.4f}\")\n",
    "            print(f\"     å†…å®¹: {doc_content}\")\n",
    "    \n",
    "    # 4. è¯é‡è¦æ€§åˆ†æ\n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(\"ã€æ­¥éª¤ 3ã€‘è¯é‡è¦æ€§åˆ†æ (IDF å€¼)\")\n",
    "    print(f\"{'='*80}\")\n",
    "    \n",
    "    # æ˜¾ç¤º IDF æœ€é«˜çš„è¯ï¼ˆæœ€å…·åŒºåˆ†æ€§çš„è¯ï¼‰\n",
    "    sorted_idf = sorted(retriever.idf.items(), key=lambda x: x[1], reverse=True)\n",
    "    print(\"\\nTop-10 æœ€å…·åŒºåˆ†æ€§çš„è¯ (é«˜ IDF):\")\n",
    "    for word, idf_score in sorted_idf[:10]:\n",
    "        print(f\"  - {word}: {idf_score:.4f}\")\n",
    "    \n",
    "    # 5. æ€§èƒ½ç»Ÿè®¡\n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(\"ã€æ­¥éª¤ 4ã€‘æ€§èƒ½ç»Ÿè®¡\")\n",
    "    print(f\"{'='*80}\")\n",
    "    total_elements = sum(len(emb) for emb in retriever.doc_embeddings)\n",
    "    max_possible = len(retriever.documents) * len(retriever.vocabulary)\n",
    "    sparsity = (1 - total_elements / max_possible) * 100\n",
    "    \n",
    "    print(f\"  æ€»éé›¶å…ƒç´ æ•°: {total_elements}\")\n",
    "    print(f\"  æœ€å¤§å¯èƒ½å…ƒç´ æ•°: {max_possible}\")\n",
    "    print(f\"  ç¨€ç–åº¦: {sparsity:.2f}%\")\n",
    "    print(f\"  å¹³å‡æ¯æ–‡æ¡£éé›¶è¯æ•°: {total_elements / len(retriever.documents):.2f}\")\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12148c45-5625-4ed1-9bb5-827e7416a9bc",
   "metadata": {},
   "source": [
    "## BGE-M3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ef0ecb85-87fd-495f-ae56-ac9ba3095b4d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "ğŸš€ BGE-M3 å¤šåŠŸèƒ½åµŒå…¥ä¸æ··åˆæ£€ç´¢æ¼”ç¤º\n",
      "================================================================================\n",
      "ğŸ”§ æ­£åœ¨åŠ è½½ BGE-M3 æ¨¡å‹: BAAI/bge-m3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching 30 files: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 30/30 [00:00<00:00, 63009.07it/s]\n",
      "You're using a XLMRobertaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ“ æ¨¡å‹åŠ è½½å®Œæˆ (è€—æ—¶: 7.73ç§’)\n",
      "\n",
      "================================================================================\n",
      "ã€æ­¥éª¤ 1ã€‘ç´¢å¼•æ–‡æ¡£\n",
      "================================================================================\n",
      "æ–‡æ¡£æ•°é‡: 7\n",
      "  ğŸ“ ç¼–ç  7 ä¸ªæ–‡æœ¬...\n",
      "  âœ“ ç¼–ç å®Œæˆ (è€—æ—¶: 1.38ç§’, é€Ÿåº¦: 5.06 docs/s)\n",
      "\n",
      "ğŸ“Š ç´¢å¼•ç»Ÿè®¡:\n",
      "  - å¯†é›†åµŒå…¥ç»´åº¦: 1024\n",
      "  - å¹³å‡ç¨€ç–åµŒå…¥éé›¶å…ƒç´ : 16.71\n",
      "  - å¹³å‡å¤šå‘é‡æ•°é‡: 21.14\n",
      "\n",
      "================================================================================\n",
      "ğŸ“Š åµŒå…¥ç‰¹æ€§åˆ†æ\n",
      "================================================================================\n",
      "æ–‡æœ¬: çŒ¢ç‹²æ–½å±•çƒˆç„°æ‹³ï¼Œå‡»é€€å¦–æ€ªï¼›éšåå¼€å¯é‡‘åˆšä½“ï¼ŒæŠµæŒ¡ç¥å…µæ”»å‡»ã€‚\n",
      "  ğŸ“ ç¼–ç  1 ä¸ªæ–‡æœ¬...\n",
      "  âœ“ ç¼–ç å®Œæˆ (è€—æ—¶: 0.48ç§’, é€Ÿåº¦: 2.06 docs/s)\n",
      "\n",
      "ğŸ”· å¯†é›†åµŒå…¥ (Dense Embedding)\n",
      "  - ç»´åº¦: (1024,)\n",
      "  - L2 èŒƒæ•°: 1.0000\n",
      "  - å‡å€¼: -0.0007\n",
      "  - æ ‡å‡†å·®: 0.0312\n",
      "  - å‰10ç»´: [ 0.01156882  0.024392   -0.02763914 -0.00984303 -0.04426071 -0.02911931\n",
      "  0.03953091  0.0216518   0.01074652 -0.03528602]\n",
      "\n",
      "ğŸ”¶ ç¨€ç–åµŒå…¥ (Sparse Embedding)\n",
      "  - éé›¶å…ƒç´ æ•°: 23\n",
      "  - æ€»æƒé‡: 3.4500\n",
      "  - æœ€å¤§æƒé‡: 0.2537\n",
      "  - Top-10 è¯é¡¹IDåŠæƒé‡:\n",
      "      ID 75133: 0.2537\n",
      "      ID 26471: 0.2490\n",
      "      ID 19752: 0.2313\n",
      "      ID 22477: 0.2181\n",
      "      ID 4742: 0.2175\n",
      "      ID 213212: 0.2088\n",
      "      ID 82929: 0.1897\n",
      "      ID 12461: 0.1877\n",
      "      ID 101184: 0.1864\n",
      "      ID 125510: 0.1702\n",
      "\n",
      "ğŸ”¸ å¤šå‘é‡åµŒå…¥ (ColBERT Embedding)\n",
      "  - å‘é‡æ•°é‡: 26\n",
      "  - æ¯ä¸ªå‘é‡ç»´åº¦: 1024\n",
      "  - å‘é‡é—´å¹³å‡ä½™å¼¦ç›¸ä¼¼åº¦: 0.6706\n",
      "  - ç¬¬1ä¸ªå‘é‡å‰10ç»´: [-0.05067746  0.00912721 -0.0287433  -0.0469315  -0.01172367  0.00606936\n",
      "  0.00621777 -0.06723101 -0.01492343 -0.02579602]\n",
      "  - ç¬¬2ä¸ªå‘é‡å‰10ç»´: [-0.0343939  -0.00773525 -0.01304417 -0.03001469 -0.00934525  0.00155912\n",
      "  0.00634999 -0.01256677 -0.01664798 -0.01816409]\n",
      "\n",
      "================================================================================\n",
      "ã€æ­¥éª¤ 2ã€‘å¤šç§æ£€ç´¢æ–¹å¼å¯¹æ¯”\n",
      "================================================================================\n",
      "\n",
      "================================================================================\n",
      "ğŸ” æŸ¥è¯¢: çƒˆç„°æ‹³æ”»å‡»å¦–æ€ª\n",
      "================================================================================\n",
      "\n",
      "ğŸ”· å¯†é›†æ£€ç´¢ (Dense)\n",
      "--------------------------------------------------------------------------------\n",
      "  ğŸ“ ç¼–ç  1 ä¸ªæ–‡æœ¬...\n",
      "  âœ“ ç¼–ç å®Œæˆ (è€—æ—¶: 0.28ç§’, é€Ÿåº¦: 3.61 docs/s)\n",
      "  1. [æ–‡æ¡£ 1] åˆ†æ•°: 0.7552\n",
      "     çŒ¢ç‹²æ–½å±•çƒˆç„°æ‹³ï¼Œå‡»é€€å¦–æ€ªï¼›éšåå¼€å¯é‡‘åˆšä½“ï¼ŒæŠµæŒ¡ç¥å…µæ”»å‡»ã€‚\n",
      "  2. [æ–‡æ¡£ 3] åˆ†æ•°: 0.7249\n",
      "     çŒ¢ç‹²å¬å”¤çƒˆç„°æ‹³ä¸æ¯ç­å’†å“®ï¼Œå‡»è´¥å¦–æ€ªï¼Œéšåæ”¶é›†å¦–æ€ªç²¾åã€‚\n",
      "  3. [æ–‡æ¡£ 2] åˆ†æ•°: 0.7234\n",
      "     å¦–æ€ªä½¿ç”¨å¯’å†°ç®­æ”»å‡»çŒ¢ç‹²ï¼Œä½†è¢«çƒˆç„°æ‹³åå‡»å‡»æºƒã€‚\n",
      "\n",
      "ğŸ”¶ ç¨€ç–æ£€ç´¢ (Sparse)\n",
      "--------------------------------------------------------------------------------\n",
      "  ğŸ“ ç¼–ç  1 ä¸ªæ–‡æœ¬...\n",
      "  âœ“ ç¼–ç å®Œæˆ (è€—æ—¶: 0.27ç§’, é€Ÿåº¦: 3.66 docs/s)\n",
      "  1. [æ–‡æ¡£ 1] åˆ†æ•°: 0.2289\n",
      "     çŒ¢ç‹²æ–½å±•çƒˆç„°æ‹³ï¼Œå‡»é€€å¦–æ€ªï¼›éšåå¼€å¯é‡‘åˆšä½“ï¼ŒæŠµæŒ¡ç¥å…µæ”»å‡»ã€‚\n",
      "  2. [æ–‡æ¡£ 3] åˆ†æ•°: 0.1754\n",
      "     çŒ¢ç‹²å¬å”¤çƒˆç„°æ‹³ä¸æ¯ç­å’†å“®ï¼Œå‡»è´¥å¦–æ€ªï¼Œéšåæ”¶é›†å¦–æ€ªç²¾åã€‚\n",
      "  3. [æ–‡æ¡£ 2] åˆ†æ•°: 0.1743\n",
      "     å¦–æ€ªä½¿ç”¨å¯’å†°ç®­æ”»å‡»çŒ¢ç‹²ï¼Œä½†è¢«çƒˆç„°æ‹³åå‡»å‡»æºƒã€‚\n",
      "\n",
      "ğŸ”¸ å¤šå‘é‡æ£€ç´¢ (ColBERT)\n",
      "--------------------------------------------------------------------------------\n",
      "  ğŸ“ ç¼–ç  1 ä¸ªæ–‡æœ¬...\n",
      "  âœ“ ç¼–ç å®Œæˆ (è€—æ—¶: 0.22ç§’, é€Ÿåº¦: 4.62 docs/s)\n",
      "  1. [æ–‡æ¡£ 1] åˆ†æ•°: 6.5377\n",
      "     çŒ¢ç‹²æ–½å±•çƒˆç„°æ‹³ï¼Œå‡»é€€å¦–æ€ªï¼›éšåå¼€å¯é‡‘åˆšä½“ï¼ŒæŠµæŒ¡ç¥å…µæ”»å‡»ã€‚\n",
      "  2. [æ–‡æ¡£ 2] åˆ†æ•°: 6.3033\n",
      "     å¦–æ€ªä½¿ç”¨å¯’å†°ç®­æ”»å‡»çŒ¢ç‹²ï¼Œä½†è¢«çƒˆç„°æ‹³åå‡»å‡»æºƒã€‚\n",
      "  3. [æ–‡æ¡£ 3] åˆ†æ•°: 6.1553\n",
      "     çŒ¢ç‹²å¬å”¤çƒˆç„°æ‹³ä¸æ¯ç­å’†å“®ï¼Œå‡»è´¥å¦–æ€ªï¼Œéšåæ”¶é›†å¦–æ€ªç²¾åã€‚\n",
      "\n",
      "â­ æ··åˆæ£€ç´¢ (Hybrid)\n",
      "--------------------------------------------------------------------------------\n",
      "  ğŸ“ ç¼–ç  1 ä¸ªæ–‡æœ¬...\n",
      "  âœ“ ç¼–ç å®Œæˆ (è€—æ—¶: 0.23ç§’, é€Ÿåº¦: 4.40 docs/s)\n",
      "  ğŸ“ ç¼–ç  1 ä¸ªæ–‡æœ¬...\n",
      "  âœ“ ç¼–ç å®Œæˆ (è€—æ—¶: 0.21ç§’, é€Ÿåº¦: 4.86 docs/s)\n",
      "  ğŸ“ ç¼–ç  1 ä¸ªæ–‡æœ¬...\n",
      "  âœ“ ç¼–ç å®Œæˆ (è€—æ—¶: 0.21ç§’, é€Ÿåº¦: 4.78 docs/s)\n",
      "  1. [æ–‡æ¡£ 1] åˆ†æ•°: 1.0000\n",
      "     çŒ¢ç‹²æ–½å±•çƒˆç„°æ‹³ï¼Œå‡»é€€å¦–æ€ªï¼›éšåå¼€å¯é‡‘åˆšä½“ï¼ŒæŠµæŒ¡ç¥å…µæ”»å‡»ã€‚\n",
      "  2. [æ–‡æ¡£ 2] åˆ†æ•°: 0.8666\n",
      "     å¦–æ€ªä½¿ç”¨å¯’å†°ç®­æ”»å‡»çŒ¢ç‹²ï¼Œä½†è¢«çƒˆç„°æ‹³åå‡»å‡»æºƒã€‚\n",
      "  3. [æ–‡æ¡£ 3] åˆ†æ•°: 0.8562\n",
      "     çŒ¢ç‹²å¬å”¤çƒˆç„°æ‹³ä¸æ¯ç­å’†å“®ï¼Œå‡»è´¥å¦–æ€ªï¼Œéšåæ”¶é›†å¦–æ€ªç²¾åã€‚\n",
      "\n",
      "================================================================================\n",
      "ğŸ” æŸ¥è¯¢: é‡‘åˆšä½“é˜²å¾¡æŠ€èƒ½\n",
      "================================================================================\n",
      "\n",
      "ğŸ”· å¯†é›†æ£€ç´¢ (Dense)\n",
      "--------------------------------------------------------------------------------\n",
      "  ğŸ“ ç¼–ç  1 ä¸ªæ–‡æœ¬...\n",
      "  âœ“ ç¼–ç å®Œæˆ (è€—æ—¶: 0.25ç§’, é€Ÿåº¦: 4.05 docs/s)\n",
      "  1. [æ–‡æ¡£ 4] åˆ†æ•°: 0.7676\n",
      "     çŒ¢ç‹²ä½¿ç”¨é‡‘åˆšä½“é˜²å¾¡æ•Œäººæ”»å‡»ï¼ŒæˆåŠŸä¿æŠ¤é˜Ÿå‹ã€‚\n",
      "  2. [æ–‡æ¡£ 1] åˆ†æ•°: 0.6211\n",
      "     çŒ¢ç‹²æ–½å±•çƒˆç„°æ‹³ï¼Œå‡»é€€å¦–æ€ªï¼›éšåå¼€å¯é‡‘åˆšä½“ï¼ŒæŠµæŒ¡ç¥å…µæ”»å‡»ã€‚\n",
      "  3. [æ–‡æ¡£ 7] åˆ†æ•°: 0.4925\n",
      "     é˜Ÿå‹ä¸ºçŒ¢ç‹²æä¾›æ²»ç–—å’Œå¢ç›Šæ•ˆæœï¼Œå¸®åŠ©å…¶æ¢å¤ç”Ÿå‘½å€¼å’Œæ³•åŠ›å€¼ã€‚\n",
      "\n",
      "ğŸ”¶ ç¨€ç–æ£€ç´¢ (Sparse)\n",
      "--------------------------------------------------------------------------------\n",
      "  ğŸ“ ç¼–ç  1 ä¸ªæ–‡æœ¬...\n",
      "  âœ“ ç¼–ç å®Œæˆ (è€—æ—¶: 0.20ç§’, é€Ÿåº¦: 4.89 docs/s)\n",
      "  1. [æ–‡æ¡£ 4] åˆ†æ•°: 0.2066\n",
      "     çŒ¢ç‹²ä½¿ç”¨é‡‘åˆšä½“é˜²å¾¡æ•Œäººæ”»å‡»ï¼ŒæˆåŠŸä¿æŠ¤é˜Ÿå‹ã€‚\n",
      "  2. [æ–‡æ¡£ 1] åˆ†æ•°: 0.1155\n",
      "     çŒ¢ç‹²æ–½å±•çƒˆç„°æ‹³ï¼Œå‡»é€€å¦–æ€ªï¼›éšåå¼€å¯é‡‘åˆšä½“ï¼ŒæŠµæŒ¡ç¥å…µæ”»å‡»ã€‚\n",
      "  3. [æ–‡æ¡£ 6] åˆ†æ•°: 0.0521\n",
      "     åœ¨æ·±æ¸Šå‰¯æœ¬ä¸­ï¼ŒçŒ¢ç‹²é­é‡å¼ºå¤§çš„Bossï¼Œä½¿ç”¨ç»ˆææŠ€èƒ½é»‘æš—çˆ†å‘ã€‚\n",
      "\n",
      "ğŸ”¸ å¤šå‘é‡æ£€ç´¢ (ColBERT)\n",
      "--------------------------------------------------------------------------------\n",
      "  ğŸ“ ç¼–ç  1 ä¸ªæ–‡æœ¬...\n",
      "  âœ“ ç¼–ç å®Œæˆ (è€—æ—¶: 0.21ç§’, é€Ÿåº¦: 4.82 docs/s)\n",
      "  1. [æ–‡æ¡£ 4] åˆ†æ•°: 5.6493\n",
      "     çŒ¢ç‹²ä½¿ç”¨é‡‘åˆšä½“é˜²å¾¡æ•Œäººæ”»å‡»ï¼ŒæˆåŠŸä¿æŠ¤é˜Ÿå‹ã€‚\n",
      "  2. [æ–‡æ¡£ 1] åˆ†æ•°: 4.7538\n",
      "     çŒ¢ç‹²æ–½å±•çƒˆç„°æ‹³ï¼Œå‡»é€€å¦–æ€ªï¼›éšåå¼€å¯é‡‘åˆšä½“ï¼ŒæŠµæŒ¡ç¥å…µæ”»å‡»ã€‚\n",
      "  3. [æ–‡æ¡£ 6] åˆ†æ•°: 3.1706\n",
      "     åœ¨æ·±æ¸Šå‰¯æœ¬ä¸­ï¼ŒçŒ¢ç‹²é­é‡å¼ºå¤§çš„Bossï¼Œä½¿ç”¨ç»ˆææŠ€èƒ½é»‘æš—çˆ†å‘ã€‚\n",
      "\n",
      "â­ æ··åˆæ£€ç´¢ (Hybrid)\n",
      "--------------------------------------------------------------------------------\n",
      "  ğŸ“ ç¼–ç  1 ä¸ªæ–‡æœ¬...\n",
      "  âœ“ ç¼–ç å®Œæˆ (è€—æ—¶: 0.21ç§’, é€Ÿåº¦: 4.83 docs/s)\n",
      "  ğŸ“ ç¼–ç  1 ä¸ªæ–‡æœ¬...\n",
      "  âœ“ ç¼–ç å®Œæˆ (è€—æ—¶: 0.23ç§’, é€Ÿåº¦: 4.29 docs/s)\n",
      "  ğŸ“ ç¼–ç  1 ä¸ªæ–‡æœ¬...\n",
      "  âœ“ ç¼–ç å®Œæˆ (è€—æ—¶: 0.20ç§’, é€Ÿåº¦: 4.88 docs/s)\n",
      "  1. [æ–‡æ¡£ 4] åˆ†æ•°: 1.0000\n",
      "     çŒ¢ç‹²ä½¿ç”¨é‡‘åˆšä½“é˜²å¾¡æ•Œäººæ”»å‡»ï¼ŒæˆåŠŸä¿æŠ¤é˜Ÿå‹ã€‚\n",
      "  2. [æ–‡æ¡£ 1] åˆ†æ•°: 0.5971\n",
      "     çŒ¢ç‹²æ–½å±•çƒˆç„°æ‹³ï¼Œå‡»é€€å¦–æ€ªï¼›éšåå¼€å¯é‡‘åˆšä½“ï¼ŒæŠµæŒ¡ç¥å…µæ”»å‡»ã€‚\n",
      "  3. [æ–‡æ¡£ 6] åˆ†æ•°: 0.1670\n",
      "     åœ¨æ·±æ¸Šå‰¯æœ¬ä¸­ï¼ŒçŒ¢ç‹²é­é‡å¼ºå¤§çš„Bossï¼Œä½¿ç”¨ç»ˆææŠ€èƒ½é»‘æš—çˆ†å‘ã€‚\n",
      "\n",
      "================================================================================\n",
      "ğŸ” æŸ¥è¯¢: æˆ˜æ–—è·å¾—ç»éªŒå€¼\n",
      "================================================================================\n",
      "\n",
      "ğŸ”· å¯†é›†æ£€ç´¢ (Dense)\n",
      "--------------------------------------------------------------------------------\n",
      "  ğŸ“ ç¼–ç  1 ä¸ªæ–‡æœ¬...\n",
      "  âœ“ ç¼–ç å®Œæˆ (è€—æ—¶: 0.21ç§’, é€Ÿåº¦: 4.79 docs/s)\n",
      "  1. [æ–‡æ¡£ 5] åˆ†æ•°: 0.7664\n",
      "     æˆ˜æ–—ç»“æŸåï¼ŒçŒ¢ç‹²è·å¾—ç»éªŒå€¼ä¸æˆ˜åˆ©å“ï¼ŒæˆåŠŸæå‡ç­‰çº§ã€‚\n",
      "  2. [æ–‡æ¡£ 7] åˆ†æ•°: 0.5953\n",
      "     é˜Ÿå‹ä¸ºçŒ¢ç‹²æä¾›æ²»ç–—å’Œå¢ç›Šæ•ˆæœï¼Œå¸®åŠ©å…¶æ¢å¤ç”Ÿå‘½å€¼å’Œæ³•åŠ›å€¼ã€‚\n",
      "  3. [æ–‡æ¡£ 4] åˆ†æ•°: 0.5108\n",
      "     çŒ¢ç‹²ä½¿ç”¨é‡‘åˆšä½“é˜²å¾¡æ•Œäººæ”»å‡»ï¼ŒæˆåŠŸä¿æŠ¤é˜Ÿå‹ã€‚\n",
      "\n",
      "ğŸ”¶ ç¨€ç–æ£€ç´¢ (Sparse)\n",
      "--------------------------------------------------------------------------------\n",
      "  ğŸ“ ç¼–ç  1 ä¸ªæ–‡æœ¬...\n",
      "  âœ“ ç¼–ç å®Œæˆ (è€—æ—¶: 0.21ç§’, é€Ÿåº¦: 4.84 docs/s)\n",
      "  1. [æ–‡æ¡£ 5] åˆ†æ•°: 0.2239\n",
      "     æˆ˜æ–—ç»“æŸåï¼ŒçŒ¢ç‹²è·å¾—ç»éªŒå€¼ä¸æˆ˜åˆ©å“ï¼ŒæˆåŠŸæå‡ç­‰çº§ã€‚\n",
      "  2. [æ–‡æ¡£ 7] åˆ†æ•°: 0.0431\n",
      "     é˜Ÿå‹ä¸ºçŒ¢ç‹²æä¾›æ²»ç–—å’Œå¢ç›Šæ•ˆæœï¼Œå¸®åŠ©å…¶æ¢å¤ç”Ÿå‘½å€¼å’Œæ³•åŠ›å€¼ã€‚\n",
      "  3. [æ–‡æ¡£ 1] åˆ†æ•°: 0.0010\n",
      "     çŒ¢ç‹²æ–½å±•çƒˆç„°æ‹³ï¼Œå‡»é€€å¦–æ€ªï¼›éšåå¼€å¯é‡‘åˆšä½“ï¼ŒæŠµæŒ¡ç¥å…µæ”»å‡»ã€‚\n",
      "\n",
      "ğŸ”¸ å¤šå‘é‡æ£€ç´¢ (ColBERT)\n",
      "--------------------------------------------------------------------------------\n",
      "  ğŸ“ ç¼–ç  1 ä¸ªæ–‡æœ¬...\n",
      "  âœ“ ç¼–ç å®Œæˆ (è€—æ—¶: 0.20ç§’, é€Ÿåº¦: 4.93 docs/s)\n",
      "  1. [æ–‡æ¡£ 5] åˆ†æ•°: 5.0352\n",
      "     æˆ˜æ–—ç»“æŸåï¼ŒçŒ¢ç‹²è·å¾—ç»éªŒå€¼ä¸æˆ˜åˆ©å“ï¼ŒæˆåŠŸæå‡ç­‰çº§ã€‚\n",
      "  2. [æ–‡æ¡£ 7] åˆ†æ•°: 3.5861\n",
      "     é˜Ÿå‹ä¸ºçŒ¢ç‹²æä¾›æ²»ç–—å’Œå¢ç›Šæ•ˆæœï¼Œå¸®åŠ©å…¶æ¢å¤ç”Ÿå‘½å€¼å’Œæ³•åŠ›å€¼ã€‚\n",
      "  3. [æ–‡æ¡£ 4] åˆ†æ•°: 3.2354\n",
      "     çŒ¢ç‹²ä½¿ç”¨é‡‘åˆšä½“é˜²å¾¡æ•Œäººæ”»å‡»ï¼ŒæˆåŠŸä¿æŠ¤é˜Ÿå‹ã€‚\n",
      "\n",
      "â­ æ··åˆæ£€ç´¢ (Hybrid)\n",
      "--------------------------------------------------------------------------------\n",
      "  ğŸ“ ç¼–ç  1 ä¸ªæ–‡æœ¬...\n",
      "  âœ“ ç¼–ç å®Œæˆ (è€—æ—¶: 0.21ç§’, é€Ÿåº¦: 4.84 docs/s)\n",
      "  ğŸ“ ç¼–ç  1 ä¸ªæ–‡æœ¬...\n",
      "  âœ“ ç¼–ç å®Œæˆ (è€—æ—¶: 0.24ç§’, é€Ÿåº¦: 4.19 docs/s)\n",
      "  ğŸ“ ç¼–ç  1 ä¸ªæ–‡æœ¬...\n",
      "  âœ“ ç¼–ç å®Œæˆ (è€—æ—¶: 0.20ç§’, é€Ÿåº¦: 4.99 docs/s)\n",
      "  1. [æ–‡æ¡£ 5] åˆ†æ•°: 1.0000\n",
      "     æˆ˜æ–—ç»“æŸåï¼ŒçŒ¢ç‹²è·å¾—ç»éªŒå€¼ä¸æˆ˜åˆ©å“ï¼ŒæˆåŠŸæå‡ç­‰çº§ã€‚\n",
      "  2. [æ–‡æ¡£ 7] åˆ†æ•°: 0.3843\n",
      "     é˜Ÿå‹ä¸ºçŒ¢ç‹²æä¾›æ²»ç–—å’Œå¢ç›Šæ•ˆæœï¼Œå¸®åŠ©å…¶æ¢å¤ç”Ÿå‘½å€¼å’Œæ³•åŠ›å€¼ã€‚\n",
      "  3. [æ–‡æ¡£ 4] åˆ†æ•°: 0.1882\n",
      "     çŒ¢ç‹²ä½¿ç”¨é‡‘åˆšä½“é˜²å¾¡æ•Œäººæ”»å‡»ï¼ŒæˆåŠŸä¿æŠ¤é˜Ÿå‹ã€‚\n",
      "\n",
      "================================================================================\n",
      "ğŸ” æŸ¥è¯¢: é˜Ÿå‹æ²»ç–—å’Œå¢ç›Š\n",
      "================================================================================\n",
      "\n",
      "ğŸ”· å¯†é›†æ£€ç´¢ (Dense)\n",
      "--------------------------------------------------------------------------------\n",
      "  ğŸ“ ç¼–ç  1 ä¸ªæ–‡æœ¬...\n",
      "  âœ“ ç¼–ç å®Œæˆ (è€—æ—¶: 0.21ç§’, é€Ÿåº¦: 4.77 docs/s)\n",
      "  1. [æ–‡æ¡£ 7] åˆ†æ•°: 0.8398\n",
      "     é˜Ÿå‹ä¸ºçŒ¢ç‹²æä¾›æ²»ç–—å’Œå¢ç›Šæ•ˆæœï¼Œå¸®åŠ©å…¶æ¢å¤ç”Ÿå‘½å€¼å’Œæ³•åŠ›å€¼ã€‚\n",
      "  2. [æ–‡æ¡£ 5] åˆ†æ•°: 0.5995\n",
      "     æˆ˜æ–—ç»“æŸåï¼ŒçŒ¢ç‹²è·å¾—ç»éªŒå€¼ä¸æˆ˜åˆ©å“ï¼ŒæˆåŠŸæå‡ç­‰çº§ã€‚\n",
      "  3. [æ–‡æ¡£ 4] åˆ†æ•°: 0.5883\n",
      "     çŒ¢ç‹²ä½¿ç”¨é‡‘åˆšä½“é˜²å¾¡æ•Œäººæ”»å‡»ï¼ŒæˆåŠŸä¿æŠ¤é˜Ÿå‹ã€‚\n",
      "\n",
      "ğŸ”¶ ç¨€ç–æ£€ç´¢ (Sparse)\n",
      "--------------------------------------------------------------------------------\n",
      "  ğŸ“ ç¼–ç  1 ä¸ªæ–‡æœ¬...\n",
      "  âœ“ ç¼–ç å®Œæˆ (è€—æ—¶: 0.21ç§’, é€Ÿåº¦: 4.79 docs/s)\n",
      "  1. [æ–‡æ¡£ 7] åˆ†æ•°: 0.2824\n",
      "     é˜Ÿå‹ä¸ºçŒ¢ç‹²æä¾›æ²»ç–—å’Œå¢ç›Šæ•ˆæœï¼Œå¸®åŠ©å…¶æ¢å¤ç”Ÿå‘½å€¼å’Œæ³•åŠ›å€¼ã€‚\n",
      "  2. [æ–‡æ¡£ 4] åˆ†æ•°: 0.0975\n",
      "     çŒ¢ç‹²ä½¿ç”¨é‡‘åˆšä½“é˜²å¾¡æ•Œäººæ”»å‡»ï¼ŒæˆåŠŸä¿æŠ¤é˜Ÿå‹ã€‚\n",
      "  3. [æ–‡æ¡£ 5] åˆ†æ•°: 0.0019\n",
      "     æˆ˜æ–—ç»“æŸåï¼ŒçŒ¢ç‹²è·å¾—ç»éªŒå€¼ä¸æˆ˜åˆ©å“ï¼ŒæˆåŠŸæå‡ç­‰çº§ã€‚\n",
      "\n",
      "ğŸ”¸ å¤šå‘é‡æ£€ç´¢ (ColBERT)\n",
      "--------------------------------------------------------------------------------\n",
      "  ğŸ“ ç¼–ç  1 ä¸ªæ–‡æœ¬...\n",
      "  âœ“ ç¼–ç å®Œæˆ (è€—æ—¶: 0.21ç§’, é€Ÿåº¦: 4.82 docs/s)\n",
      "  1. [æ–‡æ¡£ 7] åˆ†æ•°: 6.1592\n",
      "     é˜Ÿå‹ä¸ºçŒ¢ç‹²æä¾›æ²»ç–—å’Œå¢ç›Šæ•ˆæœï¼Œå¸®åŠ©å…¶æ¢å¤ç”Ÿå‘½å€¼å’Œæ³•åŠ›å€¼ã€‚\n",
      "  2. [æ–‡æ¡£ 4] åˆ†æ•°: 4.2406\n",
      "     çŒ¢ç‹²ä½¿ç”¨é‡‘åˆšä½“é˜²å¾¡æ•Œäººæ”»å‡»ï¼ŒæˆåŠŸä¿æŠ¤é˜Ÿå‹ã€‚\n",
      "  3. [æ–‡æ¡£ 5] åˆ†æ•°: 4.1302\n",
      "     æˆ˜æ–—ç»“æŸåï¼ŒçŒ¢ç‹²è·å¾—ç»éªŒå€¼ä¸æˆ˜åˆ©å“ï¼ŒæˆåŠŸæå‡ç­‰çº§ã€‚\n",
      "\n",
      "â­ æ··åˆæ£€ç´¢ (Hybrid)\n",
      "--------------------------------------------------------------------------------\n",
      "  ğŸ“ ç¼–ç  1 ä¸ªæ–‡æœ¬...\n",
      "  âœ“ ç¼–ç å®Œæˆ (è€—æ—¶: 0.22ç§’, é€Ÿåº¦: 4.60 docs/s)\n",
      "  ğŸ“ ç¼–ç  1 ä¸ªæ–‡æœ¬...\n",
      "  âœ“ ç¼–ç å®Œæˆ (è€—æ—¶: 0.22ç§’, é€Ÿåº¦: 4.56 docs/s)\n",
      "  ğŸ“ ç¼–ç  1 ä¸ªæ–‡æœ¬...\n",
      "  âœ“ ç¼–ç å®Œæˆ (è€—æ—¶: 0.22ç§’, é€Ÿåº¦: 4.47 docs/s)\n",
      "  1. [æ–‡æ¡£ 7] åˆ†æ•°: 1.0000\n",
      "     é˜Ÿå‹ä¸ºçŒ¢ç‹²æä¾›æ²»ç–—å’Œå¢ç›Šæ•ˆæœï¼Œå¸®åŠ©å…¶æ¢å¤ç”Ÿå‘½å€¼å’Œæ³•åŠ›å€¼ã€‚\n",
      "  2. [æ–‡æ¡£ 4] åˆ†æ•°: 0.4242\n",
      "     çŒ¢ç‹²ä½¿ç”¨é‡‘åˆšä½“é˜²å¾¡æ•Œäººæ”»å‡»ï¼ŒæˆåŠŸä¿æŠ¤é˜Ÿå‹ã€‚\n",
      "  3. [æ–‡æ¡£ 5] åˆ†æ•°: 0.3234\n",
      "     æˆ˜æ–—ç»“æŸåï¼ŒçŒ¢ç‹²è·å¾—ç»éªŒå€¼ä¸æˆ˜åˆ©å“ï¼ŒæˆåŠŸæå‡ç­‰çº§ã€‚\n",
      "\n",
      "================================================================================\n",
      "ã€æ­¥éª¤ 3ã€‘æ£€ç´¢æ–¹å¼ç‰¹ç‚¹æ€»ç»“\n",
      "================================================================================\n",
      "\n",
      "ğŸ”· å¯†é›†æ£€ç´¢ (Dense Retrieval)\n",
      "   ä¼˜åŠ¿: è¯­ä¹‰ç†è§£èƒ½åŠ›å¼ºï¼Œæ”¯æŒè·¨è¯­è¨€æ£€ç´¢ï¼Œå¯ä»¥ç†è§£åŒä¹‰è¯å’Œæ¦‚å¿µ\n",
      "   åŠ£åŠ¿: å¯¹ç½•è§è¯å’Œä¸“æœ‰åè¯æ”¯æŒè¾ƒå¼±\n",
      "   é€‚ç”¨: è¯­ä¹‰æœç´¢ã€æ¨èç³»ç»Ÿã€é—®ç­”ç³»ç»Ÿ\n",
      "\n",
      "ğŸ”¶ ç¨€ç–æ£€ç´¢ (Sparse Retrieval)\n",
      "   ä¼˜åŠ¿: ç²¾ç¡®è¯æ±‡åŒ¹é…ï¼Œå¯è§£é‡Šæ€§å¼ºï¼Œå¯¹å…³é”®è¯æ•æ„Ÿ\n",
      "   åŠ£åŠ¿: æ— æ³•ç†è§£åŒä¹‰è¯å’Œè¯­ä¹‰å…³ç³»\n",
      "   é€‚ç”¨: å…³é”®è¯æœç´¢ã€ä¸“æœ‰åè¯æ£€ç´¢ã€ç²¾ç¡®åŒ¹é…åœºæ™¯\n",
      "\n",
      "ğŸ”¸ å¤šå‘é‡æ£€ç´¢ (ColBERT)\n",
      "   ä¼˜åŠ¿: Tokençº§åˆ«ç²¾ç»†åŒ¹é…ï¼Œå¹³è¡¡è¯­ä¹‰å’Œè¯æ±‡ï¼Œæ£€ç´¢è´¨é‡é«˜\n",
      "   åŠ£åŠ¿: å­˜å‚¨å¼€é”€å¤§ï¼Œè®¡ç®—å¤æ‚åº¦é«˜\n",
      "   é€‚ç”¨: é«˜è´¨é‡æ£€ç´¢åœºæ™¯ã€éœ€è¦ç»†ç²’åº¦åŒ¹é…çš„ä»»åŠ¡\n",
      "\n",
      "â­ æ··åˆæ£€ç´¢ (Hybrid)\n",
      "   ä¼˜åŠ¿: ç»“åˆå¤šç§æ£€ç´¢ä¼˜åŠ¿ï¼Œæ£€ç´¢æ•ˆæœæœ€ç¨³å®šå¯é \n",
      "   åŠ£åŠ¿: éœ€è¦è°ƒæ•´æƒé‡å‚æ•°\n",
      "   é€‚ç”¨: é€šç”¨æ£€ç´¢åœºæ™¯ã€ç”Ÿäº§ç¯å¢ƒæ¨èä½¿ç”¨\n",
      "    \n",
      "\n",
      "================================================================================\n",
      "âœ“ æ¼”ç¤ºå®Œæˆï¼\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "# ä¸´æ—¶ç»•è¿‡ torch.load å®‰å…¨æ£€æŸ¥ï¼ˆä»…ç”¨äºå¼€å‘ç¯å¢ƒï¼‰\n",
    "# æ³¨æ„ï¼šè¿™æ˜¯ä¸€ä¸ªä¸´æ—¶è§£å†³æ–¹æ¡ˆï¼Œç”Ÿäº§ç¯å¢ƒåº”è¯¥å‡çº§ torch åˆ° 2.6+ æˆ–ä½¿ç”¨ safetensors æ ¼å¼\n",
    "import transformers.utils.import_utils\n",
    "import transformers.modeling_utils\n",
    "\n",
    "def dummy_check():\n",
    "    pass\n",
    "\n",
    "transformers.utils.import_utils.check_torch_load_is_safe = dummy_check\n",
    "transformers.modeling_utils.check_torch_load_is_safe = dummy_check\n",
    "\n",
    "from FlagEmbedding import BGEM3FlagModel\n",
    "import numpy as np\n",
    "from typing import List, Dict, Tuple, Optional\n",
    "import time\n",
    "\n",
    "\n",
    "class BGEM3Retriever:\n",
    "    \"\"\"\n",
    "    BGE-M3 æ··åˆæ£€ç´¢å™¨\n",
    "    \n",
    "    BGE-M3 (BAAI General Embedding - Multi-Lingual, Multi-Functionality, Multi-Granularity)\n",
    "    æ˜¯ä¸€ä¸ªå¼ºå¤§çš„å¤šè¯­è¨€åµŒå…¥æ¨¡å‹ï¼Œæ”¯æŒä¸‰ç§æ£€ç´¢æ–¹å¼ï¼š\n",
    "    \n",
    "    1. å¯†é›†æ£€ç´¢ (Dense Retrieval): è¯­ä¹‰ç›¸ä¼¼åº¦åŒ¹é…ï¼Œé€‚åˆæ•æ‰æ·±å±‚è¯­ä¹‰\n",
    "    2. ç¨€ç–æ£€ç´¢ (Sparse Retrieval): åŸºäºè¯æ±‡åŒ¹é…ï¼Œç±»ä¼¼ BM25ï¼Œé€‚åˆç²¾ç¡®åŒ¹é…\n",
    "    3. å¤šå‘é‡æ£€ç´¢ (Multi-Vector Retrieval): ColBERT é£æ ¼ï¼Œç»†ç²’åº¦äº¤äº’åŒ¹é…\n",
    "    \n",
    "    å‚æ•°:\n",
    "        model_name: æ¨¡å‹åç§°ï¼Œé»˜è®¤ \"BAAI/bge-m3\"\n",
    "        use_fp16: æ˜¯å¦ä½¿ç”¨åŠç²¾åº¦æµ®ç‚¹æ•°ï¼Œé»˜è®¤ False\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, model_name: str = \"BAAI/bge-m3\", use_fp16: bool = False):\n",
    "        print(f\"ğŸ”§ æ­£åœ¨åŠ è½½ BGE-M3 æ¨¡å‹: {model_name}\")\n",
    "        start_time = time.time()\n",
    "        \n",
    "        self.model = BGEM3FlagModel(model_name, use_fp16=use_fp16)\n",
    "        self.documents = []\n",
    "        self.dense_embeddings = None\n",
    "        self.sparse_embeddings = None\n",
    "        self.colbert_embeddings = None\n",
    "        \n",
    "        load_time = time.time() - start_time\n",
    "        print(f\"âœ“ æ¨¡å‹åŠ è½½å®Œæˆ (è€—æ—¶: {load_time:.2f}ç§’)\")\n",
    "    \n",
    "    def encode(self, texts: List[str], batch_size: int = 12, max_length: int = 512) -> Dict:\n",
    "        \"\"\"\n",
    "        ç¼–ç æ–‡æœ¬ï¼Œè·å–ä¸‰ç§åµŒå…¥\n",
    "        \n",
    "        å‚æ•°:\n",
    "            texts: æ–‡æœ¬åˆ—è¡¨\n",
    "            batch_size: æ‰¹å¤„ç†å¤§å°\n",
    "            max_length: æœ€å¤§åºåˆ—é•¿åº¦\n",
    "            \n",
    "        è¿”å›:\n",
    "            åŒ…å«ä¸‰ç§åµŒå…¥çš„å­—å…¸\n",
    "        \"\"\"\n",
    "        print(f\"  ğŸ“ ç¼–ç  {len(texts)} ä¸ªæ–‡æœ¬...\")\n",
    "        start_time = time.time()\n",
    "        \n",
    "        embeddings = self.model.encode(\n",
    "            texts,\n",
    "            batch_size=batch_size,\n",
    "            max_length=max_length,\n",
    "            return_dense=True,\n",
    "            return_sparse=True,\n",
    "            return_colbert_vecs=True\n",
    "        )\n",
    "        \n",
    "        encode_time = time.time() - start_time\n",
    "        print(f\"  âœ“ ç¼–ç å®Œæˆ (è€—æ—¶: {encode_time:.2f}ç§’, é€Ÿåº¦: {len(texts)/encode_time:.2f} docs/s)\")\n",
    "        \n",
    "        return embeddings\n",
    "    \n",
    "    def fit(self, documents: List[str]):\n",
    "        \"\"\"\n",
    "        ç´¢å¼•æ–‡æ¡£é›†åˆ\n",
    "        \n",
    "        å‚æ•°:\n",
    "            documents: æ–‡æ¡£åˆ—è¡¨\n",
    "        \"\"\"\n",
    "        print(f\"\\n{'='*80}\")\n",
    "        print(f\"ã€æ­¥éª¤ 1ã€‘ç´¢å¼•æ–‡æ¡£\")\n",
    "        print(f\"{'='*80}\")\n",
    "        print(f\"æ–‡æ¡£æ•°é‡: {len(documents)}\")\n",
    "        \n",
    "        self.documents = documents\n",
    "        embeddings = self.encode(documents)\n",
    "        \n",
    "        self.dense_embeddings = embeddings['dense_vecs']\n",
    "        self.sparse_embeddings = embeddings['lexical_weights']\n",
    "        self.colbert_embeddings = embeddings['colbert_vecs']\n",
    "        \n",
    "        # ç»Ÿè®¡ä¿¡æ¯\n",
    "        avg_sparse_len = np.mean([len(emb) for emb in self.sparse_embeddings])\n",
    "        avg_colbert_len = np.mean([emb.shape[0] for emb in self.colbert_embeddings])\n",
    "        \n",
    "        print(f\"\\nğŸ“Š ç´¢å¼•ç»Ÿè®¡:\")\n",
    "        print(f\"  - å¯†é›†åµŒå…¥ç»´åº¦: {self.dense_embeddings[0].shape[0]}\")\n",
    "        print(f\"  - å¹³å‡ç¨€ç–åµŒå…¥éé›¶å…ƒç´ : {avg_sparse_len:.2f}\")\n",
    "        print(f\"  - å¹³å‡å¤šå‘é‡æ•°é‡: {avg_colbert_len:.2f}\")\n",
    "    \n",
    "    def search_dense(self, query: str, top_k: int = 3) -> List[Tuple[int, float]]:\n",
    "        \"\"\"\n",
    "        å¯†é›†æ£€ç´¢ï¼šä½¿ç”¨ä½™å¼¦ç›¸ä¼¼åº¦è¿›è¡Œè¯­ä¹‰åŒ¹é…\n",
    "        \n",
    "        ä¼˜åŠ¿ï¼šæ•æ‰æ·±å±‚è¯­ä¹‰ï¼Œæ”¯æŒè·¨è¯­è¨€æ£€ç´¢\n",
    "        \"\"\"\n",
    "        query_embedding = self.encode([query])\n",
    "        query_dense = query_embedding['dense_vecs'][0]\n",
    "        \n",
    "        # è®¡ç®—ä½™å¼¦ç›¸ä¼¼åº¦\n",
    "        scores = []\n",
    "        for idx, doc_dense in enumerate(self.dense_embeddings):\n",
    "            # ä½™å¼¦ç›¸ä¼¼åº¦ = dot(A, B) / (norm(A) * norm(B))\n",
    "            similarity = np.dot(query_dense, doc_dense) / (\n",
    "                np.linalg.norm(query_dense) * np.linalg.norm(doc_dense)\n",
    "            )\n",
    "            scores.append((idx, float(similarity)))\n",
    "        \n",
    "        # æ’åºå¹¶è¿”å› top_k\n",
    "        scores.sort(key=lambda x: x[1], reverse=True)\n",
    "        return scores[:top_k]\n",
    "    \n",
    "    def search_sparse(self, query: str, top_k: int = 3) -> List[Tuple[int, float]]:\n",
    "        \"\"\"\n",
    "        ç¨€ç–æ£€ç´¢ï¼šåŸºäºè¯æ±‡åŒ¹é…ï¼Œç±»ä¼¼ BM25\n",
    "        \n",
    "        ä¼˜åŠ¿ï¼šç²¾ç¡®è¯æ±‡åŒ¹é…ï¼Œå¯è§£é‡Šæ€§å¼º\n",
    "        \"\"\"\n",
    "        query_embedding = self.encode([query])\n",
    "        query_sparse = query_embedding['lexical_weights'][0]\n",
    "        \n",
    "        # è®¡ç®—ç¨€ç–å‘é‡ç‚¹ç§¯\n",
    "        scores = []\n",
    "        for idx, doc_sparse in enumerate(self.sparse_embeddings):\n",
    "            # ç‚¹ç§¯ï¼šå…±åŒè¯é¡¹çš„æƒé‡ç›¸ä¹˜ç›¸åŠ \n",
    "            score = sum(\n",
    "                query_sparse.get(key, 0) * doc_sparse.get(key, 0)\n",
    "                for key in set(query_sparse.keys()) | set(doc_sparse.keys())\n",
    "            )\n",
    "            scores.append((idx, float(score)))\n",
    "        \n",
    "        scores.sort(key=lambda x: x[1], reverse=True)\n",
    "        return scores[:top_k]\n",
    "    \n",
    "    def search_colbert(self, query: str, top_k: int = 3) -> List[Tuple[int, float]]:\n",
    "        \"\"\"\n",
    "        å¤šå‘é‡æ£€ç´¢ï¼šColBERT é£æ ¼çš„ç»†ç²’åº¦äº¤äº’\n",
    "        \n",
    "        ä¼˜åŠ¿ï¼štoken çº§åˆ«çš„ç²¾ç»†åŒ¹é…ï¼Œå¹³è¡¡è¯­ä¹‰å’Œè¯æ±‡\n",
    "        \"\"\"\n",
    "        query_embedding = self.encode([query])\n",
    "        query_colbert = query_embedding['colbert_vecs'][0]\n",
    "        \n",
    "        # MaxSim æ“ä½œï¼šå¯¹æ¯ä¸ªæŸ¥è¯¢ tokenï¼Œæ‰¾åˆ°æ–‡æ¡£ä¸­æœ€ç›¸ä¼¼çš„ token\n",
    "        scores = []\n",
    "        for idx, doc_colbert in enumerate(self.colbert_embeddings):\n",
    "            # è®¡ç®—æŸ¥è¯¢å’Œæ–‡æ¡£ä¹‹é—´çš„ç›¸ä¼¼åº¦çŸ©é˜µ\n",
    "            sim_matrix = np.matmul(query_colbert, doc_colbert.T)\n",
    "            # å¯¹æ¯ä¸ªæŸ¥è¯¢ tokenï¼Œå–æœ€å¤§ç›¸ä¼¼åº¦ï¼Œç„¶åæ±‚å’Œ\n",
    "            max_sim = np.max(sim_matrix, axis=1).sum()\n",
    "            scores.append((idx, float(max_sim)))\n",
    "        \n",
    "        scores.sort(key=lambda x: x[1], reverse=True)\n",
    "        return scores[:top_k]\n",
    "    \n",
    "    def search_hybrid(\n",
    "        self, \n",
    "        query: str, \n",
    "        top_k: int = 3,\n",
    "        weights: Optional[Dict[str, float]] = None\n",
    "    ) -> List[Tuple[int, float]]:\n",
    "        \"\"\"\n",
    "        æ··åˆæ£€ç´¢ï¼šèåˆä¸‰ç§æ£€ç´¢æ–¹å¼çš„ç»“æœ\n",
    "        \n",
    "        å‚æ•°:\n",
    "            query: æŸ¥è¯¢æ–‡æœ¬\n",
    "            top_k: è¿”å›å‰ k ä¸ªç»“æœ\n",
    "            weights: ä¸‰ç§æ£€ç´¢æ–¹å¼çš„æƒé‡ï¼Œé»˜è®¤ {'dense': 0.4, 'sparse': 0.3, 'colbert': 0.3}\n",
    "        \"\"\"\n",
    "        if weights is None:\n",
    "            weights = {'dense': 0.4, 'sparse': 0.3, 'colbert': 0.3}\n",
    "        \n",
    "        # è·å–ä¸‰ç§æ£€ç´¢ç»“æœ\n",
    "        dense_results = self.search_dense(query, len(self.documents))\n",
    "        sparse_results = self.search_sparse(query, len(self.documents))\n",
    "        colbert_results = self.search_colbert(query, len(self.documents))\n",
    "        \n",
    "        # å½’ä¸€åŒ–åˆ†æ•°åˆ° [0, 1]\n",
    "        def normalize_scores(results):\n",
    "            if not results or max(r[1] for r in results) == 0:\n",
    "                return {idx: 0 for idx, _ in results}\n",
    "            max_score = max(r[1] for r in results)\n",
    "            min_score = min(r[1] for r in results)\n",
    "            score_range = max_score - min_score if max_score != min_score else 1\n",
    "            return {idx: (score - min_score) / score_range for idx, score in results}\n",
    "        \n",
    "        dense_norm = normalize_scores(dense_results)\n",
    "        sparse_norm = normalize_scores(sparse_results)\n",
    "        colbert_norm = normalize_scores(colbert_results)\n",
    "        \n",
    "        # è®¡ç®—åŠ æƒèåˆåˆ†æ•°\n",
    "        final_scores = []\n",
    "        for idx in range(len(self.documents)):\n",
    "            score = (\n",
    "                weights['dense'] * dense_norm.get(idx, 0) +\n",
    "                weights['sparse'] * sparse_norm.get(idx, 0) +\n",
    "                weights['colbert'] * colbert_norm.get(idx, 0)\n",
    "            )\n",
    "            final_scores.append((idx, score))\n",
    "        \n",
    "        final_scores.sort(key=lambda x: x[1], reverse=True)\n",
    "        return final_scores[:top_k]\n",
    "    \n",
    "    def compare_retrievals(self, query: str, top_k: int = 3):\n",
    "        \"\"\"\n",
    "        æ¯”è¾ƒä¸‰ç§æ£€ç´¢æ–¹å¼çš„ç»“æœ\n",
    "        \"\"\"\n",
    "        print(f\"\\n{'='*80}\")\n",
    "        print(f\"ğŸ” æŸ¥è¯¢: {query}\")\n",
    "        print(f\"{'='*80}\")\n",
    "        \n",
    "        methods = [\n",
    "            ('å¯†é›†æ£€ç´¢ (Dense)', self.search_dense, 'ğŸ”·'),\n",
    "            ('ç¨€ç–æ£€ç´¢ (Sparse)', self.search_sparse, 'ğŸ”¶'),\n",
    "            ('å¤šå‘é‡æ£€ç´¢ (ColBERT)', self.search_colbert, 'ğŸ”¸'),\n",
    "            ('æ··åˆæ£€ç´¢ (Hybrid)', self.search_hybrid, 'â­')\n",
    "        ]\n",
    "        \n",
    "        for method_name, method_func, emoji in methods:\n",
    "            print(f\"\\n{emoji} {method_name}\")\n",
    "            print(\"-\" * 80)\n",
    "            \n",
    "            results = method_func(query, top_k)\n",
    "            for rank, (doc_idx, score) in enumerate(results, 1):\n",
    "                print(f\"  {rank}. [æ–‡æ¡£ {doc_idx + 1}] åˆ†æ•°: {score:.4f}\")\n",
    "                print(f\"     {self.documents[doc_idx]}\")\n",
    "    \n",
    "    def analyze_embeddings(self, text: str):\n",
    "        \"\"\"\n",
    "        åˆ†æå•ä¸ªæ–‡æœ¬çš„ä¸‰ç§åµŒå…¥ç‰¹æ€§\n",
    "        \"\"\"\n",
    "        print(f\"\\n{'='*80}\")\n",
    "        print(f\"ğŸ“Š åµŒå…¥ç‰¹æ€§åˆ†æ\")\n",
    "        print(f\"{'='*80}\")\n",
    "        print(f\"æ–‡æœ¬: {text}\")\n",
    "        \n",
    "        embeddings = self.encode([text])\n",
    "        \n",
    "        # å¯†é›†åµŒå…¥åˆ†æ\n",
    "        dense = embeddings['dense_vecs'][0]\n",
    "        print(f\"\\nğŸ”· å¯†é›†åµŒå…¥ (Dense Embedding)\")\n",
    "        print(f\"  - ç»´åº¦: {dense.shape}\")\n",
    "        print(f\"  - L2 èŒƒæ•°: {np.linalg.norm(dense):.4f}\")\n",
    "        print(f\"  - å‡å€¼: {np.mean(dense):.4f}\")\n",
    "        print(f\"  - æ ‡å‡†å·®: {np.std(dense):.4f}\")\n",
    "        print(f\"  - å‰10ç»´: {dense[:10]}\")\n",
    "        \n",
    "        # ç¨€ç–åµŒå…¥åˆ†æ\n",
    "        sparse = embeddings['lexical_weights'][0]\n",
    "        sorted_sparse = sorted(sparse.items(), key=lambda x: x[1], reverse=True)\n",
    "        print(f\"\\nğŸ”¶ ç¨€ç–åµŒå…¥ (Sparse Embedding)\")\n",
    "        print(f\"  - éé›¶å…ƒç´ æ•°: {len(sparse)}\")\n",
    "        print(f\"  - æ€»æƒé‡: {sum(sparse.values()):.4f}\")\n",
    "        print(f\"  - æœ€å¤§æƒé‡: {max(sparse.values()):.4f}\")\n",
    "        print(f\"  - Top-10 è¯é¡¹IDåŠæƒé‡:\")\n",
    "        for token_id, weight in sorted_sparse[:10]:\n",
    "            print(f\"      ID {token_id}: {weight:.4f}\")\n",
    "        \n",
    "        # å¤šå‘é‡åµŒå…¥åˆ†æ\n",
    "        colbert = embeddings['colbert_vecs'][0]\n",
    "        print(f\"\\nğŸ”¸ å¤šå‘é‡åµŒå…¥ (ColBERT Embedding)\")\n",
    "        print(f\"  - å‘é‡æ•°é‡: {colbert.shape[0]}\")\n",
    "        print(f\"  - æ¯ä¸ªå‘é‡ç»´åº¦: {colbert.shape[1]}\")\n",
    "        print(f\"  - å‘é‡é—´å¹³å‡ä½™å¼¦ç›¸ä¼¼åº¦: {self._avg_cosine_similarity(colbert):.4f}\")\n",
    "        print(f\"  - ç¬¬1ä¸ªå‘é‡å‰10ç»´: {colbert[0][:10]}\")\n",
    "        print(f\"  - ç¬¬2ä¸ªå‘é‡å‰10ç»´: {colbert[1][:10]}\")\n",
    "    \n",
    "    def _avg_cosine_similarity(self, vectors):\n",
    "        \"\"\"è®¡ç®—å‘é‡é›†åˆçš„å¹³å‡ä½™å¼¦ç›¸ä¼¼åº¦\"\"\"\n",
    "        if len(vectors) < 2:\n",
    "            return 0.0\n",
    "        similarities = []\n",
    "        for i in range(len(vectors)):\n",
    "            for j in range(i + 1, len(vectors)):\n",
    "                sim = np.dot(vectors[i], vectors[j]) / (\n",
    "                    np.linalg.norm(vectors[i]) * np.linalg.norm(vectors[j])\n",
    "                )\n",
    "                similarities.append(sim)\n",
    "        return np.mean(similarities)\n",
    "\n",
    "\n",
    "def main():\n",
    "    \"\"\"ä¸»å‡½æ•°ï¼šæ¼”ç¤º BGE-M3 çš„ä½¿ç”¨\"\"\"\n",
    "    \n",
    "    print(\"=\"*80)\n",
    "    print(\"ğŸš€ BGE-M3 å¤šåŠŸèƒ½åµŒå…¥ä¸æ··åˆæ£€ç´¢æ¼”ç¤º\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    # åˆ›å»ºæ£€ç´¢å™¨\n",
    "    retriever = BGEM3Retriever(\"BAAI/bge-m3\", use_fp16=False)\n",
    "    \n",
    "    # æˆ˜æ–—æ—¥å¿—æ•°æ®é›†\n",
    "    battle_logs = [\n",
    "        \"çŒ¢ç‹²æ–½å±•çƒˆç„°æ‹³ï¼Œå‡»é€€å¦–æ€ªï¼›éšåå¼€å¯é‡‘åˆšä½“ï¼ŒæŠµæŒ¡ç¥å…µæ”»å‡»ã€‚\",\n",
    "        \"å¦–æ€ªä½¿ç”¨å¯’å†°ç®­æ”»å‡»çŒ¢ç‹²ï¼Œä½†è¢«çƒˆç„°æ‹³åå‡»å‡»æºƒã€‚\",\n",
    "        \"çŒ¢ç‹²å¬å”¤çƒˆç„°æ‹³ä¸æ¯ç­å’†å“®ï¼Œå‡»è´¥å¦–æ€ªï¼Œéšåæ”¶é›†å¦–æ€ªç²¾åã€‚\",\n",
    "        \"çŒ¢ç‹²ä½¿ç”¨é‡‘åˆšä½“é˜²å¾¡æ•Œäººæ”»å‡»ï¼ŒæˆåŠŸä¿æŠ¤é˜Ÿå‹ã€‚\",\n",
    "        \"æˆ˜æ–—ç»“æŸåï¼ŒçŒ¢ç‹²è·å¾—ç»éªŒå€¼ä¸æˆ˜åˆ©å“ï¼ŒæˆåŠŸæå‡ç­‰çº§ã€‚\",\n",
    "        \"åœ¨æ·±æ¸Šå‰¯æœ¬ä¸­ï¼ŒçŒ¢ç‹²é­é‡å¼ºå¤§çš„Bossï¼Œä½¿ç”¨ç»ˆææŠ€èƒ½é»‘æš—çˆ†å‘ã€‚\",\n",
    "        \"é˜Ÿå‹ä¸ºçŒ¢ç‹²æä¾›æ²»ç–—å’Œå¢ç›Šæ•ˆæœï¼Œå¸®åŠ©å…¶æ¢å¤ç”Ÿå‘½å€¼å’Œæ³•åŠ›å€¼ã€‚\"\n",
    "    ]\n",
    "    \n",
    "    # ç´¢å¼•æ–‡æ¡£\n",
    "    retriever.fit(battle_logs)\n",
    "    \n",
    "    # åˆ†æå•ä¸ªæ–‡æœ¬çš„åµŒå…¥ç‰¹æ€§\n",
    "    sample_text = \"çŒ¢ç‹²æ–½å±•çƒˆç„°æ‹³ï¼Œå‡»é€€å¦–æ€ªï¼›éšåå¼€å¯é‡‘åˆšä½“ï¼ŒæŠµæŒ¡ç¥å…µæ”»å‡»ã€‚\"\n",
    "    retriever.analyze_embeddings(sample_text)\n",
    "    \n",
    "    # æ¯”è¾ƒä¸åŒæ£€ç´¢æ–¹å¼\n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(f\"ã€æ­¥éª¤ 2ã€‘å¤šç§æ£€ç´¢æ–¹å¼å¯¹æ¯”\")\n",
    "    print(f\"{'='*80}\")\n",
    "    \n",
    "    queries = [\n",
    "        \"çƒˆç„°æ‹³æ”»å‡»å¦–æ€ª\",\n",
    "        \"é‡‘åˆšä½“é˜²å¾¡æŠ€èƒ½\",\n",
    "        \"æˆ˜æ–—è·å¾—ç»éªŒå€¼\",\n",
    "        \"é˜Ÿå‹æ²»ç–—å’Œå¢ç›Š\"\n",
    "    ]\n",
    "    \n",
    "    for query in queries:\n",
    "        retriever.compare_retrievals(query, top_k=3)\n",
    "    \n",
    "    # æ€§èƒ½å¯¹æ¯”æ€»ç»“\n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(f\"ã€æ­¥éª¤ 3ã€‘æ£€ç´¢æ–¹å¼ç‰¹ç‚¹æ€»ç»“\")\n",
    "    print(f\"{'='*80}\")\n",
    "    \n",
    "    print(\"\"\"\n",
    "ğŸ”· å¯†é›†æ£€ç´¢ (Dense Retrieval)\n",
    "   ä¼˜åŠ¿: è¯­ä¹‰ç†è§£èƒ½åŠ›å¼ºï¼Œæ”¯æŒè·¨è¯­è¨€æ£€ç´¢ï¼Œå¯ä»¥ç†è§£åŒä¹‰è¯å’Œæ¦‚å¿µ\n",
    "   åŠ£åŠ¿: å¯¹ç½•è§è¯å’Œä¸“æœ‰åè¯æ”¯æŒè¾ƒå¼±\n",
    "   é€‚ç”¨: è¯­ä¹‰æœç´¢ã€æ¨èç³»ç»Ÿã€é—®ç­”ç³»ç»Ÿ\n",
    "\n",
    "ğŸ”¶ ç¨€ç–æ£€ç´¢ (Sparse Retrieval)\n",
    "   ä¼˜åŠ¿: ç²¾ç¡®è¯æ±‡åŒ¹é…ï¼Œå¯è§£é‡Šæ€§å¼ºï¼Œå¯¹å…³é”®è¯æ•æ„Ÿ\n",
    "   åŠ£åŠ¿: æ— æ³•ç†è§£åŒä¹‰è¯å’Œè¯­ä¹‰å…³ç³»\n",
    "   é€‚ç”¨: å…³é”®è¯æœç´¢ã€ä¸“æœ‰åè¯æ£€ç´¢ã€ç²¾ç¡®åŒ¹é…åœºæ™¯\n",
    "\n",
    "ğŸ”¸ å¤šå‘é‡æ£€ç´¢ (ColBERT)\n",
    "   ä¼˜åŠ¿: Tokençº§åˆ«ç²¾ç»†åŒ¹é…ï¼Œå¹³è¡¡è¯­ä¹‰å’Œè¯æ±‡ï¼Œæ£€ç´¢è´¨é‡é«˜\n",
    "   åŠ£åŠ¿: å­˜å‚¨å¼€é”€å¤§ï¼Œè®¡ç®—å¤æ‚åº¦é«˜\n",
    "   é€‚ç”¨: é«˜è´¨é‡æ£€ç´¢åœºæ™¯ã€éœ€è¦ç»†ç²’åº¦åŒ¹é…çš„ä»»åŠ¡\n",
    "\n",
    "â­ æ··åˆæ£€ç´¢ (Hybrid)\n",
    "   ä¼˜åŠ¿: ç»“åˆå¤šç§æ£€ç´¢ä¼˜åŠ¿ï¼Œæ£€ç´¢æ•ˆæœæœ€ç¨³å®šå¯é \n",
    "   åŠ£åŠ¿: éœ€è¦è°ƒæ•´æƒé‡å‚æ•°\n",
    "   é€‚ç”¨: é€šç”¨æ£€ç´¢åœºæ™¯ã€ç”Ÿäº§ç¯å¢ƒæ¨èä½¿ç”¨\n",
    "    \"\"\")\n",
    "    \n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(\"âœ“ æ¼”ç¤ºå®Œæˆï¼\")\n",
    "    print(f\"{'='*80}\")\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b9ea03d",
   "metadata": {},
   "source": [
    "## å¤šæ¨¡æ€åµŒå…¥"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "04ce0af2-3e52-47a3-895b-04e0da615441",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "ğŸ¨ Visualized-BGE å¤šæ¨¡æ€æ£€ç´¢ç³»ç»Ÿæ¼”ç¤º\n",
      "================================================================================\n",
      "ğŸ”§ æ­£åœ¨åŠ è½½ Visualized-BGE å¤šæ¨¡æ€æ¨¡å‹...\n",
      "âœ“ æ¨¡å‹åŠ è½½å®Œæˆ (è®¾å¤‡: cpu, è€—æ—¶: 8.62ç§’)\n",
      "\n",
      "================================================================================\n",
      "ã€æ¼”ç¤º 1ã€‘åµŒå…¥å‘é‡ç‰¹æ€§åˆ†æ\n",
      "================================================================================\n",
      "\n",
      "================================================================================\n",
      "ğŸ“Š åµŒå…¥å‘é‡åˆ†æ\n",
      "================================================================================\n",
      "å›¾ç‰‡: /Users/ll/Desktop/rag/rag-in-action/90-æ–‡æ¡£-Data/å¤šæ¨¡æ€/query_image.jpg\n",
      "æè¿°: è¿™æ˜¯ä¸€å¼ æ‚Ÿç©ºæˆ˜æ–—çš„ç¤ºä¾‹å›¾ç‰‡\n",
      "\n",
      "ğŸ–¼ï¸  çº¯å›¾ç‰‡åµŒå…¥:\n",
      "  - ç»´åº¦: 768\n",
      "  - L2 èŒƒæ•°: 1.0000\n",
      "  - å‡å€¼: -0.000651\n",
      "  - æ ‡å‡†å·®: 0.036079\n",
      "  - æœ€å°å€¼: -0.250460\n",
      "  - æœ€å¤§å€¼: 0.096528\n",
      "  - å‰10ç»´: [ 0.01775778 -0.02236971  0.004773    0.00458726  0.02112675 -0.00138004\n",
      "  0.07065601  0.0665949  -0.01240909 -0.01269231]\n",
      "\n",
      "ğŸ–¼ï¸ +ğŸ“ å›¾æ–‡è”åˆåµŒå…¥:\n",
      "  - ç»´åº¦: 768\n",
      "  - L2 èŒƒæ•°: 1.0000\n",
      "  - å‡å€¼: -0.000667\n",
      "  - æ ‡å‡†å·®: 0.036078\n",
      "  - æœ€å°å€¼: -0.250252\n",
      "  - æœ€å¤§å€¼: 0.098347\n",
      "  - å‰10ç»´: [ 0.02958835 -0.02625961  0.00796746  0.00045585  0.00366952 -0.00388724\n",
      "  0.05554389  0.0655842  -0.01739006 -0.02965876]\n",
      "\n",
      "ç›¸ä¼¼åº¦ (çº¯å›¾ç‰‡ vs å›¾æ–‡è”åˆ): 0.8931\n",
      "\n",
      "================================================================================\n",
      "ğŸ“Š åµŒå…¥å‘é‡åˆ†æ\n",
      "================================================================================\n",
      "æ–‡æœ¬: A powerful warrior fighting monsters with flame fist\n",
      "\n",
      "ğŸ“ æ–‡æœ¬åµŒå…¥:\n",
      "  - ç»´åº¦: 768\n",
      "  - L2 èŒƒæ•°: 1.0000\n",
      "  - å‡å€¼: -0.000663\n",
      "  - æ ‡å‡†å·®: 0.036078\n",
      "  - æœ€å°å€¼: -0.242385\n",
      "  - æœ€å¤§å€¼: 0.104005\n",
      "  - å‰10ç»´: [-4.0013447e-02  7.9561156e-05 -4.8375305e-02  1.4259506e-02\n",
      " -1.1663715e-02 -1.8661396e-03 -2.2475293e-03 -3.4339085e-02\n",
      "  3.0522794e-02 -5.0171688e-02]\n",
      "\n",
      "================================================================================\n",
      "ã€æ¼”ç¤º 2ã€‘è·¨æ¨¡æ€ç›¸ä¼¼åº¦è®¡ç®—\n",
      "================================================================================\n",
      "\n",
      "æŸ¥è¯¢å›¾ç‰‡: query_image.jpg\n",
      "--------------------------------------------------------------------------------\n",
      "  ä¸æ–‡æœ¬ 'æ‚Ÿç©ºæˆ˜æ–—åœºæ™¯' çš„ç›¸ä¼¼åº¦: 0.4646\n",
      "  ä¸æ–‡æœ¬ 'A warrior with flame abilities' çš„ç›¸ä¼¼åº¦: 0.4984\n",
      "  ä¸æ–‡æœ¬ 'Cat playing with ball' çš„ç›¸ä¼¼åº¦: 0.2537\n",
      "  ä¸æ–‡æœ¬ 'Beautiful landscape scenery' çš„ç›¸ä¼¼åº¦: 0.4536\n",
      "\n",
      "================================================================================\n",
      "ã€æ¼”ç¤º 3ã€‘å›¾ç‰‡æ£€ç´¢åŠŸèƒ½ç¤ºä¾‹\n",
      "================================================================================\n",
      "\n",
      "================================================================================\n",
      "ã€æ­¥éª¤ 1ã€‘ç´¢å¼•å›¾ç‰‡é›†åˆ\n",
      "================================================================================\n",
      "å›¾ç‰‡æ•°é‡: 10\n",
      "âœ“ ç´¢å¼•å®Œæˆ (è€—æ—¶: 3.69ç§’, é€Ÿåº¦: 2.71 å›¾/ç§’)\n",
      "  - åµŒå…¥ç»´åº¦: 768\n",
      "\n",
      "ğŸ” ä»¥å›¾æœå›¾:\n",
      "æŸ¥è¯¢å›¾ç‰‡: query_image.jpg\n",
      "--------------------------------------------------------------------------------\n",
      "  1. ç›¸ä¼¼åº¦: 0.9663 - query_image.jpg\n",
      "  2. ç›¸ä¼¼åº¦: 0.6475 - 06.jpg\n",
      "  3. ç›¸ä¼¼åº¦: 0.6246 - 04.jpg\n",
      "\n",
      "ğŸ” ä»¥æ–‡æœå›¾:\n",
      "æŸ¥è¯¢æ–‡æœ¬: warrior fighting scene\n",
      "--------------------------------------------------------------------------------\n",
      "  1. ç›¸ä¼¼åº¦: 0.6141 - query_image.jpg\n",
      "  2. ç›¸ä¼¼åº¦: 0.6059 - 06.jpg\n",
      "  3. ç›¸ä¼¼åº¦: 0.6012 - 04.jpg\n",
      "\n",
      "================================================================================\n",
      "ã€å¤šæ¨¡æ€æ£€ç´¢åº”ç”¨åœºæ™¯ã€‘\n",
      "================================================================================\n",
      "\n",
      "ğŸ¯ åº”ç”¨åœºæ™¯:\n",
      "  1. ä»¥å›¾æœå›¾: å›¾ç‰‡å»é‡ã€ç›¸ä¼¼å›¾ç‰‡æ¨èã€ç‰ˆæƒæ£€æµ‹\n",
      "  2. ä»¥æ–‡æœå›¾: å›¾ç‰‡æœç´¢å¼•æ“ã€ç”µå•†å•†å“æ£€ç´¢ã€è®¾è®¡ç´ ææŸ¥æ‰¾\n",
      "  3. ä»¥å›¾æœæ–‡: å›¾ç‰‡æ ‡æ³¨ã€å†…å®¹å®¡æ ¸ã€å›¾ç‰‡ç†è§£\n",
      "  4. å›¾æ–‡åŒ¹é…: å¹¿å‘ŠæŠ•æ”¾ã€å†…å®¹æ¨èã€å¤šæ¨¡æ€é—®ç­”\n",
      "\n",
      "ğŸ’¡ æŠ€æœ¯ä¼˜åŠ¿:\n",
      "  - ç»Ÿä¸€çš„åµŒå…¥ç©ºé—´: å›¾ç‰‡å’Œæ–‡æœ¬åœ¨åŒä¸€å‘é‡ç©ºé—´ä¸­è¡¨ç¤º\n",
      "  - è·¨æ¨¡æ€æ£€ç´¢: æ”¯æŒå›¾æ‰¾æ–‡ã€æ–‡æ‰¾å›¾ç­‰çµæ´»æ£€ç´¢æ–¹å¼\n",
      "  - å›¾æ–‡å¢å¼º: ç»“åˆå›¾ç‰‡å’Œæ–‡æœ¬æè¿°ï¼Œæå‡è¡¨ç¤ºè´¨é‡\n",
      "  - é«˜æ•ˆæ£€ç´¢: å‘é‡åŒ–è¡¨ç¤ºæ”¯æŒå¿«é€Ÿç›¸ä¼¼åº¦è®¡ç®—\n",
      "    \n",
      "\n",
      "================================================================================\n",
      "âœ“ æ¼”ç¤ºå®Œæˆï¼\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "å¤šæ¨¡æ€åµŒå…¥æ£€ç´¢ç³»ç»Ÿï¼šä½¿ç”¨ Visualized-BGE æ¨¡å‹å®ç°å›¾æ–‡è”åˆæ£€ç´¢\n",
    "\n",
    "Visualized-BGE æ˜¯ä¸€ä¸ªå¼ºå¤§çš„å¤šæ¨¡æ€åµŒå…¥æ¨¡å‹ï¼Œæ”¯æŒï¼š\n",
    "- çº¯å›¾ç‰‡ç¼–ç \n",
    "- çº¯æ–‡æœ¬ç¼–ç \n",
    "- å›¾æ–‡è”åˆç¼–ç \n",
    "- è·¨æ¨¡æ€æ£€ç´¢ï¼ˆä»¥å›¾æœæ–‡ã€ä»¥æ–‡æœå›¾ã€ä»¥å›¾æœå›¾ï¼‰\n",
    "\n",
    "å®‰è£…è¯´æ˜ï¼š\n",
    "1. å®‰è£… visual_bgeï¼šhttps://github.com/FlagOpen/FlagEmbedding/tree/master/research/visual_bge\n",
    "2. ä¸‹è½½æ¨¡å‹æƒé‡ï¼šwget https://huggingface.co/BAAI/bge-visualized/resolve/main/Visualized_base_en_v1.5.pth\n",
    "\n",
    "æ³¨æ„ï¼šå¦‚æœè™šæ‹Ÿç¯å¢ƒæ— æ³•ä½¿ç”¨ï¼Œè¯·åˆ‡æ¢åˆ°ç‰©ç†ç¯å¢ƒ\n",
    "\"\"\"\n",
    "\n",
    "import torch\n",
    "from visual_bge.modeling import Visualized_BGE\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "from typing import List, Dict, Tuple, Union, Optional\n",
    "import os\n",
    "import time\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "class MultimodalRetriever:\n",
    "    \"\"\"\n",
    "    å¤šæ¨¡æ€æ£€ç´¢å™¨\n",
    "    \n",
    "    æ”¯æŒä¸‰ç§æ£€ç´¢æ¨¡å¼ï¼š\n",
    "    1. Image-to-Image: ä»¥å›¾æœå›¾\n",
    "    2. Image-to-Text: ä»¥å›¾æœæ–‡\n",
    "    3. Text-to-Image: ä»¥æ–‡æœå›¾\n",
    "    \n",
    "    å‚æ•°:\n",
    "        model_name_bge: BGE æ–‡æœ¬æ¨¡å‹åç§°\n",
    "        model_weight: Visualized-BGE æ¨¡å‹æƒé‡è·¯å¾„\n",
    "        device: è®¡ç®—è®¾å¤‡ï¼Œé»˜è®¤è‡ªåŠ¨é€‰æ‹©\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(\n",
    "        self, \n",
    "        model_name_bge: str = \"BAAI/bge-base-en-v1.5\",\n",
    "        model_weight: str = None,\n",
    "        device: Optional[str] = None\n",
    "    ):\n",
    "        print(f\"ğŸ”§ æ­£åœ¨åŠ è½½ Visualized-BGE å¤šæ¨¡æ€æ¨¡å‹...\")\n",
    "        start_time = time.time()\n",
    "        \n",
    "        # è‡ªåŠ¨é€‰æ‹©è®¾å¤‡\n",
    "        if device is None:\n",
    "            self.device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "        else:\n",
    "            self.device = device\n",
    "        \n",
    "        # æ£€æŸ¥æ¨¡å‹æƒé‡æ–‡ä»¶\n",
    "        if model_weight is None or not os.path.exists(model_weight):\n",
    "            raise FileNotFoundError(\n",
    "                f\"æ¨¡å‹æƒé‡æ–‡ä»¶ä¸å­˜åœ¨: {model_weight}\\n\"\n",
    "                \"è¯·ä¸‹è½½: wget https://huggingface.co/BAAI/bge-visualized/resolve/main/Visualized_base_en_v1.5.pth\"\n",
    "            )\n",
    "        \n",
    "        # åˆå§‹åŒ–æ¨¡å‹\n",
    "        self.model = Visualized_BGE(\n",
    "            model_name_bge=model_name_bge, \n",
    "            model_weight=model_weight\n",
    "        )\n",
    "        self.model.eval()\n",
    "        \n",
    "        # å­˜å‚¨ç´¢å¼•æ•°æ®\n",
    "        self.image_embeddings = []\n",
    "        self.text_embeddings = []\n",
    "        self.image_paths = []\n",
    "        self.texts = []\n",
    "        \n",
    "        load_time = time.time() - start_time\n",
    "        print(f\"âœ“ æ¨¡å‹åŠ è½½å®Œæˆ (è®¾å¤‡: {self.device}, è€—æ—¶: {load_time:.2f}ç§’)\")\n",
    "    \n",
    "    def encode_image(\n",
    "        self, \n",
    "        image_path: Union[str, List[str]], \n",
    "        text: Optional[Union[str, List[str]]] = None\n",
    "    ) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        ç¼–ç å›¾ç‰‡ï¼ˆå¯é€‰é™„åŠ æ–‡æœ¬æè¿°ï¼‰\n",
    "        \n",
    "        å‚æ•°:\n",
    "            image_path: å›¾ç‰‡è·¯å¾„æˆ–è·¯å¾„åˆ—è¡¨\n",
    "            text: å¯é€‰çš„æ–‡æœ¬æè¿°ï¼Œç”¨äºå›¾æ–‡è”åˆç¼–ç \n",
    "            \n",
    "        è¿”å›:\n",
    "            åµŒå…¥å‘é‡æ•°ç»„\n",
    "        \"\"\"\n",
    "        # å¤„ç†å•ä¸ªæˆ–æ‰¹é‡è¾“å…¥\n",
    "        if isinstance(image_path, str):\n",
    "            image_path = [image_path]\n",
    "        if text is not None and isinstance(text, str):\n",
    "            text = [text]\n",
    "        \n",
    "        embeddings = []\n",
    "        with torch.no_grad():\n",
    "            for idx, img_path in enumerate(image_path):\n",
    "                if not os.path.exists(img_path):\n",
    "                    print(f\"âš ï¸  å›¾ç‰‡ä¸å­˜åœ¨ï¼Œè·³è¿‡: {img_path}\")\n",
    "                    continue\n",
    "                \n",
    "                # ç¼–ç å›¾ç‰‡ï¼ˆå¸¦æˆ–ä¸å¸¦æ–‡æœ¬ï¼‰\n",
    "                img_text = text[idx] if text is not None else None\n",
    "                embedding = self.model.encode(image=img_path, text=img_text)\n",
    "                embeddings.append(embedding.cpu().numpy())\n",
    "        \n",
    "        return np.vstack(embeddings) if embeddings else np.array([])\n",
    "    \n",
    "    def encode_text(self, text: Union[str, List[str]]) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        ç¼–ç çº¯æ–‡æœ¬\n",
    "        \n",
    "        å‚æ•°:\n",
    "            text: æ–‡æœ¬æˆ–æ–‡æœ¬åˆ—è¡¨\n",
    "            \n",
    "        è¿”å›:\n",
    "            åµŒå…¥å‘é‡æ•°ç»„\n",
    "        \"\"\"\n",
    "        if isinstance(text, str):\n",
    "            text = [text]\n",
    "        \n",
    "        embeddings = []\n",
    "        with torch.no_grad():\n",
    "            for t in text:\n",
    "                embedding = self.model.encode(text=t)\n",
    "                embeddings.append(embedding.cpu().numpy())\n",
    "        \n",
    "        return np.vstack(embeddings)\n",
    "    \n",
    "    def index_images(\n",
    "        self, \n",
    "        image_paths: List[str], \n",
    "        descriptions: Optional[List[str]] = None\n",
    "    ):\n",
    "        \"\"\"\n",
    "        ç´¢å¼•å›¾ç‰‡é›†åˆ\n",
    "        \n",
    "        å‚æ•°:\n",
    "            image_paths: å›¾ç‰‡è·¯å¾„åˆ—è¡¨\n",
    "            descriptions: å¯é€‰çš„å›¾ç‰‡æè¿°åˆ—è¡¨\n",
    "        \"\"\"\n",
    "        print(f\"\\n{'='*80}\")\n",
    "        print(f\"ã€æ­¥éª¤ 1ã€‘ç´¢å¼•å›¾ç‰‡é›†åˆ\")\n",
    "        print(f\"{'='*80}\")\n",
    "        print(f\"å›¾ç‰‡æ•°é‡: {len(image_paths)}\")\n",
    "        \n",
    "        start_time = time.time()\n",
    "        self.image_paths = image_paths\n",
    "        self.image_embeddings = self.encode_image(image_paths, descriptions)\n",
    "        \n",
    "        index_time = time.time() - start_time\n",
    "        print(f\"âœ“ ç´¢å¼•å®Œæˆ (è€—æ—¶: {index_time:.2f}ç§’, é€Ÿåº¦: {len(image_paths)/index_time:.2f} å›¾/ç§’)\")\n",
    "        print(f\"  - åµŒå…¥ç»´åº¦: {self.image_embeddings.shape[1]}\")\n",
    "    \n",
    "    def index_texts(self, texts: List[str]):\n",
    "        \"\"\"\n",
    "        ç´¢å¼•æ–‡æœ¬é›†åˆ\n",
    "        \n",
    "        å‚æ•°:\n",
    "            texts: æ–‡æœ¬åˆ—è¡¨\n",
    "        \"\"\"\n",
    "        print(f\"\\n{'='*80}\")\n",
    "        print(f\"ã€æ­¥éª¤ 1ã€‘ç´¢å¼•æ–‡æœ¬é›†åˆ\")\n",
    "        print(f\"{'='*80}\")\n",
    "        print(f\"æ–‡æœ¬æ•°é‡: {len(texts)}\")\n",
    "        \n",
    "        start_time = time.time()\n",
    "        self.texts = texts\n",
    "        self.text_embeddings = self.encode_text(texts)\n",
    "        \n",
    "        index_time = time.time() - start_time\n",
    "        print(f\"âœ“ ç´¢å¼•å®Œæˆ (è€—æ—¶: {index_time:.2f}ç§’)\")\n",
    "        print(f\"  - åµŒå…¥ç»´åº¦: {self.text_embeddings.shape[1]}\")\n",
    "    \n",
    "    def search_by_image(\n",
    "        self, \n",
    "        query_image: str, \n",
    "        search_in: str = 'images',\n",
    "        top_k: int = 3\n",
    "    ) -> List[Tuple[int, float, str]]:\n",
    "        \"\"\"\n",
    "        ä»¥å›¾æœç´¢\n",
    "        \n",
    "        å‚æ•°:\n",
    "            query_image: æŸ¥è¯¢å›¾ç‰‡è·¯å¾„\n",
    "            search_in: æœç´¢ç›®æ ‡ï¼Œ'images' æˆ– 'texts'\n",
    "            top_k: è¿”å›å‰ k ä¸ªç»“æœ\n",
    "            \n",
    "        è¿”å›:\n",
    "            [(ç´¢å¼•, ç›¸ä¼¼åº¦åˆ†æ•°, å†…å®¹), ...]\n",
    "        \"\"\"\n",
    "        query_emb = self.encode_image(query_image)\n",
    "        \n",
    "        if search_in == 'images':\n",
    "            if len(self.image_embeddings) == 0:\n",
    "                raise ValueError(\"è¯·å…ˆä½¿ç”¨ index_images() ç´¢å¼•å›¾ç‰‡\")\n",
    "            scores = self._compute_similarities(query_emb, self.image_embeddings)\n",
    "            results = [(i, scores[i], self.image_paths[i]) for i in range(len(scores))]\n",
    "        else:  # texts\n",
    "            if len(self.text_embeddings) == 0:\n",
    "                raise ValueError(\"è¯·å…ˆä½¿ç”¨ index_texts() ç´¢å¼•æ–‡æœ¬\")\n",
    "            scores = self._compute_similarities(query_emb, self.text_embeddings)\n",
    "            results = [(i, scores[i], self.texts[i]) for i in range(len(scores))]\n",
    "        \n",
    "        results.sort(key=lambda x: x[1], reverse=True)\n",
    "        return results[:top_k]\n",
    "    \n",
    "    def search_by_text(\n",
    "        self, \n",
    "        query_text: str,\n",
    "        search_in: str = 'images',\n",
    "        top_k: int = 3\n",
    "    ) -> List[Tuple[int, float, str]]:\n",
    "        \"\"\"\n",
    "        ä»¥æ–‡æœç´¢\n",
    "        \n",
    "        å‚æ•°:\n",
    "            query_text: æŸ¥è¯¢æ–‡æœ¬\n",
    "            search_in: æœç´¢ç›®æ ‡ï¼Œ'images' æˆ– 'texts'\n",
    "            top_k: è¿”å›å‰ k ä¸ªç»“æœ\n",
    "            \n",
    "        è¿”å›:\n",
    "            [(ç´¢å¼•, ç›¸ä¼¼åº¦åˆ†æ•°, å†…å®¹), ...]\n",
    "        \"\"\"\n",
    "        query_emb = self.encode_text(query_text)\n",
    "        \n",
    "        if search_in == 'images':\n",
    "            if len(self.image_embeddings) == 0:\n",
    "                raise ValueError(\"è¯·å…ˆä½¿ç”¨ index_images() ç´¢å¼•å›¾ç‰‡\")\n",
    "            scores = self._compute_similarities(query_emb, self.image_embeddings)\n",
    "            results = [(i, scores[i], self.image_paths[i]) for i in range(len(scores))]\n",
    "        else:  # texts\n",
    "            if len(self.text_embeddings) == 0:\n",
    "                raise ValueError(\"è¯·å…ˆä½¿ç”¨ index_texts() ç´¢å¼•æ–‡æœ¬\")\n",
    "            scores = self._compute_similarities(query_emb, self.text_embeddings)\n",
    "            results = [(i, scores[i], self.texts[i]) for i in range(len(scores))]\n",
    "        \n",
    "        results.sort(key=lambda x: x[1], reverse=True)\n",
    "        return results[:top_k]\n",
    "    \n",
    "    def _compute_similarities(self, query_emb: np.ndarray, doc_embs: np.ndarray) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        è®¡ç®—ä½™å¼¦ç›¸ä¼¼åº¦\n",
    "        \n",
    "        å‚æ•°:\n",
    "            query_emb: æŸ¥è¯¢åµŒå…¥ (1, dim)\n",
    "            doc_embs: æ–‡æ¡£åµŒå…¥ (n, dim)\n",
    "            \n",
    "        è¿”å›:\n",
    "            ç›¸ä¼¼åº¦æ•°ç»„ (n,)\n",
    "        \"\"\"\n",
    "        # å½’ä¸€åŒ–\n",
    "        query_norm = query_emb / np.linalg.norm(query_emb, axis=1, keepdims=True)\n",
    "        doc_norms = doc_embs / np.linalg.norm(doc_embs, axis=1, keepdims=True)\n",
    "        \n",
    "        # ä½™å¼¦ç›¸ä¼¼åº¦\n",
    "        similarities = np.dot(query_norm, doc_norms.T)[0]\n",
    "        return similarities\n",
    "    \n",
    "    def compute_similarity(\n",
    "        self, \n",
    "        item1: Union[str, np.ndarray],\n",
    "        item2: Union[str, np.ndarray],\n",
    "        item1_type: str = 'image',\n",
    "        item2_type: str = 'image'\n",
    "    ) -> float:\n",
    "        \"\"\"\n",
    "        è®¡ç®—ä¸¤ä¸ªé¡¹ç›®ä¹‹é—´çš„ç›¸ä¼¼åº¦\n",
    "        \n",
    "        å‚æ•°:\n",
    "            item1: ç¬¬ä¸€ä¸ªé¡¹ç›®ï¼ˆè·¯å¾„æˆ–åµŒå…¥å‘é‡ï¼‰\n",
    "            item2: ç¬¬äºŒä¸ªé¡¹ç›®ï¼ˆè·¯å¾„æˆ–åµŒå…¥å‘é‡ï¼‰\n",
    "            item1_type: 'image' æˆ– 'text'\n",
    "            item2_type: 'image' æˆ– 'text'\n",
    "            \n",
    "        è¿”å›:\n",
    "            ç›¸ä¼¼åº¦åˆ†æ•° [0, 1]\n",
    "        \"\"\"\n",
    "        # è·å–åµŒå…¥å‘é‡\n",
    "        if isinstance(item1, str):\n",
    "            emb1 = self.encode_image(item1) if item1_type == 'image' else self.encode_text(item1)\n",
    "        else:\n",
    "            emb1 = item1\n",
    "        \n",
    "        if isinstance(item2, str):\n",
    "            emb2 = self.encode_image(item2) if item2_type == 'image' else self.encode_text(item2)\n",
    "        else:\n",
    "            emb2 = item2\n",
    "        \n",
    "        # è®¡ç®—ä½™å¼¦ç›¸ä¼¼åº¦\n",
    "        similarity = np.dot(emb1.flatten(), emb2.flatten()) / (\n",
    "            np.linalg.norm(emb1) * np.linalg.norm(emb2)\n",
    "        )\n",
    "        \n",
    "        return float(similarity)\n",
    "    \n",
    "    def analyze_embedding(self, item: str, item_type: str = 'image', text_desc: Optional[str] = None):\n",
    "        \"\"\"\n",
    "        åˆ†æåµŒå…¥å‘é‡çš„ç‰¹æ€§\n",
    "        \n",
    "        å‚æ•°:\n",
    "            item: å›¾ç‰‡è·¯å¾„æˆ–æ–‡æœ¬\n",
    "            item_type: 'image' æˆ– 'text'\n",
    "            text_desc: å¦‚æœæ˜¯å›¾ç‰‡ï¼Œå¯é€‰çš„æ–‡æœ¬æè¿°\n",
    "        \"\"\"\n",
    "        print(f\"\\n{'='*80}\")\n",
    "        print(f\"ğŸ“Š åµŒå…¥å‘é‡åˆ†æ\")\n",
    "        print(f\"{'='*80}\")\n",
    "        \n",
    "        if item_type == 'image':\n",
    "            print(f\"å›¾ç‰‡: {item}\")\n",
    "            if text_desc:\n",
    "                print(f\"æè¿°: {text_desc}\")\n",
    "            \n",
    "            # çº¯å›¾ç‰‡åµŒå…¥\n",
    "            img_emb = self.encode_image(item)\n",
    "            print(f\"\\nğŸ–¼ï¸  çº¯å›¾ç‰‡åµŒå…¥:\")\n",
    "            self._print_embedding_stats(img_emb[0])\n",
    "            \n",
    "            # å›¾æ–‡è”åˆåµŒå…¥ï¼ˆå¦‚æœæœ‰æè¿°ï¼‰\n",
    "            if text_desc:\n",
    "                multimodal_emb = self.encode_image(item, text_desc)\n",
    "                print(f\"\\nğŸ–¼ï¸ +ğŸ“ å›¾æ–‡è”åˆåµŒå…¥:\")\n",
    "                self._print_embedding_stats(multimodal_emb[0])\n",
    "                \n",
    "                # è®¡ç®—ä¸¤ç§åµŒå…¥çš„ç›¸ä¼¼åº¦\n",
    "                similarity = self.compute_similarity(img_emb, multimodal_emb)\n",
    "                print(f\"\\nç›¸ä¼¼åº¦ (çº¯å›¾ç‰‡ vs å›¾æ–‡è”åˆ): {similarity:.4f}\")\n",
    "        else:\n",
    "            print(f\"æ–‡æœ¬: {item}\")\n",
    "            text_emb = self.encode_text(item)\n",
    "            print(f\"\\nğŸ“ æ–‡æœ¬åµŒå…¥:\")\n",
    "            self._print_embedding_stats(text_emb[0])\n",
    "    \n",
    "    def _print_embedding_stats(self, embedding: np.ndarray):\n",
    "        \"\"\"æ‰“å°åµŒå…¥å‘é‡ç»Ÿè®¡ä¿¡æ¯\"\"\"\n",
    "        print(f\"  - ç»´åº¦: {embedding.shape[0]}\")\n",
    "        print(f\"  - L2 èŒƒæ•°: {np.linalg.norm(embedding):.4f}\")\n",
    "        print(f\"  - å‡å€¼: {np.mean(embedding):.6f}\")\n",
    "        print(f\"  - æ ‡å‡†å·®: {np.std(embedding):.6f}\")\n",
    "        print(f\"  - æœ€å°å€¼: {np.min(embedding):.6f}\")\n",
    "        print(f\"  - æœ€å¤§å€¼: {np.max(embedding):.6f}\")\n",
    "        print(f\"  - å‰10ç»´: {embedding[:10]}\")\n",
    "\n",
    "\n",
    "def main():\n",
    "    \"\"\"ä¸»å‡½æ•°ï¼šæ¼”ç¤ºå¤šæ¨¡æ€æ£€ç´¢ç³»ç»Ÿ\"\"\"\n",
    "    \n",
    "    print(\"=\"*80)\n",
    "    print(\"ğŸ¨ Visualized-BGE å¤šæ¨¡æ€æ£€ç´¢ç³»ç»Ÿæ¼”ç¤º\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    # é…ç½®è·¯å¾„\n",
    "    base_dir = \"/Users/ll/Desktop/rag/rag-in-action\"\n",
    "    model_weight = os.path.join(base_dir, \"Visualized_base_en_v1.5.pth\")\n",
    "    data_dir = os.path.join(base_dir, \"90-æ–‡æ¡£-Data/å¤šæ¨¡æ€\")\n",
    "    \n",
    "    # æ£€æŸ¥æ¨¡å‹æƒé‡æ˜¯å¦å­˜åœ¨\n",
    "    if not os.path.exists(model_weight):\n",
    "        print(f\"âŒ æ¨¡å‹æƒé‡æ–‡ä»¶ä¸å­˜åœ¨: {model_weight}\")\n",
    "        print(\"è¯·ä¸‹è½½æ¨¡å‹æƒé‡æ–‡ä»¶ï¼š\")\n",
    "        print(\"wget https://huggingface.co/BAAI/bge-visualized/resolve/main/Visualized_base_en_v1.5.pth\")\n",
    "        return\n",
    "    \n",
    "    # æ£€æŸ¥æ•°æ®ç›®å½•\n",
    "    if not os.path.exists(data_dir):\n",
    "        print(f\"âŒ æ•°æ®ç›®å½•ä¸å­˜åœ¨: {data_dir}\")\n",
    "        print(\"è¯·åˆ›å»ºæ•°æ®ç›®å½•å¹¶å‡†å¤‡ç¤ºä¾‹å›¾ç‰‡\")\n",
    "        return\n",
    "    \n",
    "    # åˆ›å»ºæ£€ç´¢å™¨\n",
    "    retriever = MultimodalRetriever(\n",
    "        model_name_bge=\"BAAI/bge-base-en-v1.5\",\n",
    "        model_weight=model_weight\n",
    "    )\n",
    "    \n",
    "    # ç¤ºä¾‹å›¾ç‰‡è·¯å¾„\n",
    "    query_image = os.path.join(data_dir, \"query_image.jpg\")\n",
    "    \n",
    "    if not os.path.exists(query_image):\n",
    "        print(f\"âŒ æŸ¥è¯¢å›¾ç‰‡ä¸å­˜åœ¨: {query_image}\")\n",
    "        print(\"è¯·å‡†å¤‡ç¤ºä¾‹å›¾ç‰‡\")\n",
    "        return\n",
    "    \n",
    "    # ã€æ¼”ç¤º 1ã€‘åµŒå…¥å‘é‡åˆ†æ\n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(\"ã€æ¼”ç¤º 1ã€‘åµŒå…¥å‘é‡ç‰¹æ€§åˆ†æ\")\n",
    "    print(f\"{'='*80}\")\n",
    "    \n",
    "    retriever.analyze_embedding(\n",
    "        query_image, \n",
    "        item_type='image',\n",
    "        text_desc=\"è¿™æ˜¯ä¸€å¼ æ‚Ÿç©ºæˆ˜æ–—çš„ç¤ºä¾‹å›¾ç‰‡\"\n",
    "    )\n",
    "    \n",
    "    # ã€æ¼”ç¤º 2ã€‘æ–‡æœ¬åµŒå…¥åˆ†æ\n",
    "    retriever.analyze_embedding(\n",
    "        \"A powerful warrior fighting monsters with flame fist\",\n",
    "        item_type='text'\n",
    "    )\n",
    "    \n",
    "    # ã€æ¼”ç¤º 3ã€‘è·¨æ¨¡æ€ç›¸ä¼¼åº¦è®¡ç®—\n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(\"ã€æ¼”ç¤º 2ã€‘è·¨æ¨¡æ€ç›¸ä¼¼åº¦è®¡ç®—\")\n",
    "    print(f\"{'='*80}\")\n",
    "    \n",
    "    text_queries = [\n",
    "        \"æ‚Ÿç©ºæˆ˜æ–—åœºæ™¯\",\n",
    "        \"A warrior with flame abilities\",\n",
    "        \"Cat playing with ball\",\n",
    "        \"Beautiful landscape scenery\"\n",
    "    ]\n",
    "    \n",
    "    print(f\"\\næŸ¥è¯¢å›¾ç‰‡: {os.path.basename(query_image)}\")\n",
    "    print(\"-\" * 80)\n",
    "    \n",
    "    for text in text_queries:\n",
    "        similarity = retriever.compute_similarity(\n",
    "            query_image, text,\n",
    "            item1_type='image', item2_type='text'\n",
    "        )\n",
    "        print(f\"  ä¸æ–‡æœ¬ '{text}' çš„ç›¸ä¼¼åº¦: {similarity:.4f}\")\n",
    "    \n",
    "    # ã€æ¼”ç¤º 3ã€‘å¦‚æœæœ‰å¤šå¼ å›¾ç‰‡ï¼Œæ¼”ç¤ºæ£€ç´¢åŠŸèƒ½\n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(\"ã€æ¼”ç¤º 3ã€‘å›¾ç‰‡æ£€ç´¢åŠŸèƒ½ç¤ºä¾‹\")\n",
    "    print(f\"{'='*80}\")\n",
    "    \n",
    "    # æŸ¥æ‰¾æ•°æ®ç›®å½•ä¸‹çš„æ‰€æœ‰å›¾ç‰‡\n",
    "    image_extensions = {'.jpg', '.jpeg', '.png', '.bmp', '.gif'}\n",
    "    image_files = [\n",
    "        os.path.join(data_dir, f) \n",
    "        for f in os.listdir(data_dir)\n",
    "        if os.path.splitext(f)[1].lower() in image_extensions\n",
    "    ]\n",
    "    \n",
    "    if len(image_files) > 1:\n",
    "        # å›¾ç‰‡æè¿°ï¼ˆå¯é€‰ï¼‰\n",
    "        descriptions = [f\"Image {i+1}\" for i in range(len(image_files))]\n",
    "        \n",
    "        # ç´¢å¼•å›¾ç‰‡\n",
    "        retriever.index_images(image_files, descriptions)\n",
    "        \n",
    "        # ä»¥å›¾æœå›¾\n",
    "        print(f\"\\nğŸ” ä»¥å›¾æœå›¾:\")\n",
    "        print(f\"æŸ¥è¯¢å›¾ç‰‡: {os.path.basename(query_image)}\")\n",
    "        print(\"-\" * 80)\n",
    "        \n",
    "        results = retriever.search_by_image(query_image, search_in='images', top_k=3)\n",
    "        for rank, (idx, score, img_path) in enumerate(results, 1):\n",
    "            print(f\"  {rank}. ç›¸ä¼¼åº¦: {score:.4f} - {os.path.basename(img_path)}\")\n",
    "        \n",
    "        # ä»¥æ–‡æœå›¾\n",
    "        print(f\"\\nğŸ” ä»¥æ–‡æœå›¾:\")\n",
    "        search_text = \"warrior fighting scene\"\n",
    "        print(f\"æŸ¥è¯¢æ–‡æœ¬: {search_text}\")\n",
    "        print(\"-\" * 80)\n",
    "        \n",
    "        results = retriever.search_by_text(search_text, search_in='images', top_k=3)\n",
    "        for rank, (idx, score, img_path) in enumerate(results, 1):\n",
    "            print(f\"  {rank}. ç›¸ä¼¼åº¦: {score:.4f} - {os.path.basename(img_path)}\")\n",
    "    else:\n",
    "        print(\"âš ï¸  æ•°æ®ç›®å½•ä¸­å›¾ç‰‡æ•°é‡ä¸è¶³ï¼Œè·³è¿‡æ£€ç´¢æ¼”ç¤º\")\n",
    "        print(f\"å½“å‰å›¾ç‰‡æ•°é‡: {len(image_files)}\")\n",
    "    \n",
    "    # æ€»ç»“\n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(\"ã€å¤šæ¨¡æ€æ£€ç´¢åº”ç”¨åœºæ™¯ã€‘\")\n",
    "    print(f\"{'='*80}\")\n",
    "    print(\"\"\"\n",
    "ğŸ¯ åº”ç”¨åœºæ™¯:\n",
    "  1. ä»¥å›¾æœå›¾: å›¾ç‰‡å»é‡ã€ç›¸ä¼¼å›¾ç‰‡æ¨èã€ç‰ˆæƒæ£€æµ‹\n",
    "  2. ä»¥æ–‡æœå›¾: å›¾ç‰‡æœç´¢å¼•æ“ã€ç”µå•†å•†å“æ£€ç´¢ã€è®¾è®¡ç´ ææŸ¥æ‰¾\n",
    "  3. ä»¥å›¾æœæ–‡: å›¾ç‰‡æ ‡æ³¨ã€å†…å®¹å®¡æ ¸ã€å›¾ç‰‡ç†è§£\n",
    "  4. å›¾æ–‡åŒ¹é…: å¹¿å‘ŠæŠ•æ”¾ã€å†…å®¹æ¨èã€å¤šæ¨¡æ€é—®ç­”\n",
    "\n",
    "ğŸ’¡ æŠ€æœ¯ä¼˜åŠ¿:\n",
    "  - ç»Ÿä¸€çš„åµŒå…¥ç©ºé—´: å›¾ç‰‡å’Œæ–‡æœ¬åœ¨åŒä¸€å‘é‡ç©ºé—´ä¸­è¡¨ç¤º\n",
    "  - è·¨æ¨¡æ€æ£€ç´¢: æ”¯æŒå›¾æ‰¾æ–‡ã€æ–‡æ‰¾å›¾ç­‰çµæ´»æ£€ç´¢æ–¹å¼\n",
    "  - å›¾æ–‡å¢å¼º: ç»“åˆå›¾ç‰‡å’Œæ–‡æœ¬æè¿°ï¼Œæå‡è¡¨ç¤ºè´¨é‡\n",
    "  - é«˜æ•ˆæ£€ç´¢: å‘é‡åŒ–è¡¨ç¤ºæ”¯æŒå¿«é€Ÿç›¸ä¼¼åº¦è®¡ç®—\n",
    "    \"\"\")\n",
    "    \n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(\"âœ“ æ¼”ç¤ºå®Œæˆï¼\")\n",
    "    print(f\"{'='*80}\")\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main() "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25d77482",
   "metadata": {},
   "source": [
    "# Milvuså‘é‡æ•°æ®åº“"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3c4831e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ”§ æ­£åœ¨è¿æ¥ Milvus...\n",
      "âœ“ å·²è¿æ¥åˆ° Milvus (URI: http://localhost:19530)\n",
      "================================================================================\n",
      "ğŸš€ Milvus å‘é‡æ•°æ®åº“å®Œæ•´æ“ä½œæ¼”ç¤º\n",
      "================================================================================\n",
      "\n",
      "ğŸ§¹ æ¸…ç†æ—§çš„æ¼”ç¤ºæ•°æ®...\n",
      "âœ“ æ¸…ç†å®Œæˆ\n",
      "\n",
      "\n",
      "================================================================================\n",
      "ã€ç¬¬ä¸€éƒ¨åˆ†ã€‘æ•°æ®åº“ç®¡ç† (Database Management)\n",
      "================================================================================\n",
      "\n",
      "1ï¸âƒ£  åˆ›å»ºæ•°æ®åº“\n",
      "--------------------------------------------------------------------------------\n",
      "âœ“ demo_db_1 åˆ›å»ºæˆåŠŸ\n",
      "âœ“ demo_db_2 åˆ›å»ºæˆåŠŸ (å‰¯æœ¬æ•°=2)\n",
      "\n",
      "2ï¸âƒ£  åˆ—å‡ºæ‰€æœ‰æ•°æ®åº“\n",
      "--------------------------------------------------------------------------------\n",
      "å½“å‰æ•°æ®åº“åˆ—è¡¨: ['default', 'demo_db_1', 'demo_db_2']\n",
      "\n",
      "3ï¸âƒ£  æŸ¥çœ‹æ•°æ®åº“è¯¦æƒ…\n",
      "--------------------------------------------------------------------------------\n",
      "é»˜è®¤æ•°æ®åº“è¯¦æƒ…: {'name': 'default'}\n",
      "\n",
      "4ï¸âƒ£  ä¿®æ”¹æ•°æ®åº“å±æ€§\n",
      "--------------------------------------------------------------------------------\n",
      "âœ“ å·²ä¸º demo_db_1 é™åˆ¶æœ€å¤§é›†åˆæ•°ä¸º 10\n",
      "\n",
      "5ï¸âƒ£  åˆ é™¤æ•°æ®åº“å±æ€§\n",
      "--------------------------------------------------------------------------------\n",
      "âœ“ å·²ç§»é™¤ demo_db_1 çš„æœ€å¤§é›†åˆæ•°é™åˆ¶\n",
      "\n",
      "6ï¸âƒ£  åˆ‡æ¢å½“å‰æ•°æ®åº“\n",
      "--------------------------------------------------------------------------------\n",
      "âœ“ å·²åˆ‡æ¢åˆ° demo_db_1\n",
      "âœ“ å·²åˆ‡æ¢å› default æ•°æ®åº“\n",
      "\n",
      "================================================================================\n",
      "ã€ç¬¬äºŒéƒ¨åˆ†ã€‘é›†åˆç®¡ç† (Collection Management)\n",
      "================================================================================\n",
      "\n",
      "1ï¸âƒ£  åˆ›å»ºé›†åˆ (å¿«é€Ÿæ¨¡å¼)\n",
      "--------------------------------------------------------------------------------\n",
      "âœ“ é›†åˆ demo_collection åˆ›å»ºæˆåŠŸ (ç»´åº¦=128)\n",
      "\n",
      "2ï¸âƒ£  åˆ—å‡ºæ‰€æœ‰é›†åˆ\n",
      "--------------------------------------------------------------------------------\n",
      "å½“å‰é›†åˆåˆ—è¡¨: ['demo_collection', 'quick_renamed']\n",
      "\n",
      "3ï¸âƒ£  æŸ¥çœ‹é›†åˆè¯¦æƒ…\n",
      "--------------------------------------------------------------------------------\n",
      "é›†åˆè¯¦æƒ…:\n",
      "  - é›†åˆå: demo_collection\n",
      "  - å­—æ®µæ•°: 2\n",
      "\n",
      "4ï¸âƒ£  é‡å‘½åé›†åˆ\n",
      "--------------------------------------------------------------------------------\n",
      "âœ“ é›†åˆå·²é‡å‘½å: demo_collection -> demo_collection_renamed\n",
      "\n",
      "5ï¸âƒ£  ä¿®æ”¹é›†åˆå±æ€§\n",
      "--------------------------------------------------------------------------------\n",
      "âœ“ å·²ä¸º demo_collection_renamed è®¾ç½® TTL=3600ç§’ (1å°æ—¶)\n",
      "\n",
      "6ï¸âƒ£  åˆ é™¤é›†åˆå±æ€§\n",
      "--------------------------------------------------------------------------------\n",
      "âœ“ å·²åˆ é™¤ demo_collection_renamed çš„ TTL å±æ€§\n",
      "\n",
      "7ï¸âƒ£  åŠ è½½å’Œé‡Šæ”¾é›†åˆ\n",
      "--------------------------------------------------------------------------------\n",
      "åŠ è½½çŠ¶æ€: {'state': <LoadState: Loaded>}\n",
      "é‡Šæ”¾åçŠ¶æ€: {'state': <LoadState: NotLoad>}\n",
      "\n",
      "8ï¸âƒ£  åˆ†åŒºç®¡ç† (Partition Management)\n",
      "--------------------------------------------------------------------------------\n",
      "åˆå§‹åˆ†åŒºåˆ—è¡¨: ['_default']\n",
      "âœ“ å·²åˆ›å»ºåˆ†åŒº demo_partition\n",
      "åˆ†åŒº demo_partition å­˜åœ¨: True\n",
      "âœ“ å·²åŠ è½½åˆ†åŒº demo_partition\n",
      "âœ“ å·²é‡Šæ”¾åˆ†åŒº demo_partition\n",
      "âœ“ å·²åˆ é™¤åˆ†åŒº demo_partition\n",
      "\n",
      "9ï¸âƒ£  åˆ«åç®¡ç† (Alias Management)\n",
      "--------------------------------------------------------------------------------\n",
      "âœ“ å·²åˆ›å»ºåˆ«å: demo_alias_1, demo_alias_2\n",
      "å½“å‰åˆ«ååˆ—è¡¨: {'aliases': ['demo_alias_1', 'demo_alias_2'], 'collection_name': 'demo_collection_renamed', 'db_name': 'default'}\n",
      "åˆ«å demo_alias_1 è¯¦æƒ…: {'alias': 'demo_alias_1', 'collection_name': 'demo_collection_renamed', 'db_name': 'default'}\n",
      "âœ“ å·²åˆ é™¤åˆ«å demo_alias_1\n",
      "\n",
      "âœ“ å·²æ¸…ç†æ¼”ç¤ºé›†åˆ\n",
      "\n",
      "================================================================================\n",
      "ã€ç¬¬ä¸‰éƒ¨åˆ†ã€‘Schema å®šä¹‰ (Schema Definition)\n",
      "================================================================================\n",
      "\n",
      "1ï¸âƒ£  åˆ›å»º Schema\n",
      "--------------------------------------------------------------------------------\n",
      "âœ“ å·²åˆ›å»ºç©º Schema\n",
      "\n",
      "2ï¸âƒ£  æ·»åŠ ä¸»é”®å­—æ®µ (Primary Key)\n",
      "--------------------------------------------------------------------------------\n",
      "âœ“ å·²æ·»åŠ  INT64 ç±»å‹ä¸»é”®å­—æ®µ 'id'\n",
      "\n",
      "3ï¸âƒ£  æ·»åŠ å‘é‡å­—æ®µ (Vector Fields)\n",
      "--------------------------------------------------------------------------------\n",
      "âœ“ å·²æ·»åŠ  FLOAT_VECTOR å­—æ®µ 'text_embedding' (ç»´åº¦=768)\n",
      "âœ“ å·²æ·»åŠ  BINARY_VECTOR å­—æ®µ 'image_embedding' (ç»´åº¦=256)\n",
      "\n",
      "4ï¸âƒ£  æ·»åŠ æ ‡é‡å­—æ®µ (Scalar Fields)\n",
      "--------------------------------------------------------------------------------\n",
      "âœ“ å·²æ·»åŠ  VARCHAR å­—æ®µ 'title' (æœ€å¤§é•¿åº¦=200)\n",
      "âœ“ å·²æ·»åŠ  INT32 å­—æ®µ 'score'\n",
      "âœ“ å·²æ·»åŠ  DOUBLE å­—æ®µ 'price'\n",
      "âœ“ å·²æ·»åŠ  BOOL å­—æ®µ 'is_active'\n",
      "âœ“ å·²æ·»åŠ  JSON å­—æ®µ 'metadata'\n",
      "âœ“ å·²æ·»åŠ  ARRAY å­—æ®µ 'tags' (å®¹é‡=10)\n",
      "\n",
      "5ï¸âƒ£  ä½¿ç”¨ Schema åˆ›å»ºé›†åˆ\n",
      "--------------------------------------------------------------------------------\n",
      "âœ“ å·²ä½¿ç”¨è‡ªå®šä¹‰ Schema åˆ›å»ºé›†åˆ 'demo_schema_collection'\n",
      "\n",
      "6ï¸âƒ£  æŸ¥çœ‹é›†åˆè¯¦æƒ…\n",
      "--------------------------------------------------------------------------------\n",
      "é›†åˆ 'demo_schema_collection' çš„å­—æ®µ:\n",
      "  - id: 5 (ä¸»é”®)\n",
      "  - text_embedding: 101 \n",
      "  - image_embedding: 100 \n",
      "  - title: 21 \n",
      "  - score: 4 \n",
      "  - price: 11 \n",
      "  - is_active: 1 \n",
      "  - metadata: 23 \n",
      "  - tags: 22 \n",
      "\n",
      "âœ“ å·²æ¸…ç†æ¼”ç¤ºé›†åˆ\n",
      "\n",
      "================================================================================\n",
      "ã€ç¬¬å››éƒ¨åˆ†ã€‘å®ä½“æ“ä½œ (Entity Operations)\n",
      "================================================================================\n",
      "\n",
      "1ï¸âƒ£  åˆ›å»ºé›†åˆ\n",
      "--------------------------------------------------------------------------------\n",
      "âœ“ é›†åˆ 'demo_entity_collection' åˆ›å»ºæˆåŠŸ (ç»´åº¦=5)\n",
      "\n",
      "2ï¸âƒ£  æ’å…¥å®ä½“ (Insert)\n",
      "--------------------------------------------------------------------------------\n",
      "âœ“ å·²æ’å…¥ 10 æ¡å®ä½“\n",
      "  æ’å…¥çš„ ID èŒƒå›´: [0, 1, 2]...9\n",
      "\n",
      "3ï¸âƒ£  æ›´æ–°å®ä½“ (Upsert)\n",
      "--------------------------------------------------------------------------------\n",
      "âœ“ å·²æ›´æ–° 2 æ¡å®ä½“ (ID: [0, 1])\n",
      "\n",
      "4ï¸âƒ£  åˆ·æ–°å’ŒåŠ è½½é›†åˆ\n",
      "--------------------------------------------------------------------------------\n",
      "âœ“ å·²åˆ·æ–°é›†åˆï¼ˆæ•°æ®æŒä¹…åŒ–åˆ°ç£ç›˜ï¼‰\n",
      "âœ“ å·²åŠ è½½é›†åˆåˆ°å†…å­˜\n",
      "\n",
      "5ï¸âƒ£  æŸ¥è¯¢å®ä½“ (Query)\n",
      "--------------------------------------------------------------------------------\n",
      "æŸ¥è¯¢ç»“æœ (ID in [0,1,2]):\n",
      "  - ID: 0, Color: updated_color_0\n",
      "  - ID: 1, Color: updated_color_1\n",
      "  - ID: 2, Color: color_2\n",
      "\n",
      "6ï¸âƒ£  å‘é‡æ£€ç´¢ (Vector Search)\n",
      "--------------------------------------------------------------------------------\n",
      "Top-3 æœ€ç›¸ä¼¼çš„å®ä½“:\n",
      "  1. ID: 0, Color: updated_color_0, è·ç¦»: 0.9826\n",
      "  2. ID: 7, Color: color_7, è·ç¦»: 0.9125\n",
      "  3. ID: 8, Color: color_8, è·ç¦»: 0.9011\n",
      "\n",
      "7ï¸âƒ£  æ··åˆæ£€ç´¢ (Hybrid Search)\n",
      "--------------------------------------------------------------------------------\n",
      "Top-3 æœ€ç›¸ä¼¼çš„å®ä½“ (ID > 5):\n",
      "  1. ID: 7, Color: color_7, è·ç¦»: 0.9125\n",
      "  2. ID: 8, Color: color_8, è·ç¦»: 0.9011\n",
      "  3. ID: 9, Color: color_9, è·ç¦»: 0.8089\n",
      "\n",
      "8ï¸âƒ£  åˆ é™¤å®ä½“ (Delete)\n",
      "--------------------------------------------------------------------------------\n",
      "âœ“ å·²åˆ é™¤å®ä½“ (ID: [0, 1])\n",
      "éªŒè¯åˆ é™¤åæŸ¥è¯¢ç»“æœ: [0, 1, 2]\n",
      "\n",
      "9ï¸âƒ£  é›†åˆç»Ÿè®¡ä¿¡æ¯\n",
      "--------------------------------------------------------------------------------\n",
      "é›†åˆç»Ÿè®¡:\n",
      "  - æ€»å®ä½“æ•°: 12\n",
      "\n",
      "âœ“ å·²æ¸…ç†æ¼”ç¤ºé›†åˆ\n",
      "\n",
      "ğŸ§¹ æ¸…ç†æ¼”ç¤ºæ•°æ®åº“...\n",
      "âœ“ å·²åˆ é™¤ demo_db_1\n",
      "âœ“ å·²åˆ é™¤ demo_db_2\n",
      "\n",
      "================================================================================\n",
      "ã€Milvus æ ¸å¿ƒæ¦‚å¿µæ€»ç»“ã€‘\n",
      "================================================================================\n",
      "\n",
      "ğŸ“š æ ¸å¿ƒæ¦‚å¿µå±‚çº§:\n",
      "  Database (æ•°æ®åº“)\n",
      "    â””â”€â”€ Collection (é›†åˆ)\n",
      "          â”œâ”€â”€ Schema (æ¨¡å¼å®šä¹‰)\n",
      "          â”‚     â”œâ”€â”€ Primary Field (ä¸»é”®å­—æ®µ)\n",
      "          â”‚     â”œâ”€â”€ Vector Field (å‘é‡å­—æ®µ)\n",
      "          â”‚     â””â”€â”€ Scalar Field (æ ‡é‡å­—æ®µ)\n",
      "          â”œâ”€â”€ Partition (åˆ†åŒº)\n",
      "          â”œâ”€â”€ Alias (åˆ«å)\n",
      "          â””â”€â”€ Entity (å®ä½“/æ•°æ®)\n",
      "\n",
      "ğŸ”‘ å…³é”®æ“ä½œ:\n",
      "  1. Database: å¤šç§Ÿæˆ·éš”ç¦»ã€èµ„æºç®¡ç†\n",
      "  2. Collection: æ•°æ®å®¹å™¨ã€Schema å®šä¹‰\n",
      "  3. Schema: å­—æ®µç±»å‹ã€çº¦æŸæ¡ä»¶\n",
      "  4. Entity: CRUD æ“ä½œã€å‘é‡æ£€ç´¢\n",
      "\n",
      "ğŸ’¡ æœ€ä½³å®è·µ:\n",
      "  - åˆç†è§„åˆ’ Database å’Œ Collection ç»“æ„\n",
      "  - æ ¹æ®ä¸šåŠ¡éœ€æ±‚è®¾è®¡ Schema\n",
      "  - ä½¿ç”¨ Partition ä¼˜åŒ–å¤§è§„æ¨¡æ•°æ®æŸ¥è¯¢\n",
      "  - åˆ©ç”¨ Alias å®ç°ç°åº¦å‘å¸ƒå’Œç‰ˆæœ¬ç®¡ç†\n",
      "  - å®šæœŸåˆ·æ–°(flush)ä¿è¯æ•°æ®æŒä¹…åŒ–\n",
      "  - æŸ¥è¯¢å‰ç¡®ä¿ Collection å·²åŠ è½½åˆ°å†…å­˜\n",
      "            \n",
      "\n",
      "================================================================================\n",
      "âœ“ æ‰€æœ‰æ¼”ç¤ºå®Œæˆï¼\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Milvus å‘é‡æ•°æ®åº“å®Œæ•´æ“ä½œæŒ‡å—\n",
    "\n",
    "æœ¬æ–‡ä»¶æ•´åˆäº† Milvus çš„æ ¸å¿ƒåŠŸèƒ½æ¼”ç¤ºï¼š\n",
    "1. æ•°æ®åº“ç®¡ç† (Database Management)\n",
    "2. é›†åˆç®¡ç† (Collection Management)\n",
    "3. Schema å®šä¹‰ (Schema Definition)\n",
    "4. å®ä½“æ“ä½œ (Entity Operations)\n",
    "\n",
    "å®‰è£…ä¾èµ–ï¼š\n",
    "    pip install pymilvus\n",
    "\n",
    "å¯åŠ¨ Milvus æœåŠ¡ç«¯ï¼š\n",
    "    wget https://github.com/milvus-io/milvus/releases/download/v2.5.10/milvus-standalone-docker-compose.yml -O docker-compose.yml\n",
    "    sudo docker compose up -d\n",
    "\n",
    "æ£€æŸ¥ç‰ˆæœ¬ï¼š\n",
    "    pip show pymilvus\n",
    "\"\"\"\n",
    "\n",
    "from pymilvus import MilvusClient, DataType\n",
    "from pymilvus.exceptions import MilvusException\n",
    "import random\n",
    "from typing import List, Dict, Any, Optional\n",
    "import time\n",
    "\n",
    "\n",
    "class MilvusManager:\n",
    "    \"\"\"\n",
    "    Milvus å‘é‡æ•°æ®åº“ç®¡ç†å™¨\n",
    "    \n",
    "    å°è£…äº† Milvus çš„å®Œæ•´æ“ä½œæµç¨‹ï¼š\n",
    "    - æ•°æ®åº“ CRUD\n",
    "    - é›†åˆ CRUD\n",
    "    - Schema å®šä¹‰\n",
    "    - å®ä½“ CRUD\n",
    "    - åˆ†åŒºç®¡ç†\n",
    "    - åˆ«åç®¡ç†\n",
    "    \n",
    "    å‚æ•°:\n",
    "        uri: Milvus æœåŠ¡åœ°å€ï¼Œé»˜è®¤ \"http://localhost:19530\"\n",
    "        token: è®¤è¯ä»¤ç‰Œï¼Œæ ¼å¼ \"ç”¨æˆ·å:å¯†ç \"ï¼Œé»˜è®¤ \"root:Milvus\"\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, uri: str = \"http://localhost:19530\", token: str = \"root:Milvus\"):\n",
    "        print(f\"ğŸ”§ æ­£åœ¨è¿æ¥ Milvus...\")\n",
    "        self.client = MilvusClient(uri=uri, token=token)\n",
    "        print(f\"âœ“ å·²è¿æ¥åˆ° Milvus (URI: {uri})\")\n",
    "    \n",
    "    # ========================================\n",
    "    # ç¬¬ä¸€éƒ¨åˆ†ï¼šæ•°æ®åº“ç®¡ç†\n",
    "    # ========================================\n",
    "    \n",
    "    def demo_database_operations(self):\n",
    "        \"\"\"æ¼”ç¤ºæ•°æ®åº“çš„å®Œæ•´æ“ä½œ\"\"\"\n",
    "        print(f\"\\n{'='*80}\")\n",
    "        print(\"ã€ç¬¬ä¸€éƒ¨åˆ†ã€‘æ•°æ®åº“ç®¡ç† (Database Management)\")\n",
    "        print(f\"{'='*80}\")\n",
    "        \n",
    "        # 1. åˆ›å»ºæ•°æ®åº“\n",
    "        print(f\"\\n1ï¸âƒ£  åˆ›å»ºæ•°æ®åº“\")\n",
    "        print(\"-\" * 80)\n",
    "        \n",
    "        # åˆ›å»ºåŸºæœ¬æ•°æ®åº“\n",
    "        try:\n",
    "            self.client.create_database(db_name=\"demo_db_1\")\n",
    "            print(\"âœ“ demo_db_1 åˆ›å»ºæˆåŠŸ\")\n",
    "        except MilvusException as e:\n",
    "            if \"already exist\" in str(e):\n",
    "                print(\"â„¹ demo_db_1 å·²å­˜åœ¨ï¼Œè·³è¿‡åˆ›å»º\")\n",
    "            else:\n",
    "                raise\n",
    "        \n",
    "        # åˆ›å»ºå¸¦å±æ€§çš„æ•°æ®åº“ï¼ˆè®¾ç½®å‰¯æœ¬æ•°ï¼‰\n",
    "        try:\n",
    "            self.client.create_database(\n",
    "                db_name=\"demo_db_2\",\n",
    "                properties={\"database.replica.number\": 2}\n",
    "            )\n",
    "            print(\"âœ“ demo_db_2 åˆ›å»ºæˆåŠŸ (å‰¯æœ¬æ•°=2)\")\n",
    "        except MilvusException as e:\n",
    "            if \"already exist\" in str(e):\n",
    "                print(\"â„¹ demo_db_2 å·²å­˜åœ¨ï¼Œè·³è¿‡åˆ›å»º\")\n",
    "            else:\n",
    "                raise\n",
    "        \n",
    "        # 2. åˆ—å‡ºæ‰€æœ‰æ•°æ®åº“\n",
    "        print(f\"\\n2ï¸âƒ£  åˆ—å‡ºæ‰€æœ‰æ•°æ®åº“\")\n",
    "        print(\"-\" * 80)\n",
    "        db_list = self.client.list_databases()\n",
    "        print(f\"å½“å‰æ•°æ®åº“åˆ—è¡¨: {db_list}\")\n",
    "        \n",
    "        # 3. æŸ¥çœ‹æ•°æ®åº“è¯¦æƒ…\n",
    "        print(f\"\\n3ï¸âƒ£  æŸ¥çœ‹æ•°æ®åº“è¯¦æƒ…\")\n",
    "        print(\"-\" * 80)\n",
    "        default_info = self.client.describe_database(db_name=\"default\")\n",
    "        print(f\"é»˜è®¤æ•°æ®åº“è¯¦æƒ…: {default_info}\")\n",
    "        \n",
    "        # 4. ä¿®æ”¹æ•°æ®åº“å±æ€§\n",
    "        print(f\"\\n4ï¸âƒ£  ä¿®æ”¹æ•°æ®åº“å±æ€§\")\n",
    "        print(\"-\" * 80)\n",
    "        self.client.alter_database_properties(\n",
    "            db_name=\"demo_db_1\",\n",
    "            properties={\"database.max.collections\": 10}\n",
    "        )\n",
    "        print(\"âœ“ å·²ä¸º demo_db_1 é™åˆ¶æœ€å¤§é›†åˆæ•°ä¸º 10\")\n",
    "        \n",
    "        # 5. åˆ é™¤æ•°æ®åº“å±æ€§\n",
    "        print(f\"\\n5ï¸âƒ£  åˆ é™¤æ•°æ®åº“å±æ€§\")\n",
    "        print(\"-\" * 80)\n",
    "        self.client.drop_database_properties(\n",
    "            db_name=\"demo_db_1\",\n",
    "            property_keys=[\"database.max.collections\"]\n",
    "        )\n",
    "        print(\"âœ“ å·²ç§»é™¤ demo_db_1 çš„æœ€å¤§é›†åˆæ•°é™åˆ¶\")\n",
    "        \n",
    "        # 6. åˆ‡æ¢æ•°æ®åº“\n",
    "        print(f\"\\n6ï¸âƒ£  åˆ‡æ¢å½“å‰æ•°æ®åº“\")\n",
    "        print(\"-\" * 80)\n",
    "        self.client.use_database(db_name=\"demo_db_1\")\n",
    "        print(\"âœ“ å·²åˆ‡æ¢åˆ° demo_db_1\")\n",
    "        \n",
    "        # åˆ‡æ¢å›é»˜è®¤æ•°æ®åº“\n",
    "        self.client.use_database(db_name=\"default\")\n",
    "        print(\"âœ“ å·²åˆ‡æ¢å› default æ•°æ®åº“\")\n",
    "    \n",
    "    def cleanup_databases(self):\n",
    "        \"\"\"æ¸…ç†æ¼”ç¤ºæ•°æ®åº“\"\"\"\n",
    "        print(f\"\\nğŸ§¹ æ¸…ç†æ¼”ç¤ºæ•°æ®åº“...\")\n",
    "        for db_name in [\"demo_db_1\", \"demo_db_2\"]:\n",
    "            try:\n",
    "                self.client.drop_database(db_name=db_name)\n",
    "                print(f\"âœ“ å·²åˆ é™¤ {db_name}\")\n",
    "            except Exception as e:\n",
    "                print(f\"âš ï¸  åˆ é™¤ {db_name} å¤±è´¥: {e}\")\n",
    "    \n",
    "    # ========================================\n",
    "    # ç¬¬äºŒéƒ¨åˆ†ï¼šé›†åˆç®¡ç†\n",
    "    # ========================================\n",
    "    \n",
    "    def demo_collection_operations(self):\n",
    "        \"\"\"æ¼”ç¤ºé›†åˆçš„å®Œæ•´æ“ä½œ\"\"\"\n",
    "        print(f\"\\n{'='*80}\")\n",
    "        print(\"ã€ç¬¬äºŒéƒ¨åˆ†ã€‘é›†åˆç®¡ç† (Collection Management)\")\n",
    "        print(f\"{'='*80}\")\n",
    "        \n",
    "        collection_name = \"demo_collection\"\n",
    "        \n",
    "        # 1. åˆ›å»ºé›†åˆï¼ˆå¿«é€Ÿæ¨¡å¼ï¼‰\n",
    "        print(f\"\\n1ï¸âƒ£  åˆ›å»ºé›†åˆ (å¿«é€Ÿæ¨¡å¼)\")\n",
    "        print(\"-\" * 80)\n",
    "        \n",
    "        if collection_name in self.client.list_collections():\n",
    "            self.client.drop_collection(collection_name=collection_name)\n",
    "            print(f\"âœ“ å·²åˆ é™¤å·²å­˜åœ¨çš„é›†åˆ {collection_name}\")\n",
    "        \n",
    "        self.client.create_collection(\n",
    "            collection_name=collection_name,\n",
    "            dimension=128  # å‘é‡ç»´åº¦\n",
    "        )\n",
    "        print(f\"âœ“ é›†åˆ {collection_name} åˆ›å»ºæˆåŠŸ (ç»´åº¦=128)\")\n",
    "        \n",
    "        # 2. åˆ—å‡ºæ‰€æœ‰é›†åˆ\n",
    "        print(f\"\\n2ï¸âƒ£  åˆ—å‡ºæ‰€æœ‰é›†åˆ\")\n",
    "        print(\"-\" * 80)\n",
    "        collections = self.client.list_collections()\n",
    "        print(f\"å½“å‰é›†åˆåˆ—è¡¨: {collections}\")\n",
    "        \n",
    "        # 3. æŸ¥çœ‹é›†åˆè¯¦æƒ…\n",
    "        print(f\"\\n3ï¸âƒ£  æŸ¥çœ‹é›†åˆè¯¦æƒ…\")\n",
    "        print(\"-\" * 80)\n",
    "        info = self.client.describe_collection(collection_name=collection_name)\n",
    "        print(f\"é›†åˆè¯¦æƒ…:\")\n",
    "        print(f\"  - é›†åˆå: {info.get('collection_name')}\")\n",
    "        print(f\"  - å­—æ®µæ•°: {len(info.get('fields', []))}\")\n",
    "        \n",
    "        # 4. é‡å‘½åé›†åˆ\n",
    "        print(f\"\\n4ï¸âƒ£  é‡å‘½åé›†åˆ\")\n",
    "        print(\"-\" * 80)\n",
    "        new_name = \"demo_collection_renamed\"\n",
    "        \n",
    "        if new_name in self.client.list_collections():\n",
    "            self.client.drop_collection(collection_name=new_name)\n",
    "        \n",
    "        self.client.rename_collection(\n",
    "            old_name=collection_name,\n",
    "            new_name=new_name\n",
    "        )\n",
    "        print(f\"âœ“ é›†åˆå·²é‡å‘½å: {collection_name} -> {new_name}\")\n",
    "        collection_name = new_name\n",
    "        \n",
    "        # 5. ä¿®æ”¹é›†åˆå±æ€§ï¼ˆè®¾ç½® TTLï¼‰\n",
    "        print(f\"\\n5ï¸âƒ£  ä¿®æ”¹é›†åˆå±æ€§\")\n",
    "        print(\"-\" * 80)\n",
    "        self.client.alter_collection_properties(\n",
    "            collection_name=collection_name,\n",
    "            properties={\"collection.ttl.seconds\": 3600}\n",
    "        )\n",
    "        print(f\"âœ“ å·²ä¸º {collection_name} è®¾ç½® TTL=3600ç§’ (1å°æ—¶)\")\n",
    "        \n",
    "        # 6. åˆ é™¤é›†åˆå±æ€§\n",
    "        print(f\"\\n6ï¸âƒ£  åˆ é™¤é›†åˆå±æ€§\")\n",
    "        print(\"-\" * 80)\n",
    "        self.client.drop_collection_properties(\n",
    "            collection_name=collection_name,\n",
    "            property_keys=[\"collection.ttl.seconds\"]\n",
    "        )\n",
    "        print(f\"âœ“ å·²åˆ é™¤ {collection_name} çš„ TTL å±æ€§\")\n",
    "        \n",
    "        # 7. åŠ è½½å’Œé‡Šæ”¾é›†åˆ\n",
    "        print(f\"\\n7ï¸âƒ£  åŠ è½½å’Œé‡Šæ”¾é›†åˆ\")\n",
    "        print(\"-\" * 80)\n",
    "        \n",
    "        self.client.load_collection(collection_name=collection_name)\n",
    "        state = self.client.get_load_state(collection_name=collection_name)\n",
    "        print(f\"åŠ è½½çŠ¶æ€: {state}\")\n",
    "        \n",
    "        self.client.release_collection(collection_name=collection_name)\n",
    "        state = self.client.get_load_state(collection_name=collection_name)\n",
    "        print(f\"é‡Šæ”¾åçŠ¶æ€: {state}\")\n",
    "        \n",
    "        # 8. åˆ†åŒºç®¡ç†\n",
    "        print(f\"\\n8ï¸âƒ£  åˆ†åŒºç®¡ç† (Partition Management)\")\n",
    "        print(\"-\" * 80)\n",
    "        \n",
    "        # åˆ—å‡ºåˆ†åŒº\n",
    "        partitions = self.client.list_partitions(collection_name=collection_name)\n",
    "        print(f\"åˆå§‹åˆ†åŒºåˆ—è¡¨: {partitions}\")\n",
    "        \n",
    "        # åˆ›å»ºåˆ†åŒº\n",
    "        partition_name = \"demo_partition\"\n",
    "        self.client.create_partition(\n",
    "            collection_name=collection_name,\n",
    "            partition_name=partition_name\n",
    "        )\n",
    "        print(f\"âœ“ å·²åˆ›å»ºåˆ†åŒº {partition_name}\")\n",
    "        \n",
    "        # æ£€æŸ¥åˆ†åŒºæ˜¯å¦å­˜åœ¨\n",
    "        exists = self.client.has_partition(\n",
    "            collection_name=collection_name,\n",
    "            partition_name=partition_name\n",
    "        )\n",
    "        print(f\"åˆ†åŒº {partition_name} å­˜åœ¨: {exists}\")\n",
    "        \n",
    "        # åŠ è½½åˆ†åŒº\n",
    "        self.client.load_partitions(\n",
    "            collection_name=collection_name,\n",
    "            partition_names=[partition_name]\n",
    "        )\n",
    "        print(f\"âœ“ å·²åŠ è½½åˆ†åŒº {partition_name}\")\n",
    "        \n",
    "        # é‡Šæ”¾åˆ†åŒº\n",
    "        self.client.release_partitions(\n",
    "            collection_name=collection_name,\n",
    "            partition_names=[partition_name]\n",
    "        )\n",
    "        print(f\"âœ“ å·²é‡Šæ”¾åˆ†åŒº {partition_name}\")\n",
    "        \n",
    "        # åˆ é™¤åˆ†åŒº\n",
    "        self.client.drop_partition(\n",
    "            collection_name=collection_name,\n",
    "            partition_name=partition_name\n",
    "        )\n",
    "        print(f\"âœ“ å·²åˆ é™¤åˆ†åŒº {partition_name}\")\n",
    "        \n",
    "        # 9. åˆ«åç®¡ç†\n",
    "        print(f\"\\n9ï¸âƒ£  åˆ«åç®¡ç† (Alias Management)\")\n",
    "        print(\"-\" * 80)\n",
    "        \n",
    "        # åˆ›å»ºåˆ«å\n",
    "        alias1 = \"demo_alias_1\"\n",
    "        alias2 = \"demo_alias_2\"\n",
    "        \n",
    "        self.client.create_alias(collection_name=collection_name, alias=alias1)\n",
    "        self.client.create_alias(collection_name=collection_name, alias=alias2)\n",
    "        print(f\"âœ“ å·²åˆ›å»ºåˆ«å: {alias1}, {alias2}\")\n",
    "        \n",
    "        # åˆ—å‡ºåˆ«å\n",
    "        aliases = self.client.list_aliases(collection_name=collection_name)\n",
    "        print(f\"å½“å‰åˆ«ååˆ—è¡¨: {aliases}\")\n",
    "        \n",
    "        # æŸ¥çœ‹åˆ«åè¯¦æƒ…\n",
    "        desc = self.client.describe_alias(alias=alias1)\n",
    "        print(f\"åˆ«å {alias1} è¯¦æƒ…: {desc}\")\n",
    "        \n",
    "        # åˆ é™¤åˆ«å\n",
    "        self.client.drop_alias(alias=alias1)\n",
    "        print(f\"âœ“ å·²åˆ é™¤åˆ«å {alias1}\")\n",
    "        \n",
    "        # æ¸…ç†\n",
    "        self.client.drop_alias(alias=alias2)\n",
    "        self.client.drop_collection(collection_name=collection_name)\n",
    "        print(f\"\\nâœ“ å·²æ¸…ç†æ¼”ç¤ºé›†åˆ\")\n",
    "    \n",
    "    # ========================================\n",
    "    # ç¬¬ä¸‰éƒ¨åˆ†ï¼šSchema å®šä¹‰\n",
    "    # ========================================\n",
    "    \n",
    "    def demo_schema_definition(self):\n",
    "        \"\"\"æ¼”ç¤º Schema çš„å®šä¹‰å’Œä½¿ç”¨\"\"\"\n",
    "        print(f\"\\n{'='*80}\")\n",
    "        print(\"ã€ç¬¬ä¸‰éƒ¨åˆ†ã€‘Schema å®šä¹‰ (Schema Definition)\")\n",
    "        print(f\"{'='*80}\")\n",
    "        \n",
    "        # 1. åˆ›å»ºç©º Schema\n",
    "        print(f\"\\n1ï¸âƒ£  åˆ›å»º Schema\")\n",
    "        print(\"-\" * 80)\n",
    "        schema = MilvusClient.create_schema()\n",
    "        print(\"âœ“ å·²åˆ›å»ºç©º Schema\")\n",
    "        \n",
    "        # 2. æ·»åŠ ä¸»é”®å­—æ®µ\n",
    "        print(f\"\\n2ï¸âƒ£  æ·»åŠ ä¸»é”®å­—æ®µ (Primary Key)\")\n",
    "        print(\"-\" * 80)\n",
    "        \n",
    "        # INT64 ä¸»é”®\n",
    "        schema.add_field(\n",
    "            field_name=\"id\",\n",
    "            datatype=DataType.INT64,\n",
    "            is_primary=True,  # è®¾ç½®ä¸ºä¸»é”®\n",
    "            auto_id=False     # æ‰‹åŠ¨æŒ‡å®š ID\n",
    "        )\n",
    "        print(\"âœ“ å·²æ·»åŠ  INT64 ç±»å‹ä¸»é”®å­—æ®µ 'id'\")\n",
    "        \n",
    "        # 3. æ·»åŠ å‘é‡å­—æ®µ\n",
    "        print(f\"\\n3ï¸âƒ£  æ·»åŠ å‘é‡å­—æ®µ (Vector Fields)\")\n",
    "        print(\"-\" * 80)\n",
    "        \n",
    "        # å¯†é›†æµ®ç‚¹å‘é‡\n",
    "        schema.add_field(\n",
    "            field_name=\"text_embedding\",\n",
    "            datatype=DataType.FLOAT_VECTOR,\n",
    "            dim=768  # å‘é‡ç»´åº¦\n",
    "        )\n",
    "        print(\"âœ“ å·²æ·»åŠ  FLOAT_VECTOR å­—æ®µ 'text_embedding' (ç»´åº¦=768)\")\n",
    "        \n",
    "        # äºŒè¿›åˆ¶å‘é‡\n",
    "        schema.add_field(\n",
    "            field_name=\"image_embedding\",\n",
    "            datatype=DataType.BINARY_VECTOR,\n",
    "            dim=256  # ç»´åº¦å¿…é¡»æ˜¯ 8 çš„å€æ•°\n",
    "        )\n",
    "        print(\"âœ“ å·²æ·»åŠ  BINARY_VECTOR å­—æ®µ 'image_embedding' (ç»´åº¦=256)\")\n",
    "        \n",
    "        # 4. æ·»åŠ æ ‡é‡å­—æ®µ\n",
    "        print(f\"\\n4ï¸âƒ£  æ·»åŠ æ ‡é‡å­—æ®µ (Scalar Fields)\")\n",
    "        print(\"-\" * 80)\n",
    "        \n",
    "        # å­—ç¬¦ä¸²å­—æ®µ\n",
    "        schema.add_field(\n",
    "            field_name=\"title\",\n",
    "            datatype=DataType.VARCHAR,\n",
    "            max_length=200,\n",
    "            is_nullable=True,\n",
    "            default_value=\"untitled\"\n",
    "        )\n",
    "        print(\"âœ“ å·²æ·»åŠ  VARCHAR å­—æ®µ 'title' (æœ€å¤§é•¿åº¦=200)\")\n",
    "        \n",
    "        # æ•´æ•°å­—æ®µ\n",
    "        schema.add_field(\n",
    "            field_name=\"score\",\n",
    "            datatype=DataType.INT32,\n",
    "            is_nullable=False\n",
    "        )\n",
    "        print(\"âœ“ å·²æ·»åŠ  INT32 å­—æ®µ 'score'\")\n",
    "        \n",
    "        # åŒç²¾åº¦æµ®ç‚¹æ•°å­—æ®µ\n",
    "        schema.add_field(\n",
    "            field_name=\"price\",\n",
    "            datatype=DataType.DOUBLE,\n",
    "            default_value=0.0\n",
    "        )\n",
    "        print(\"âœ“ å·²æ·»åŠ  DOUBLE å­—æ®µ 'price'\")\n",
    "        \n",
    "        # å¸ƒå°”å­—æ®µ\n",
    "        schema.add_field(\n",
    "            field_name=\"is_active\",\n",
    "            datatype=DataType.BOOL,\n",
    "            default_value=True\n",
    "        )\n",
    "        print(\"âœ“ å·²æ·»åŠ  BOOL å­—æ®µ 'is_active'\")\n",
    "        \n",
    "        # JSON å­—æ®µ\n",
    "        schema.add_field(\n",
    "            field_name=\"metadata\",\n",
    "            datatype=DataType.JSON\n",
    "        )\n",
    "        print(\"âœ“ å·²æ·»åŠ  JSON å­—æ®µ 'metadata'\")\n",
    "        \n",
    "        # æ•°ç»„å­—æ®µ\n",
    "        schema.add_field(\n",
    "            field_name=\"tags\",\n",
    "            datatype=DataType.ARRAY,\n",
    "            element_type=DataType.VARCHAR,\n",
    "            max_capacity=10,\n",
    "            max_length=50\n",
    "        )\n",
    "        print(\"âœ“ å·²æ·»åŠ  ARRAY å­—æ®µ 'tags' (å®¹é‡=10)\")\n",
    "        \n",
    "        # 5. ä½¿ç”¨ Schema åˆ›å»ºé›†åˆ\n",
    "        print(f\"\\n5ï¸âƒ£  ä½¿ç”¨ Schema åˆ›å»ºé›†åˆ\")\n",
    "        print(\"-\" * 80)\n",
    "        \n",
    "        collection_name = \"demo_schema_collection\"\n",
    "        \n",
    "        if collection_name in self.client.list_collections():\n",
    "            self.client.drop_collection(collection_name=collection_name)\n",
    "        \n",
    "        self.client.create_collection(\n",
    "            collection_name=collection_name,\n",
    "            schema=schema\n",
    "        )\n",
    "        print(f\"âœ“ å·²ä½¿ç”¨è‡ªå®šä¹‰ Schema åˆ›å»ºé›†åˆ '{collection_name}'\")\n",
    "        \n",
    "        # 6. æŸ¥çœ‹é›†åˆè¯¦æƒ…\n",
    "        print(f\"\\n6ï¸âƒ£  æŸ¥çœ‹é›†åˆè¯¦æƒ…\")\n",
    "        print(\"-\" * 80)\n",
    "        info = self.client.describe_collection(collection_name=collection_name)\n",
    "        print(f\"é›†åˆ '{collection_name}' çš„å­—æ®µ:\")\n",
    "        for field in info.get('fields', []):\n",
    "            print(f\"  - {field.get('name')}: {field.get('type')} \"\n",
    "                  f\"{'(ä¸»é”®)' if field.get('is_primary') else ''}\")\n",
    "        \n",
    "        # æ¸…ç†\n",
    "        self.client.drop_collection(collection_name=collection_name)\n",
    "        print(f\"\\nâœ“ å·²æ¸…ç†æ¼”ç¤ºé›†åˆ\")\n",
    "    \n",
    "    # ========================================\n",
    "    # ç¬¬å››éƒ¨åˆ†ï¼šå®ä½“æ“ä½œ\n",
    "    # ========================================\n",
    "    \n",
    "    def demo_entity_operations(self):\n",
    "        \"\"\"æ¼”ç¤ºå®ä½“çš„ CRUD æ“ä½œ\"\"\"\n",
    "        print(f\"\\n{'='*80}\")\n",
    "        print(\"ã€ç¬¬å››éƒ¨åˆ†ã€‘å®ä½“æ“ä½œ (Entity Operations)\")\n",
    "        print(f\"{'='*80}\")\n",
    "        \n",
    "        collection_name = \"demo_entity_collection\"\n",
    "        \n",
    "        # 1. åˆ›å»ºé›†åˆ\n",
    "        print(f\"\\n1ï¸âƒ£  åˆ›å»ºé›†åˆ\")\n",
    "        print(\"-\" * 80)\n",
    "        \n",
    "        if collection_name in self.client.list_collections():\n",
    "            self.client.drop_collection(collection_name=collection_name)\n",
    "        \n",
    "        self.client.create_collection(\n",
    "            collection_name=collection_name,\n",
    "            dimension=5,  # å‘é‡ç»´åº¦\n",
    "            primary_field_name=\"id\",\n",
    "            vector_field_name=\"vector\",\n",
    "            id_type=\"int\"\n",
    "        )\n",
    "        print(f\"âœ“ é›†åˆ '{collection_name}' åˆ›å»ºæˆåŠŸ (ç»´åº¦=5)\")\n",
    "        \n",
    "        # 2. æ’å…¥å®ä½“\n",
    "        print(f\"\\n2ï¸âƒ£  æ’å…¥å®ä½“ (Insert)\")\n",
    "        print(\"-\" * 80)\n",
    "        \n",
    "        # ç”Ÿæˆç¤ºä¾‹æ•°æ®\n",
    "        data = [\n",
    "            {\n",
    "                \"id\": i,\n",
    "                \"vector\": [random.random() for _ in range(5)],\n",
    "                \"color\": f\"color_{i}\"\n",
    "            }\n",
    "            for i in range(10)\n",
    "        ]\n",
    "        \n",
    "        res = self.client.insert(\n",
    "            collection_name=collection_name,\n",
    "            data=data\n",
    "        )\n",
    "        print(f\"âœ“ å·²æ’å…¥ {res['insert_count']} æ¡å®ä½“\")\n",
    "        print(f\"  æ’å…¥çš„ ID èŒƒå›´: {res['ids'][:3]}...{res['ids'][-1]}\")\n",
    "        \n",
    "        # 3. æ›´æ–°å®ä½“ï¼ˆUpsertï¼‰\n",
    "        print(f\"\\n3ï¸âƒ£  æ›´æ–°å®ä½“ (Upsert)\")\n",
    "        print(\"-\" * 80)\n",
    "        \n",
    "        update_data = [\n",
    "            {\n",
    "                \"id\": 0,\n",
    "                \"vector\": [random.random() for _ in range(5)],\n",
    "                \"color\": \"updated_color_0\"\n",
    "            },\n",
    "            {\n",
    "                \"id\": 1,\n",
    "                \"vector\": [random.random() for _ in range(5)],\n",
    "                \"color\": \"updated_color_1\"\n",
    "            }\n",
    "        ]\n",
    "        \n",
    "        res = self.client.upsert(\n",
    "            collection_name=collection_name,\n",
    "            data=update_data\n",
    "        )\n",
    "        print(f\"âœ“ å·²æ›´æ–° {res['upsert_count']} æ¡å®ä½“ (ID: {res['ids']})\")\n",
    "        \n",
    "        # 4. åˆ·æ–°å’ŒåŠ è½½\n",
    "        print(f\"\\n4ï¸âƒ£  åˆ·æ–°å’ŒåŠ è½½é›†åˆ\")\n",
    "        print(\"-\" * 80)\n",
    "        \n",
    "        self.client.flush(collection_name=collection_name)\n",
    "        print(\"âœ“ å·²åˆ·æ–°é›†åˆï¼ˆæ•°æ®æŒä¹…åŒ–åˆ°ç£ç›˜ï¼‰\")\n",
    "        \n",
    "        self.client.load_collection(collection_name=collection_name)\n",
    "        print(\"âœ“ å·²åŠ è½½é›†åˆåˆ°å†…å­˜\")\n",
    "        \n",
    "        # 5. æŸ¥è¯¢å®ä½“\n",
    "        print(f\"\\n5ï¸âƒ£  æŸ¥è¯¢å®ä½“ (Query)\")\n",
    "        print(\"-\" * 80)\n",
    "        \n",
    "        # æŒ‰ ID æŸ¥è¯¢\n",
    "        res = self.client.query(\n",
    "            collection_name=collection_name,\n",
    "            filter=\"id in [0, 1, 2]\",\n",
    "            output_fields=[\"id\", \"color\"]\n",
    "        )\n",
    "        print(f\"æŸ¥è¯¢ç»“æœ (ID in [0,1,2]):\")\n",
    "        for entity in res:\n",
    "            print(f\"  - ID: {entity['id']}, Color: {entity['color']}\")\n",
    "        \n",
    "        # 6. å‘é‡æ£€ç´¢\n",
    "        print(f\"\\n6ï¸âƒ£  å‘é‡æ£€ç´¢ (Vector Search)\")\n",
    "        print(\"-\" * 80)\n",
    "        \n",
    "        # éšæœºæŸ¥è¯¢å‘é‡\n",
    "        query_vector = [random.random() for _ in range(5)]\n",
    "        \n",
    "        search_res = self.client.search(\n",
    "            collection_name=collection_name,\n",
    "            data=[query_vector],\n",
    "            limit=3,\n",
    "            output_fields=[\"id\", \"color\"]\n",
    "        )\n",
    "        \n",
    "        print(f\"Top-3 æœ€ç›¸ä¼¼çš„å®ä½“:\")\n",
    "        for hits in search_res:\n",
    "            for rank, hit in enumerate(hits, 1):\n",
    "                print(f\"  {rank}. ID: {hit['id']}, \"\n",
    "                      f\"Color: {hit['entity']['color']}, \"\n",
    "                      f\"è·ç¦»: {hit['distance']:.4f}\")\n",
    "        \n",
    "        # 7. æ··åˆæ£€ç´¢ï¼ˆå‘é‡ + è¿‡æ»¤ï¼‰\n",
    "        print(f\"\\n7ï¸âƒ£  æ··åˆæ£€ç´¢ (Hybrid Search)\")\n",
    "        print(\"-\" * 80)\n",
    "        \n",
    "        search_res = self.client.search(\n",
    "            collection_name=collection_name,\n",
    "            data=[query_vector],\n",
    "            filter=\"id > 5\",  # è¿‡æ»¤æ¡ä»¶\n",
    "            limit=3,\n",
    "            output_fields=[\"id\", \"color\"]\n",
    "        )\n",
    "        \n",
    "        print(f\"Top-3 æœ€ç›¸ä¼¼çš„å®ä½“ (ID > 5):\")\n",
    "        for hits in search_res:\n",
    "            for rank, hit in enumerate(hits, 1):\n",
    "                print(f\"  {rank}. ID: {hit['id']}, \"\n",
    "                      f\"Color: {hit['entity']['color']}, \"\n",
    "                      f\"è·ç¦»: {hit['distance']:.4f}\")\n",
    "        \n",
    "        # 8. åˆ é™¤å®ä½“\n",
    "        print(f\"\\n8ï¸âƒ£  åˆ é™¤å®ä½“ (Delete)\")\n",
    "        print(\"-\" * 80)\n",
    "        \n",
    "        res = self.client.delete(\n",
    "            collection_name=collection_name,\n",
    "            ids=[0, 1]\n",
    "        )\n",
    "        print(f\"âœ“ å·²åˆ é™¤å®ä½“ (ID: [0, 1])\")\n",
    "        \n",
    "        # éªŒè¯åˆ é™¤\n",
    "        res = self.client.query(\n",
    "            collection_name=collection_name,\n",
    "            filter=\"id in [0, 1, 2]\",\n",
    "            output_fields=[\"id\", \"color\"]\n",
    "        )\n",
    "        print(f\"éªŒè¯åˆ é™¤åæŸ¥è¯¢ç»“æœ: {[e['id'] for e in res]}\")\n",
    "        \n",
    "        # 9. ç»Ÿè®¡ä¿¡æ¯\n",
    "        print(f\"\\n9ï¸âƒ£  é›†åˆç»Ÿè®¡ä¿¡æ¯\")\n",
    "        print(\"-\" * 80)\n",
    "        \n",
    "        stats = self.client.get_collection_stats(collection_name=collection_name)\n",
    "        print(f\"é›†åˆç»Ÿè®¡:\")\n",
    "        print(f\"  - æ€»å®ä½“æ•°: {stats.get('row_count', 0)}\")\n",
    "        \n",
    "        # æ¸…ç†\n",
    "        self.client.drop_collection(collection_name=collection_name)\n",
    "        print(f\"\\nâœ“ å·²æ¸…ç†æ¼”ç¤ºé›†åˆ\")\n",
    "    \n",
    "    # ========================================\n",
    "    # ç»¼åˆæ¼”ç¤º\n",
    "    # ========================================\n",
    "    \n",
    "    def cleanup_before_demo(self):\n",
    "        \"\"\"æ¼”ç¤ºå‰æ¸…ç†ï¼Œç¡®ä¿ç¯å¢ƒå¹²å‡€\"\"\"\n",
    "        print(f\"\\nğŸ§¹ æ¸…ç†æ—§çš„æ¼”ç¤ºæ•°æ®...\")\n",
    "        \n",
    "        # æ¸…ç†æ—§çš„æ•°æ®åº“\n",
    "        for db_name in [\"demo_db_1\", \"demo_db_2\"]:\n",
    "            try:\n",
    "                if db_name in self.client.list_databases():\n",
    "                    self.client.drop_database(db_name=db_name)\n",
    "                    print(f\"  âœ“ å·²åˆ é™¤æ—§æ•°æ®åº“ {db_name}\")\n",
    "            except Exception as e:\n",
    "                print(f\"  âš ï¸  æ¸…ç† {db_name} æ—¶å‡ºé”™: {e}\")\n",
    "        \n",
    "        print(\"âœ“ æ¸…ç†å®Œæˆ\\n\")\n",
    "    \n",
    "    def run_complete_demo(self):\n",
    "        \"\"\"è¿è¡Œå®Œæ•´æ¼”ç¤º\"\"\"\n",
    "        print(\"=\"*80)\n",
    "        print(\"ğŸš€ Milvus å‘é‡æ•°æ®åº“å®Œæ•´æ“ä½œæ¼”ç¤º\")\n",
    "        print(\"=\"*80)\n",
    "        \n",
    "        try:\n",
    "            # æ¼”ç¤ºå‰æ¸…ç†\n",
    "            self.cleanup_before_demo()\n",
    "            # ç¬¬ä¸€éƒ¨åˆ†ï¼šæ•°æ®åº“ç®¡ç†\n",
    "            self.demo_database_operations()\n",
    "            \n",
    "            # ç¬¬äºŒéƒ¨åˆ†ï¼šé›†åˆç®¡ç†\n",
    "            self.demo_collection_operations()\n",
    "            \n",
    "            # ç¬¬ä¸‰éƒ¨åˆ†ï¼šSchema å®šä¹‰\n",
    "            self.demo_schema_definition()\n",
    "            \n",
    "            # ç¬¬å››éƒ¨åˆ†ï¼šå®ä½“æ“ä½œ\n",
    "            self.demo_entity_operations()\n",
    "            \n",
    "            # æ¸…ç†æ¼”ç¤ºæ•°æ®åº“\n",
    "            self.cleanup_databases()\n",
    "            \n",
    "            # æ€»ç»“\n",
    "            print(f\"\\n{'='*80}\")\n",
    "            print(\"ã€Milvus æ ¸å¿ƒæ¦‚å¿µæ€»ç»“ã€‘\")\n",
    "            print(f\"{'='*80}\")\n",
    "            print(\"\"\"\n",
    "ğŸ“š æ ¸å¿ƒæ¦‚å¿µå±‚çº§:\n",
    "  Database (æ•°æ®åº“)\n",
    "    â””â”€â”€ Collection (é›†åˆ)\n",
    "          â”œâ”€â”€ Schema (æ¨¡å¼å®šä¹‰)\n",
    "          â”‚     â”œâ”€â”€ Primary Field (ä¸»é”®å­—æ®µ)\n",
    "          â”‚     â”œâ”€â”€ Vector Field (å‘é‡å­—æ®µ)\n",
    "          â”‚     â””â”€â”€ Scalar Field (æ ‡é‡å­—æ®µ)\n",
    "          â”œâ”€â”€ Partition (åˆ†åŒº)\n",
    "          â”œâ”€â”€ Alias (åˆ«å)\n",
    "          â””â”€â”€ Entity (å®ä½“/æ•°æ®)\n",
    "\n",
    "ğŸ”‘ å…³é”®æ“ä½œ:\n",
    "  1. Database: å¤šç§Ÿæˆ·éš”ç¦»ã€èµ„æºç®¡ç†\n",
    "  2. Collection: æ•°æ®å®¹å™¨ã€Schema å®šä¹‰\n",
    "  3. Schema: å­—æ®µç±»å‹ã€çº¦æŸæ¡ä»¶\n",
    "  4. Entity: CRUD æ“ä½œã€å‘é‡æ£€ç´¢\n",
    "\n",
    "ğŸ’¡ æœ€ä½³å®è·µ:\n",
    "  - åˆç†è§„åˆ’ Database å’Œ Collection ç»“æ„\n",
    "  - æ ¹æ®ä¸šåŠ¡éœ€æ±‚è®¾è®¡ Schema\n",
    "  - ä½¿ç”¨ Partition ä¼˜åŒ–å¤§è§„æ¨¡æ•°æ®æŸ¥è¯¢\n",
    "  - åˆ©ç”¨ Alias å®ç°ç°åº¦å‘å¸ƒå’Œç‰ˆæœ¬ç®¡ç†\n",
    "  - å®šæœŸåˆ·æ–°(flush)ä¿è¯æ•°æ®æŒä¹…åŒ–\n",
    "  - æŸ¥è¯¢å‰ç¡®ä¿ Collection å·²åŠ è½½åˆ°å†…å­˜\n",
    "            \"\"\")\n",
    "            \n",
    "            print(f\"\\n{'='*80}\")\n",
    "            print(\"âœ“ æ‰€æœ‰æ¼”ç¤ºå®Œæˆï¼\")\n",
    "            print(f\"{'='*80}\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"\\nâŒ æ¼”ç¤ºè¿‡ç¨‹ä¸­å‡ºé”™: {e}\")\n",
    "            import traceback\n",
    "            traceback.print_exc()\n",
    "\n",
    "\n",
    "def main():\n",
    "    \"\"\"ä¸»å‡½æ•°\"\"\"\n",
    "    \n",
    "    # åˆ›å»º Milvus ç®¡ç†å™¨\n",
    "    try:\n",
    "        manager = MilvusManager(\n",
    "            uri=\"http://localhost:19530\",\n",
    "            token=\"root:Milvus\"\n",
    "        )\n",
    "        \n",
    "        # è¿è¡Œå®Œæ•´æ¼”ç¤º\n",
    "        manager.run_complete_demo()\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"\\nâŒ è¿æ¥ Milvus å¤±è´¥: {e}\")\n",
    "        print(\"\\nè¯·ç¡®ä¿:\")\n",
    "        print(\"  1. Milvus æœåŠ¡å·²å¯åŠ¨\")\n",
    "        print(\"  2. ç«¯å£ 19530 å¯è®¿é—®\")\n",
    "        print(\"  3. è®¤è¯ä¿¡æ¯æ­£ç¡®\")\n",
    "        print(\"\\nå¯åŠ¨å‘½ä»¤:\")\n",
    "        print(\"  wget https://github.com/milvus-io/milvus/releases/download/v2.5.10/milvus-standalone-docker-compose.yml -O docker-compose.yml\")\n",
    "        print(\"  sudo docker compose up -d\")\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bc05a2f",
   "metadata": {},
   "source": [
    "# ç´¢å¼•ä¼˜åŒ–"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "416834d2",
   "metadata": {},
   "source": [
    "## ä»å°å—åˆ°ä¸Šå¤§ä¸Šä¸‹æ–‡"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff3aa198",
   "metadata": {},
   "source": [
    "### èŠ‚ç‚¹å¥å­åä¸œçª—å£"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "183160f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== ä½¿ç”¨çª—å£è§£æå™¨çš„æ£€ç´¢ç»“æœ ===\n",
      "\n",
      "é—®é¢˜ï¼šæ¸¸æˆä¸­æ‚Ÿç©ºæœ‰å“ªäº›å½¢æ€å˜åŒ–ï¼Ÿ\n"
     ]
    },
    {
     "ename": "AuthenticationError",
     "evalue": "Error code: 401 - {'error': {'message': 'Authentication Fails, Your api key: ****bb4f is invalid', 'type': 'authentication_error', 'param': None, 'code': 'invalid_request_error'}}",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAuthenticationError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[20], line 75\u001b[0m\n\u001b[1;32m     73\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m question \u001b[38;5;129;01min\u001b[39;00m test_questions:\n\u001b[1;32m     74\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mé—®é¢˜ï¼š\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mquestion\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 75\u001b[0m     window_response \u001b[38;5;241m=\u001b[39m \u001b[43mwindow_query_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mquery\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquestion\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     76\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124må›ç­”ï¼š\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mwindow_response\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     78\u001b[0m     \u001b[38;5;66;03m# å±•ç¤ºæ£€ç´¢åˆ°çš„åŸå§‹å¥å­å’Œçª—å£å†…å®¹\u001b[39;00m\n",
      "File \u001b[0;32m~/Desktop/rag/rag-in-action/.venv/lib/python3.10/site-packages/llama_index_instrumentation/dispatcher.py:335\u001b[0m, in \u001b[0;36mDispatcher.span.<locals>.wrapper\u001b[0;34m(func, instance, args, kwargs)\u001b[0m\n\u001b[1;32m    332\u001b[0m             _logger\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFailed to reset active_span_id: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    334\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 335\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    336\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(result, asyncio\u001b[38;5;241m.\u001b[39mFuture):\n\u001b[1;32m    337\u001b[0m         \u001b[38;5;66;03m# If the result is a Future, wrap it\u001b[39;00m\n\u001b[1;32m    338\u001b[0m         new_future \u001b[38;5;241m=\u001b[39m asyncio\u001b[38;5;241m.\u001b[39mensure_future(result)\n",
      "File \u001b[0;32m~/Desktop/rag/rag-in-action/.venv/lib/python3.10/site-packages/llama_index/core/base/base_query_engine.py:44\u001b[0m, in \u001b[0;36mBaseQueryEngine.query\u001b[0;34m(self, str_or_query_bundle)\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(str_or_query_bundle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m     43\u001b[0m         str_or_query_bundle \u001b[38;5;241m=\u001b[39m QueryBundle(str_or_query_bundle)\n\u001b[0;32m---> 44\u001b[0m     query_result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_query\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstr_or_query_bundle\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     45\u001b[0m dispatcher\u001b[38;5;241m.\u001b[39mevent(\n\u001b[1;32m     46\u001b[0m     QueryEndEvent(query\u001b[38;5;241m=\u001b[39mstr_or_query_bundle, response\u001b[38;5;241m=\u001b[39mquery_result)\n\u001b[1;32m     47\u001b[0m )\n\u001b[1;32m     48\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m query_result\n",
      "File \u001b[0;32m~/Desktop/rag/rag-in-action/.venv/lib/python3.10/site-packages/llama_index_instrumentation/dispatcher.py:335\u001b[0m, in \u001b[0;36mDispatcher.span.<locals>.wrapper\u001b[0;34m(func, instance, args, kwargs)\u001b[0m\n\u001b[1;32m    332\u001b[0m             _logger\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFailed to reset active_span_id: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    334\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 335\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    336\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(result, asyncio\u001b[38;5;241m.\u001b[39mFuture):\n\u001b[1;32m    337\u001b[0m         \u001b[38;5;66;03m# If the result is a Future, wrap it\u001b[39;00m\n\u001b[1;32m    338\u001b[0m         new_future \u001b[38;5;241m=\u001b[39m asyncio\u001b[38;5;241m.\u001b[39mensure_future(result)\n",
      "File \u001b[0;32m~/Desktop/rag/rag-in-action/.venv/lib/python3.10/site-packages/llama_index/core/query_engine/retriever_query_engine.py:197\u001b[0m, in \u001b[0;36mRetrieverQueryEngine._query\u001b[0;34m(self, query_bundle)\u001b[0m\n\u001b[1;32m    193\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcallback_manager\u001b[38;5;241m.\u001b[39mevent(\n\u001b[1;32m    194\u001b[0m     CBEventType\u001b[38;5;241m.\u001b[39mQUERY, payload\u001b[38;5;241m=\u001b[39m{EventPayload\u001b[38;5;241m.\u001b[39mQUERY_STR: query_bundle\u001b[38;5;241m.\u001b[39mquery_str}\n\u001b[1;32m    195\u001b[0m ) \u001b[38;5;28;01mas\u001b[39;00m query_event:\n\u001b[1;32m    196\u001b[0m     nodes \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mretrieve(query_bundle)\n\u001b[0;32m--> 197\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_response_synthesizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msynthesize\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    198\u001b[0m \u001b[43m        \u001b[49m\u001b[43mquery\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mquery_bundle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    199\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnodes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnodes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    200\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    201\u001b[0m     query_event\u001b[38;5;241m.\u001b[39mon_end(payload\u001b[38;5;241m=\u001b[39m{EventPayload\u001b[38;5;241m.\u001b[39mRESPONSE: response})\n\u001b[1;32m    203\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "File \u001b[0;32m~/Desktop/rag/rag-in-action/.venv/lib/python3.10/site-packages/llama_index_instrumentation/dispatcher.py:335\u001b[0m, in \u001b[0;36mDispatcher.span.<locals>.wrapper\u001b[0;34m(func, instance, args, kwargs)\u001b[0m\n\u001b[1;32m    332\u001b[0m             _logger\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFailed to reset active_span_id: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    334\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 335\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    336\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(result, asyncio\u001b[38;5;241m.\u001b[39mFuture):\n\u001b[1;32m    337\u001b[0m         \u001b[38;5;66;03m# If the result is a Future, wrap it\u001b[39;00m\n\u001b[1;32m    338\u001b[0m         new_future \u001b[38;5;241m=\u001b[39m asyncio\u001b[38;5;241m.\u001b[39mensure_future(result)\n",
      "File \u001b[0;32m~/Desktop/rag/rag-in-action/.venv/lib/python3.10/site-packages/llama_index/core/response_synthesizers/base.py:235\u001b[0m, in \u001b[0;36mBaseSynthesizer.synthesize\u001b[0;34m(self, query, nodes, additional_source_nodes, **response_kwargs)\u001b[0m\n\u001b[1;32m    229\u001b[0m     query \u001b[38;5;241m=\u001b[39m QueryBundle(query_str\u001b[38;5;241m=\u001b[39mquery)\n\u001b[1;32m    231\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_callback_manager\u001b[38;5;241m.\u001b[39mevent(\n\u001b[1;32m    232\u001b[0m     CBEventType\u001b[38;5;241m.\u001b[39mSYNTHESIZE,\n\u001b[1;32m    233\u001b[0m     payload\u001b[38;5;241m=\u001b[39m{EventPayload\u001b[38;5;241m.\u001b[39mQUERY_STR: query\u001b[38;5;241m.\u001b[39mquery_str},\n\u001b[1;32m    234\u001b[0m ) \u001b[38;5;28;01mas\u001b[39;00m event:\n\u001b[0;32m--> 235\u001b[0m     response_str \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_response\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    236\u001b[0m \u001b[43m        \u001b[49m\u001b[43mquery_str\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mquery\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mquery_str\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    237\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtext_chunks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\n\u001b[1;32m    238\u001b[0m \u001b[43m            \u001b[49m\u001b[43mn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnode\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_content\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmetadata_mode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mMetadataMode\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mLLM\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mn\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mnodes\u001b[49m\n\u001b[1;32m    239\u001b[0m \u001b[43m        \u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    240\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mresponse_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    241\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    243\u001b[0m     additional_source_nodes \u001b[38;5;241m=\u001b[39m additional_source_nodes \u001b[38;5;129;01mor\u001b[39;00m []\n\u001b[1;32m    244\u001b[0m     source_nodes \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(nodes) \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mlist\u001b[39m(additional_source_nodes)\n",
      "File \u001b[0;32m~/Desktop/rag/rag-in-action/.venv/lib/python3.10/site-packages/llama_index_instrumentation/dispatcher.py:335\u001b[0m, in \u001b[0;36mDispatcher.span.<locals>.wrapper\u001b[0;34m(func, instance, args, kwargs)\u001b[0m\n\u001b[1;32m    332\u001b[0m             _logger\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFailed to reset active_span_id: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    334\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 335\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    336\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(result, asyncio\u001b[38;5;241m.\u001b[39mFuture):\n\u001b[1;32m    337\u001b[0m         \u001b[38;5;66;03m# If the result is a Future, wrap it\u001b[39;00m\n\u001b[1;32m    338\u001b[0m         new_future \u001b[38;5;241m=\u001b[39m asyncio\u001b[38;5;241m.\u001b[39mensure_future(result)\n",
      "File \u001b[0;32m~/Desktop/rag/rag-in-action/.venv/lib/python3.10/site-packages/llama_index/core/response_synthesizers/compact_and_refine.py:43\u001b[0m, in \u001b[0;36mCompactAndRefine.get_response\u001b[0;34m(self, query_str, text_chunks, prev_response, **response_kwargs)\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[38;5;66;03m# use prompt helper to fix compact text_chunks under the prompt limitation\u001b[39;00m\n\u001b[1;32m     40\u001b[0m \u001b[38;5;66;03m# TODO: This is a temporary fix - reason it's temporary is that\u001b[39;00m\n\u001b[1;32m     41\u001b[0m \u001b[38;5;66;03m# the refine template does not account for size of previous answer.\u001b[39;00m\n\u001b[1;32m     42\u001b[0m new_texts \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_compact_text_chunks(query_str, text_chunks)\n\u001b[0;32m---> 43\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_response\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     44\u001b[0m \u001b[43m    \u001b[49m\u001b[43mquery_str\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mquery_str\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     45\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtext_chunks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnew_texts\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     46\u001b[0m \u001b[43m    \u001b[49m\u001b[43mprev_response\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprev_response\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     47\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mresponse_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     48\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/rag/rag-in-action/.venv/lib/python3.10/site-packages/llama_index_instrumentation/dispatcher.py:335\u001b[0m, in \u001b[0;36mDispatcher.span.<locals>.wrapper\u001b[0;34m(func, instance, args, kwargs)\u001b[0m\n\u001b[1;32m    332\u001b[0m             _logger\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFailed to reset active_span_id: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    334\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 335\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    336\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(result, asyncio\u001b[38;5;241m.\u001b[39mFuture):\n\u001b[1;32m    337\u001b[0m         \u001b[38;5;66;03m# If the result is a Future, wrap it\u001b[39;00m\n\u001b[1;32m    338\u001b[0m         new_future \u001b[38;5;241m=\u001b[39m asyncio\u001b[38;5;241m.\u001b[39mensure_future(result)\n",
      "File \u001b[0;32m~/Desktop/rag/rag-in-action/.venv/lib/python3.10/site-packages/llama_index/core/response_synthesizers/refine.py:179\u001b[0m, in \u001b[0;36mRefine.get_response\u001b[0;34m(self, query_str, text_chunks, prev_response, **response_kwargs)\u001b[0m\n\u001b[1;32m    175\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m text_chunk \u001b[38;5;129;01min\u001b[39;00m text_chunks:\n\u001b[1;32m    176\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m prev_response \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    177\u001b[0m         \u001b[38;5;66;03m# if this is the first chunk, and text chunk already\u001b[39;00m\n\u001b[1;32m    178\u001b[0m         \u001b[38;5;66;03m# is an answer, then return it\u001b[39;00m\n\u001b[0;32m--> 179\u001b[0m         response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_give_response_single\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    180\u001b[0m \u001b[43m            \u001b[49m\u001b[43mquery_str\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtext_chunk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mresponse_kwargs\u001b[49m\n\u001b[1;32m    181\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    182\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    183\u001b[0m         \u001b[38;5;66;03m# refine response if possible\u001b[39;00m\n\u001b[1;32m    184\u001b[0m         response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_refine_response_single(\n\u001b[1;32m    185\u001b[0m             prev_response, query_str, text_chunk, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mresponse_kwargs\n\u001b[1;32m    186\u001b[0m         )\n",
      "File \u001b[0;32m~/Desktop/rag/rag-in-action/.venv/lib/python3.10/site-packages/llama_index/core/response_synthesizers/refine.py:241\u001b[0m, in \u001b[0;36mRefine._give_response_single\u001b[0;34m(self, query_str, text_chunk, **response_kwargs)\u001b[0m\n\u001b[1;32m    237\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m response \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_streaming:\n\u001b[1;32m    238\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    239\u001b[0m         structured_response \u001b[38;5;241m=\u001b[39m cast(\n\u001b[1;32m    240\u001b[0m             StructuredRefineResponse,\n\u001b[0;32m--> 241\u001b[0m             \u001b[43mprogram\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    242\u001b[0m \u001b[43m                \u001b[49m\u001b[43mcontext_str\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcur_text_chunk\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    243\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mresponse_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    244\u001b[0m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m,\n\u001b[1;32m    245\u001b[0m         )\n\u001b[1;32m    246\u001b[0m         query_satisfied \u001b[38;5;241m=\u001b[39m structured_response\u001b[38;5;241m.\u001b[39mquery_satisfied\n\u001b[1;32m    247\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m query_satisfied:\n",
      "File \u001b[0;32m~/Desktop/rag/rag-in-action/.venv/lib/python3.10/site-packages/llama_index_instrumentation/dispatcher.py:335\u001b[0m, in \u001b[0;36mDispatcher.span.<locals>.wrapper\u001b[0;34m(func, instance, args, kwargs)\u001b[0m\n\u001b[1;32m    332\u001b[0m             _logger\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFailed to reset active_span_id: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    334\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 335\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    336\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(result, asyncio\u001b[38;5;241m.\u001b[39mFuture):\n\u001b[1;32m    337\u001b[0m         \u001b[38;5;66;03m# If the result is a Future, wrap it\u001b[39;00m\n\u001b[1;32m    338\u001b[0m         new_future \u001b[38;5;241m=\u001b[39m asyncio\u001b[38;5;241m.\u001b[39mensure_future(result)\n",
      "File \u001b[0;32m~/Desktop/rag/rag-in-action/.venv/lib/python3.10/site-packages/llama_index/core/response_synthesizers/refine.py:85\u001b[0m, in \u001b[0;36mDefaultRefineProgram.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m     83\u001b[0m         answer \u001b[38;5;241m=\u001b[39m answer\u001b[38;5;241m.\u001b[39mmodel_dump_json()\n\u001b[1;32m     84\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 85\u001b[0m     answer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_llm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     86\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_prompt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     87\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     88\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     89\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m StructuredRefineResponse(answer\u001b[38;5;241m=\u001b[39manswer, query_satisfied\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m~/Desktop/rag/rag-in-action/.venv/lib/python3.10/site-packages/llama_index_instrumentation/dispatcher.py:335\u001b[0m, in \u001b[0;36mDispatcher.span.<locals>.wrapper\u001b[0;34m(func, instance, args, kwargs)\u001b[0m\n\u001b[1;32m    332\u001b[0m             _logger\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFailed to reset active_span_id: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    334\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 335\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    336\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(result, asyncio\u001b[38;5;241m.\u001b[39mFuture):\n\u001b[1;32m    337\u001b[0m         \u001b[38;5;66;03m# If the result is a Future, wrap it\u001b[39;00m\n\u001b[1;32m    338\u001b[0m         new_future \u001b[38;5;241m=\u001b[39m asyncio\u001b[38;5;241m.\u001b[39mensure_future(result)\n",
      "File \u001b[0;32m~/Desktop/rag/rag-in-action/.venv/lib/python3.10/site-packages/llama_index/core/llms/llm.py:623\u001b[0m, in \u001b[0;36mLLM.predict\u001b[0;34m(self, prompt, **prompt_args)\u001b[0m\n\u001b[1;32m    621\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmetadata\u001b[38;5;241m.\u001b[39mis_chat_model:\n\u001b[1;32m    622\u001b[0m     messages \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_messages(prompt, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mprompt_args)\n\u001b[0;32m--> 623\u001b[0m     chat_response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mchat\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    624\u001b[0m     output \u001b[38;5;241m=\u001b[39m chat_response\u001b[38;5;241m.\u001b[39mmessage\u001b[38;5;241m.\u001b[39mcontent \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    625\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/Desktop/rag/rag-in-action/.venv/lib/python3.10/site-packages/llama_index_instrumentation/dispatcher.py:335\u001b[0m, in \u001b[0;36mDispatcher.span.<locals>.wrapper\u001b[0;34m(func, instance, args, kwargs)\u001b[0m\n\u001b[1;32m    332\u001b[0m             _logger\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFailed to reset active_span_id: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    334\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 335\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    336\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(result, asyncio\u001b[38;5;241m.\u001b[39mFuture):\n\u001b[1;32m    337\u001b[0m         \u001b[38;5;66;03m# If the result is a Future, wrap it\u001b[39;00m\n\u001b[1;32m    338\u001b[0m         new_future \u001b[38;5;241m=\u001b[39m asyncio\u001b[38;5;241m.\u001b[39mensure_future(result)\n",
      "File \u001b[0;32m~/Desktop/rag/rag-in-action/.venv/lib/python3.10/site-packages/llama_index/llms/openai_like/base.py:173\u001b[0m, in \u001b[0;36mOpenAILike.chat\u001b[0;34m(self, messages, **kwargs)\u001b[0m\n\u001b[1;32m    170\u001b[0m     completion_response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcomplete(prompt, formatted\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    171\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m completion_response_to_chat_response(completion_response)\n\u001b[0;32m--> 173\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mchat\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/rag/rag-in-action/.venv/lib/python3.10/site-packages/llama_index_instrumentation/dispatcher.py:335\u001b[0m, in \u001b[0;36mDispatcher.span.<locals>.wrapper\u001b[0;34m(func, instance, args, kwargs)\u001b[0m\n\u001b[1;32m    332\u001b[0m             _logger\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFailed to reset active_span_id: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    334\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 335\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    336\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(result, asyncio\u001b[38;5;241m.\u001b[39mFuture):\n\u001b[1;32m    337\u001b[0m         \u001b[38;5;66;03m# If the result is a Future, wrap it\u001b[39;00m\n\u001b[1;32m    338\u001b[0m         new_future \u001b[38;5;241m=\u001b[39m asyncio\u001b[38;5;241m.\u001b[39mensure_future(result)\n",
      "File \u001b[0;32m~/Desktop/rag/rag-in-action/.venv/lib/python3.10/site-packages/llama_index/core/llms/callbacks.py:175\u001b[0m, in \u001b[0;36mllm_chat_callback.<locals>.wrap.<locals>.wrapped_llm_chat\u001b[0;34m(_self, messages, **kwargs)\u001b[0m\n\u001b[1;32m    166\u001b[0m event_id \u001b[38;5;241m=\u001b[39m callback_manager\u001b[38;5;241m.\u001b[39mon_event_start(\n\u001b[1;32m    167\u001b[0m     CBEventType\u001b[38;5;241m.\u001b[39mLLM,\n\u001b[1;32m    168\u001b[0m     payload\u001b[38;5;241m=\u001b[39m{\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    172\u001b[0m     },\n\u001b[1;32m    173\u001b[0m )\n\u001b[1;32m    174\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 175\u001b[0m     f_return_val \u001b[38;5;241m=\u001b[39m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_self\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    176\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    177\u001b[0m     callback_manager\u001b[38;5;241m.\u001b[39mon_event_end(\n\u001b[1;32m    178\u001b[0m         CBEventType\u001b[38;5;241m.\u001b[39mLLM,\n\u001b[1;32m    179\u001b[0m         payload\u001b[38;5;241m=\u001b[39m{EventPayload\u001b[38;5;241m.\u001b[39mEXCEPTION: e},\n\u001b[1;32m    180\u001b[0m         event_id\u001b[38;5;241m=\u001b[39mevent_id,\n\u001b[1;32m    181\u001b[0m     )\n",
      "File \u001b[0;32m~/Desktop/rag/rag-in-action/.venv/lib/python3.10/site-packages/llama_index/llms/openai/base.py:398\u001b[0m, in \u001b[0;36mOpenAI.chat\u001b[0;34m(self, messages, **kwargs)\u001b[0m\n\u001b[1;32m    396\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    397\u001b[0m     chat_fn \u001b[38;5;241m=\u001b[39m completion_to_chat_decorator(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_complete)\n\u001b[0;32m--> 398\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mchat_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/rag/rag-in-action/.venv/lib/python3.10/site-packages/llama_index/llms/openai/base.py:113\u001b[0m, in \u001b[0;36mllm_retry_decorator.<locals>.wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    104\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m f(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    106\u001b[0m retry \u001b[38;5;241m=\u001b[39m create_retry_decorator(\n\u001b[1;32m    107\u001b[0m     max_retries\u001b[38;5;241m=\u001b[39mmax_retries,\n\u001b[1;32m    108\u001b[0m     random_exponential\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    111\u001b[0m     max_seconds\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m20\u001b[39m,\n\u001b[1;32m    112\u001b[0m )\n\u001b[0;32m--> 113\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mretry\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/rag/rag-in-action/.venv/lib/python3.10/site-packages/tenacity/__init__.py:338\u001b[0m, in \u001b[0;36mBaseRetrying.wraps.<locals>.wrapped_f\u001b[0;34m(*args, **kw)\u001b[0m\n\u001b[1;32m    336\u001b[0m copy \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcopy()\n\u001b[1;32m    337\u001b[0m wrapped_f\u001b[38;5;241m.\u001b[39mstatistics \u001b[38;5;241m=\u001b[39m copy\u001b[38;5;241m.\u001b[39mstatistics  \u001b[38;5;66;03m# type: ignore[attr-defined]\u001b[39;00m\n\u001b[0;32m--> 338\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcopy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkw\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/rag/rag-in-action/.venv/lib/python3.10/site-packages/tenacity/__init__.py:477\u001b[0m, in \u001b[0;36mRetrying.__call__\u001b[0;34m(self, fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m    475\u001b[0m retry_state \u001b[38;5;241m=\u001b[39m RetryCallState(retry_object\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m, fn\u001b[38;5;241m=\u001b[39mfn, args\u001b[38;5;241m=\u001b[39margs, kwargs\u001b[38;5;241m=\u001b[39mkwargs)\n\u001b[1;32m    476\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m--> 477\u001b[0m     do \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43miter\u001b[49m\u001b[43m(\u001b[49m\u001b[43mretry_state\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretry_state\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    478\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(do, DoAttempt):\n\u001b[1;32m    479\u001b[0m         \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[0;32m~/Desktop/rag/rag-in-action/.venv/lib/python3.10/site-packages/tenacity/__init__.py:378\u001b[0m, in \u001b[0;36mBaseRetrying.iter\u001b[0;34m(self, retry_state)\u001b[0m\n\u001b[1;32m    376\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    377\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m action \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39miter_state\u001b[38;5;241m.\u001b[39mactions:\n\u001b[0;32m--> 378\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43maction\u001b[49m\u001b[43m(\u001b[49m\u001b[43mretry_state\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    379\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m~/Desktop/rag/rag-in-action/.venv/lib/python3.10/site-packages/tenacity/__init__.py:400\u001b[0m, in \u001b[0;36mBaseRetrying._post_retry_check_actions.<locals>.<lambda>\u001b[0;34m(rs)\u001b[0m\n\u001b[1;32m    398\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_post_retry_check_actions\u001b[39m(\u001b[38;5;28mself\u001b[39m, retry_state: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRetryCallState\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    399\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39miter_state\u001b[38;5;241m.\u001b[39mis_explicit_retry \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39miter_state\u001b[38;5;241m.\u001b[39mretry_run_result):\n\u001b[0;32m--> 400\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_add_action_func(\u001b[38;5;28;01mlambda\u001b[39;00m rs: \u001b[43mrs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moutcome\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    401\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m    403\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mafter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/concurrent/futures/_base.py:451\u001b[0m, in \u001b[0;36mFuture.result\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    449\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m CancelledError()\n\u001b[1;32m    450\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;241m==\u001b[39m FINISHED:\n\u001b[0;32m--> 451\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__get_result\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    453\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_condition\u001b[38;5;241m.\u001b[39mwait(timeout)\n\u001b[1;32m    455\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;129;01min\u001b[39;00m [CANCELLED, CANCELLED_AND_NOTIFIED]:\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/concurrent/futures/_base.py:403\u001b[0m, in \u001b[0;36mFuture.__get_result\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    401\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception:\n\u001b[1;32m    402\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 403\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception\n\u001b[1;32m    404\u001b[0m     \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    405\u001b[0m         \u001b[38;5;66;03m# Break a reference cycle with the exception in self._exception\u001b[39;00m\n\u001b[1;32m    406\u001b[0m         \u001b[38;5;28mself\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/Desktop/rag/rag-in-action/.venv/lib/python3.10/site-packages/tenacity/__init__.py:480\u001b[0m, in \u001b[0;36mRetrying.__call__\u001b[0;34m(self, fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m    478\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(do, DoAttempt):\n\u001b[1;32m    479\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 480\u001b[0m         result \u001b[38;5;241m=\u001b[39m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    481\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m:  \u001b[38;5;66;03m# noqa: B902\u001b[39;00m\n\u001b[1;32m    482\u001b[0m         retry_state\u001b[38;5;241m.\u001b[39mset_exception(sys\u001b[38;5;241m.\u001b[39mexc_info())  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n",
      "File \u001b[0;32m~/Desktop/rag/rag-in-action/.venv/lib/python3.10/site-packages/llama_index/llms/openai/base.py:494\u001b[0m, in \u001b[0;36mOpenAI._chat\u001b[0;34m(self, messages, **kwargs)\u001b[0m\n\u001b[1;32m    488\u001b[0m message_dicts \u001b[38;5;241m=\u001b[39m to_openai_message_dicts(\n\u001b[1;32m    489\u001b[0m     messages,\n\u001b[1;32m    490\u001b[0m     model\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel,\n\u001b[1;32m    491\u001b[0m )\n\u001b[1;32m    493\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreuse_client:\n\u001b[0;32m--> 494\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mclient\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mchat\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompletions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    495\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmessages\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmessage_dicts\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    496\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    497\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_model_kwargs\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    498\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    499\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    500\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m client:\n",
      "File \u001b[0;32m~/Desktop/rag/rag-in-action/.venv/lib/python3.10/site-packages/openai/_utils/_utils.py:286\u001b[0m, in \u001b[0;36mrequired_args.<locals>.inner.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    284\u001b[0m             msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMissing required argument: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mquote(missing[\u001b[38;5;241m0\u001b[39m])\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    285\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(msg)\n\u001b[0;32m--> 286\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/rag/rag-in-action/.venv/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py:1192\u001b[0m, in \u001b[0;36mCompletions.create\u001b[0;34m(self, messages, model, audio, frequency_penalty, function_call, functions, logit_bias, logprobs, max_completion_tokens, max_tokens, metadata, modalities, n, parallel_tool_calls, prediction, presence_penalty, prompt_cache_key, prompt_cache_retention, reasoning_effort, response_format, safety_identifier, seed, service_tier, stop, store, stream, stream_options, temperature, tool_choice, tools, top_logprobs, top_p, user, verbosity, web_search_options, extra_headers, extra_query, extra_body, timeout)\u001b[0m\n\u001b[1;32m   1145\u001b[0m \u001b[38;5;129m@required_args\u001b[39m([\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessages\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m], [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessages\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstream\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m   1146\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mcreate\u001b[39m(\n\u001b[1;32m   1147\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1189\u001b[0m     timeout: \u001b[38;5;28mfloat\u001b[39m \u001b[38;5;241m|\u001b[39m httpx\u001b[38;5;241m.\u001b[39mTimeout \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m|\u001b[39m NotGiven \u001b[38;5;241m=\u001b[39m not_given,\n\u001b[1;32m   1190\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ChatCompletion \u001b[38;5;241m|\u001b[39m Stream[ChatCompletionChunk]:\n\u001b[1;32m   1191\u001b[0m     validate_response_format(response_format)\n\u001b[0;32m-> 1192\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_post\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1193\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m/chat/completions\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1194\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmaybe_transform\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1195\u001b[0m \u001b[43m            \u001b[49m\u001b[43m{\u001b[49m\n\u001b[1;32m   1196\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmessages\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1197\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmodel\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1198\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43maudio\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43maudio\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1199\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfrequency_penalty\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfrequency_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1200\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfunction_call\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunction_call\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1201\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfunctions\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunctions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1202\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlogit_bias\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogit_bias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1203\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlogprobs\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogprobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1204\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmax_completion_tokens\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_completion_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1205\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmax_tokens\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1206\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmetadata\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1207\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmodalities\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodalities\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1208\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mn\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1209\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mparallel_tool_calls\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mparallel_tool_calls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1210\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mprediction\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mprediction\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1211\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpresence_penalty\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mpresence_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1212\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mprompt_cache_key\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mprompt_cache_key\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1213\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mprompt_cache_retention\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mprompt_cache_retention\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1214\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mreasoning_effort\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mreasoning_effort\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1215\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mresponse_format\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mresponse_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1216\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43msafety_identifier\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43msafety_identifier\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1217\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mseed\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mseed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1218\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mservice_tier\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mservice_tier\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1219\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstop\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1220\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstore\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstore\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1221\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstream\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1222\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstream_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1223\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtemperature\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1224\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtool_choice\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtool_choice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1225\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtools\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtools\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1226\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtop_logprobs\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_logprobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1227\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtop_p\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_p\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1228\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43muser\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43muser\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1229\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mverbosity\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbosity\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1230\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mweb_search_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mweb_search_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1231\u001b[0m \u001b[43m            \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1232\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcompletion_create_params\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mCompletionCreateParamsStreaming\u001b[49m\n\u001b[1;32m   1233\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\n\u001b[1;32m   1234\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mcompletion_create_params\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mCompletionCreateParamsNonStreaming\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1235\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1236\u001b[0m \u001b[43m        \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmake_request_options\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1237\u001b[0m \u001b[43m            \u001b[49m\u001b[43mextra_headers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_headers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_query\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_query\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_body\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_body\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\n\u001b[1;32m   1238\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1239\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mChatCompletion\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1240\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   1241\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mStream\u001b[49m\u001b[43m[\u001b[49m\u001b[43mChatCompletionChunk\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1242\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/rag/rag-in-action/.venv/lib/python3.10/site-packages/openai/_base_client.py:1259\u001b[0m, in \u001b[0;36mSyncAPIClient.post\u001b[0;34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1245\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mpost\u001b[39m(\n\u001b[1;32m   1246\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   1247\u001b[0m     path: \u001b[38;5;28mstr\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1254\u001b[0m     stream_cls: \u001b[38;5;28mtype\u001b[39m[_StreamT] \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   1255\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ResponseT \u001b[38;5;241m|\u001b[39m _StreamT:\n\u001b[1;32m   1256\u001b[0m     opts \u001b[38;5;241m=\u001b[39m FinalRequestOptions\u001b[38;5;241m.\u001b[39mconstruct(\n\u001b[1;32m   1257\u001b[0m         method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpost\u001b[39m\u001b[38;5;124m\"\u001b[39m, url\u001b[38;5;241m=\u001b[39mpath, json_data\u001b[38;5;241m=\u001b[39mbody, files\u001b[38;5;241m=\u001b[39mto_httpx_files(files), \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39moptions\n\u001b[1;32m   1258\u001b[0m     )\n\u001b[0;32m-> 1259\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(ResponseT, \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[0;32m~/Desktop/rag/rag-in-action/.venv/lib/python3.10/site-packages/openai/_base_client.py:1047\u001b[0m, in \u001b[0;36mSyncAPIClient.request\u001b[0;34m(self, cast_to, options, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1044\u001b[0m             err\u001b[38;5;241m.\u001b[39mresponse\u001b[38;5;241m.\u001b[39mread()\n\u001b[1;32m   1046\u001b[0m         log\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRe-raising status error\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m-> 1047\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_status_error_from_response(err\u001b[38;5;241m.\u001b[39mresponse) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1049\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m   1051\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m response \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcould not resolve response (should never happen)\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "\u001b[0;31mAuthenticationError\u001b[0m: Error code: 401 - {'error': {'message': 'Authentication Fails, Your api key: ****bb4f is invalid', 'type': 'authentication_error', 'param': None, 'code': 'invalid_request_error'}}"
     ]
    }
   ],
   "source": [
    "# ä¸´æ—¶ç»•è¿‡ torch.load å®‰å…¨æ£€æŸ¥ï¼ˆä»…ç”¨äºå¼€å‘ç¯å¢ƒï¼‰\n",
    "# æ³¨æ„ï¼šè¿™æ˜¯ä¸€ä¸ªä¸´æ—¶è§£å†³æ–¹æ¡ˆï¼Œç”Ÿäº§ç¯å¢ƒåº”è¯¥å‡çº§ torch åˆ° 2.6+ æˆ–ä½¿ç”¨ safetensors æ ¼å¼\n",
    "import transformers.utils.import_utils\n",
    "import transformers.modeling_utils\n",
    "\n",
    "def dummy_check():\n",
    "    pass\n",
    "\n",
    "transformers.utils.import_utils.check_torch_load_is_safe = dummy_check\n",
    "transformers.modeling_utils.check_torch_load_is_safe = dummy_check\n",
    "\n",
    "from llama_index.core import  VectorStoreIndex, Settings, Document\n",
    "from llama_index.core.node_parser import  SentenceWindowNodeParser, SentenceSplitter\n",
    "from llama_index.llms.deepseek import DeepSeek\n",
    "from llama_index.embeddings.huggingface import HuggingFaceEmbedding\n",
    "from llama_index.core.postprocessor import MetadataReplacementPostProcessor # å…ƒæ•°æ®æ›¿æ¢åå¤„ç†å™¨\n",
    "\n",
    "import os\n",
    "os.environ[\"DEEPSEEK_API_KEY\"] = \"sk-34*****5bb4f\"\n",
    "\n",
    "# é…ç½®å…¨å±€è®¾ç½®\n",
    "Settings.llm = DeepSeek(model=\"deepseek-chat\", temperature=0.1)\n",
    "Settings.embed_model = HuggingFaceEmbedding(model_name=\"BAAI/bge-small-zh\")\n",
    "Settings.text_splitter = SentenceSplitter(separator=\"\\n\",  chunk_size=50, chunk_overlap=0)\n",
    "# å‡†å¤‡çŸ¥è¯†æ–‡æœ¬å¹¶åˆ›å»ºDocumentå¯¹è±¡\n",
    "game_knowledge = \"\"\"\n",
    "ã€Šç­ç¥çºªâˆ™çŒ¢ç‹²ã€‹æ˜¯ä¸€æ¬¾åŠ¨ä½œè§’è‰²æ‰®æ¼”æ¸¸æˆã€‚æ¸¸æˆèƒŒæ™¯è®¾å®šåœ¨æ¶ç©ºçš„ç¥è¯ä¸–ç•Œä¸­ã€‚\n",
    "ç©å®¶å°†æ‰®æ¼”é½å¤©å¤§åœ£å­™æ‚Ÿç©ºï¼Œåœ¨å……æ»¡ä¸œæ–¹ç¥è¯å…ƒç´ çš„ä¸–ç•Œä¸­å±•å¼€å†’é™©ã€‚\n",
    "æ¸¸æˆçš„æˆ˜æ–—ç³»ç»Ÿæå…·ç‰¹è‰²ï¼Œé‡‡ç”¨äº†ç‹¬ç‰¹çš„â€œå˜èº«ç³»ç»Ÿâ€ã€‚æ‚Ÿç©ºå¯ä»¥åœ¨æˆ˜æ–—ä¸­å˜æ¢ä¸åŒå½¢æ€ã€‚\n",
    "æ¯ç§å½¢æ€éƒ½æœ‰å…¶ç‹¬ç‰¹çš„æˆ˜æ–—é£æ ¼å’ŒæŠ€èƒ½ç»„åˆã€‚é‡‘åˆšå½¢æ€ä¾§é‡åŠ›é‡å‹æ‰“å‡»ï¼Œå¸¦æ¥å‹å€’æ€§çš„ç ´ååŠ›ã€‚\n",
    "é­”ä½›å½¢æ€åˆ™ä¸“æ³¨æ³•æœ¯æ”»å‡»ï¼Œèƒ½é‡Šæ”¾å¼ºå¤§çš„æ³•æœ¯ä¼¤å®³ã€‚\n",
    "æ¸¸æˆä¸–ç•Œä¸­å……æ»¡äº†æ ‡å¿—æ€§çš„ç¥è¯è§’è‰²ï¼Œé™¤äº†ä¸»è§’å­™æ‚Ÿç©ºä»¥å¤–ï¼Œè¿˜æœ‰æ¥è‡ªä½›æ•™ã€é“æ•™ç­‰å„æ´¾ç³»çš„ç¥é­”ã€‚\n",
    "è¿™äº›è§’è‰²æ—¢å¯èƒ½æ˜¯æ‚Ÿç©ºçš„ç›Ÿå‹ï¼Œä¹Ÿå¯èƒ½æ˜¯éœ€è¦å‡»è´¥çš„å¼ºå¤§å¯¹æ‰‹ã€‚\n",
    "è£…å¤‡ç³»ç»ŸåŒ…å«äº†ä¸°å¯Œçš„æ­¦å™¨é€‰æ‹©ï¼Œé™¤äº†è‘—åçš„å¦‚æ„é‡‘ç®æ£’ä»¥å¤–ï¼Œæ‚Ÿç©ºè¿˜å¯ä»¥ä½¿ç”¨å„ç§ç¥å™¨æ³•å®ã€‚\n",
    "ä¸åŒæ­¦å™¨æœ‰å…¶ç‰¹è‰²æ•ˆæœï¼Œç©å®¶éœ€è¦æ ¹æ®æˆ˜æ–—åœºæ™¯çµæ´»é€‰æ‹©ã€‚\n",
    "æ¸¸æˆçš„ç”»é¢è¡¨ç°æå…·ä¸œæ–¹ç¾å­¦ç‰¹è‰²ï¼Œåœºæ™¯èåˆäº†æ°´å¢¨ç”»é£æ ¼ï¼Œå°†å±±å·ã€å»ºç­‘ç­‰å…ƒç´ å®Œç¾å‘ˆç°ã€‚\n",
    "æˆ˜æ–—ç‰¹æ•ˆæ—¢æœ‰ä¸­å›½ä¼ ç»Ÿæ–‡åŒ–å…ƒç´ ï¼Œåˆå…·å¤‡ç°ä»£æ¸¸æˆçš„è§†è§‰éœ‡æ’¼åŠ›ã€‚\n",
    "éš¾åº¦è®¾è®¡ä¸Šï¼ŒBossæˆ˜å……æ»¡æŒ‘æˆ˜æ€§ï¼Œéœ€è¦ç©å®¶ç²¾å‡†æŠŠæ¡æˆ˜æ–—èŠ‚å¥å’ŒæŠ€èƒ½è¿ç”¨ã€‚\n",
    "åŒæ—¶æ¸¸æˆä¹Ÿæä¾›äº†å¤šç§éš¾åº¦é€‰æ‹©ï¼Œç…§é¡¾ä¸åŒæŠ€æœ¯æ°´å¹³çš„ç©å®¶ã€‚\"\"\"\n",
    "# åˆ›å»ºDocumentå¯¹è±¡\n",
    "documents = [Document(text=game_knowledge)]\n",
    "# åˆ›å»ºå¸¦ä¸Šä¸‹æ–‡çª—å£çš„å¥å­è§£æå™¨ï¼ˆæ¯ä¸ªç›®æ ‡å¥å­ä¸¤ä¾§å„ä¿ç•™nä¸ªå¥å­ä½œä¸ºä¸Šä¸‹æ–‡ï¼‰\n",
    "node_parser = SentenceWindowNodeParser.from_defaults(\n",
    "    window_size=3,\n",
    "    window_metadata_key=\"window\",\n",
    "    original_text_metadata_key=\"original_text\"\n",
    ")\n",
    "# ä½¿ç”¨çª—å£è§£æå™¨å¤„ç†æ–‡æ¡£\n",
    "nodes = node_parser.get_nodes_from_documents(documents)\n",
    "# ä½¿ç”¨åŸºç¡€è§£æå™¨å¤„ç†æ–‡æ¡£ï¼ˆç”¨äºå¯¹æ¯”ï¼‰\n",
    "base_nodes = Settings.text_splitter.get_nodes_from_documents(documents)\n",
    "# æ„å»ºä¸¤ç§ç´¢å¼•ç”¨äºå¯¹æ¯”\n",
    "sentence_index = VectorStoreIndex(nodes)\n",
    "base_index = VectorStoreIndex(base_nodes)\n",
    "# åˆ›å»ºå¸¦ä¸Šä¸‹æ–‡çª—å£çš„æŸ¥è¯¢å¼•æ“\n",
    "window_query_engine = sentence_index.as_query_engine(\n",
    "    similarity_top_k=2,\n",
    "    node_postprocessors=[\n",
    "        MetadataReplacementPostProcessor(target_metadata_key=\"window\")\n",
    "    ]\n",
    ")\n",
    "# åˆ›å»ºåŸºç¡€æŸ¥è¯¢å¼•æ“\n",
    "base_query_engine = base_index.as_query_engine(\n",
    "    similarity_top_k=6\n",
    ")\n",
    "# æµ‹è¯•é—®ç­”\n",
    "test_questions = [\n",
    "    \"æ¸¸æˆä¸­æ‚Ÿç©ºæœ‰å“ªäº›å½¢æ€å˜åŒ–ï¼Ÿ\",\n",
    "    # \"æ¸¸æˆçš„ç”»é¢é£æ ¼æ˜¯æ€æ ·çš„ï¼Ÿ\",\n",
    "    # \"æ¸¸æˆçš„éš¾åº¦è®¾è®¡å¦‚ä½•ï¼Ÿ\"\n",
    "]\n",
    "print(\"=== ä½¿ç”¨çª—å£è§£æå™¨çš„æ£€ç´¢ç»“æœ ===\")\n",
    "for question in test_questions:\n",
    "    print(f\"\\né—®é¢˜ï¼š{question}\")\n",
    "    window_response = window_query_engine.query(question)\n",
    "    print(f\"å›ç­”ï¼š{window_response}\")\n",
    "    \n",
    "    # å±•ç¤ºæ£€ç´¢åˆ°çš„åŸå§‹å¥å­å’Œçª—å£å†…å®¹\n",
    "    print(\"\\næ£€ç´¢è¯¦æƒ…ï¼š\")\n",
    "    for node in window_response.source_nodes:\n",
    "        print(f\"åŸå§‹å¥å­ï¼š{node.node.metadata['original_text']}\")\n",
    "        print(f\"ä¸Šä¸‹æ–‡çª—å£ï¼š{node.node.metadata['window']}\")\n",
    "        print(\"---\")\n",
    "print(\"\\n=== ä½¿ç”¨åŸºç¡€è§£æå™¨çš„æ£€ç´¢ç»“æœï¼ˆå¯¹æ¯”ï¼‰===\")\n",
    "for question in test_questions:\n",
    "    print(f\"\\né—®é¢˜ï¼š{question}\")\n",
    "    base_response = base_query_engine.query(question)\n",
    "print(f\"å›ç­”ï¼š{base_response}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4a94dcb",
   "metadata": {},
   "source": [
    "### çˆ¶å­æ–‡æœ¬å—æ£€ç´¢"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b607878",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/bp/x7mjxntx7k75gqf0w3_nsztc0000gn/T/ipykernel_72411/1595382956.py:48: LangChainDeprecationWarning: The class `Chroma` was deprecated in LangChain 0.2.9 and will be removed in 1.0. An updated version of the class exists in the `langchain-chroma package and should be used instead. To use it run `pip install -U `langchain-chroma` and import as `from `langchain_chroma import Chroma``.\n",
      "  vectorstore = Chroma(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "é—®é¢˜ï¼šæ¸¸æˆä¸­æ‚Ÿç©ºæœ‰å“ªäº›å½¢æ€å˜åŒ–ï¼Ÿ\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/bp/x7mjxntx7k75gqf0w3_nsztc0000gn/T/ipykernel_72411/1595382956.py:88: LangChainDeprecationWarning: The method `Chain.__call__` was deprecated in langchain-classic 0.1.0 and will be removed in 1.0. Use `invoke` instead.\n",
      "  result = qa_chain({\"query\": question})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "å›ç­”ï¼šæ ¹æ®ä¸Šä¸‹æ–‡ä¿¡æ¯ï¼Œæ¸¸æˆä¸­æ‚Ÿç©ºæ‹¥æœ‰ä»¥ä¸‹å½¢æ€å˜åŒ–ï¼š\n",
      "1. **é‡‘åˆšå½¢æ€**ï¼šä¾§é‡åŠ›é‡å‹æ‰“å‡»ï¼Œå¸¦æ¥å‹å€’æ€§çš„ç ´ååŠ›ã€‚\n",
      "2. **é­”ä½›å½¢æ€**ï¼šä¸“æ³¨æ³•æœ¯æ”»å‡»ï¼Œèƒ½é‡Šæ”¾å¼ºå¤§çš„æ³•æœ¯ä¼¤å®³ã€‚\n",
      "\n",
      "ä½¿ç”¨çš„æºæ–‡æ¡£ï¼š\n",
      "\n",
      "ç›¸å…³æ–‡æ¡£ 1:\n",
      "é•¿åº¦ï¼š444 å­—ç¬¦\n",
      "å†…å®¹ç‰‡æ®µï¼šã€Šç­ç¥çºªâˆ™çŒ¢ç‹²ã€‹æ˜¯ä¸€æ¬¾åŠ¨ä½œè§’è‰²æ‰®æ¼”æ¸¸æˆã€‚æ¸¸æˆèƒŒæ™¯è®¾å®šåœ¨æ¶ç©ºçš„ç¥è¯ä¸–ç•Œä¸­ã€‚ç©å®¶å°†æ‰®æ¼”é½å¤©å¤§åœ£å­™æ‚Ÿç©ºï¼Œåœ¨å……æ»¡ä¸œæ–¹ç¥è¯å…ƒç´ çš„ä¸–ç•Œä¸­å±•å¼€å†’é™©ã€‚æ¸¸æˆçš„æˆ˜æ–—ç³»ç»Ÿæå…·ç‰¹è‰²ï¼Œé‡‡ç”¨äº†ç‹¬ç‰¹çš„\"å˜èº«ç³»ç»Ÿ\"ã€‚æ‚Ÿç©ºå¯ä»¥åœ¨æˆ˜æ–—ä¸­å˜æ¢ä¸åŒå½¢æ€ã€‚æ¯ç§å½¢æ€éƒ½æœ‰å…¶ç‹¬ç‰¹çš„æˆ˜æ–—é£æ ¼å’ŒæŠ€èƒ½ç»„åˆã€‚é‡‘åˆšå½¢æ€ä¾§é‡åŠ›é‡å‹æ‰“å‡»ï¼Œå¸¦æ¥å‹å€’æ€§çš„ç ´ååŠ›ã€‚é­”...\n",
      "---\n",
      "\n",
      "é—®é¢˜ï¼šæ¸¸æˆçš„ç”»é¢é£æ ¼æ˜¯æ€æ ·çš„ï¼Ÿ\n",
      "\n",
      "å›ç­”ï¼šæ¸¸æˆçš„ç”»é¢è¡¨ç°æå…·ä¸œæ–¹ç¾å­¦ç‰¹è‰²ï¼Œåœºæ™¯èåˆäº†æ°´å¢¨ç”»é£æ ¼ï¼Œå°†å±±å·ã€å»ºç­‘ç­‰å…ƒç´ å®Œç¾å‘ˆç°ã€‚æˆ˜æ–—ç‰¹æ•ˆæ—¢æœ‰ä¸­å›½ä¼ ç»Ÿæ–‡åŒ–å…ƒç´ ï¼Œåˆå…·å¤‡ç°ä»£æ¸¸æˆçš„è§†è§‰éœ‡æ’¼åŠ›ã€‚\n",
      "\n",
      "ä½¿ç”¨çš„æºæ–‡æ¡£ï¼š\n",
      "\n",
      "ç›¸å…³æ–‡æ¡£ 1:\n",
      "é•¿åº¦ï¼š444 å­—ç¬¦\n",
      "å†…å®¹ç‰‡æ®µï¼šã€Šç­ç¥çºªâˆ™çŒ¢ç‹²ã€‹æ˜¯ä¸€æ¬¾åŠ¨ä½œè§’è‰²æ‰®æ¼”æ¸¸æˆã€‚æ¸¸æˆèƒŒæ™¯è®¾å®šåœ¨æ¶ç©ºçš„ç¥è¯ä¸–ç•Œä¸­ã€‚ç©å®¶å°†æ‰®æ¼”é½å¤©å¤§åœ£å­™æ‚Ÿç©ºï¼Œåœ¨å……æ»¡ä¸œæ–¹ç¥è¯å…ƒç´ çš„ä¸–ç•Œä¸­å±•å¼€å†’é™©ã€‚æ¸¸æˆçš„æˆ˜æ–—ç³»ç»Ÿæå…·ç‰¹è‰²ï¼Œé‡‡ç”¨äº†ç‹¬ç‰¹çš„\"å˜èº«ç³»ç»Ÿ\"ã€‚æ‚Ÿç©ºå¯ä»¥åœ¨æˆ˜æ–—ä¸­å˜æ¢ä¸åŒå½¢æ€ã€‚æ¯ç§å½¢æ€éƒ½æœ‰å…¶ç‹¬ç‰¹çš„æˆ˜æ–—é£æ ¼å’ŒæŠ€èƒ½ç»„åˆã€‚é‡‘åˆšå½¢æ€ä¾§é‡åŠ›é‡å‹æ‰“å‡»ï¼Œå¸¦æ¥å‹å€’æ€§çš„ç ´ååŠ›ã€‚é­”...\n",
      "---\n"
     ]
    }
   ],
   "source": [
    "# ä¸´æ—¶ç»•è¿‡ torch.load å®‰å…¨æ£€æŸ¥ï¼ˆä»…ç”¨äºå¼€å‘ç¯å¢ƒï¼‰\n",
    "import transformers.utils.import_utils\n",
    "import transformers.modeling_utils\n",
    "\n",
    "def dummy_check():\n",
    "    pass\n",
    "\n",
    "transformers.utils.import_utils.check_torch_load_is_safe = dummy_check\n",
    "transformers.modeling_utils.check_torch_load_is_safe = dummy_check\n",
    "\n",
    "from langchain_deepseek import ChatDeepSeek \n",
    "from langchain_huggingface import HuggingFaceEmbeddings \n",
    "\n",
    "import os\n",
    "os.environ[\"DEEPSEEK_API_KEY\"] = \"sk-34b4f11***5bb4f\"\n",
    "\n",
    "# åˆå§‹åŒ–è¯­è¨€æ¨¡å‹å’Œå‘é‡åµŒå…¥æ¨¡å‹\n",
    "llm = ChatDeepSeek(model=\"deepseek-chat\", temperature=0.1)\n",
    "embed_model = HuggingFaceEmbeddings(model_name=\"BAAI/bge-small-zh\")\n",
    "# å‡†å¤‡æ¸¸æˆçŸ¥è¯†æ–‡æœ¬ï¼Œåˆ›å»ºDocumentå¯¹è±¡ã€‚\n",
    "from langchain_core.documents import Document\n",
    "game_knowledge = \"\"\"\n",
    "ã€Šç­ç¥çºªâˆ™çŒ¢ç‹²ã€‹æ˜¯ä¸€æ¬¾åŠ¨ä½œè§’è‰²æ‰®æ¼”æ¸¸æˆã€‚æ¸¸æˆèƒŒæ™¯è®¾å®šåœ¨æ¶ç©ºçš„ç¥è¯ä¸–ç•Œä¸­ã€‚ç©å®¶å°†æ‰®æ¼”é½å¤©å¤§åœ£å­™æ‚Ÿç©ºï¼Œåœ¨å……æ»¡ä¸œæ–¹ç¥è¯å…ƒç´ çš„ä¸–ç•Œä¸­å±•å¼€å†’é™©ã€‚æ¸¸æˆçš„æˆ˜æ–—ç³»ç»Ÿæå…·ç‰¹è‰²ï¼Œé‡‡ç”¨äº†ç‹¬ç‰¹çš„\"å˜èº«ç³»ç»Ÿ\"ã€‚æ‚Ÿç©ºå¯ä»¥åœ¨æˆ˜æ–—ä¸­å˜æ¢ä¸åŒå½¢æ€ã€‚æ¯ç§å½¢æ€éƒ½æœ‰å…¶ç‹¬ç‰¹çš„æˆ˜æ–—é£æ ¼å’ŒæŠ€èƒ½ç»„åˆã€‚é‡‘åˆšå½¢æ€ä¾§é‡åŠ›é‡å‹æ‰“å‡»ï¼Œå¸¦æ¥å‹å€’æ€§çš„ç ´ååŠ›ã€‚é­”ä½›å½¢æ€åˆ™ä¸“æ³¨æ³•æœ¯æ”»å‡»ï¼Œèƒ½é‡Šæ”¾å¼ºå¤§çš„æ³•æœ¯ä¼¤å®³ã€‚æ¸¸æˆä¸–ç•Œä¸­å……æ»¡äº†æ ‡å¿—æ€§çš„ç¥è¯è§’è‰²ï¼Œé™¤äº†ä¸»è§’å­™æ‚Ÿç©ºä»¥å¤–ï¼Œè¿˜æœ‰æ¥è‡ªä½›æ•™ã€é“æ•™ç­‰å„æ´¾ç³»çš„ç¥é­”ã€‚è¿™äº›è§’è‰²æ—¢å¯èƒ½æ˜¯æ‚Ÿç©ºçš„ç›Ÿå‹ï¼Œä¹Ÿå¯èƒ½æ˜¯éœ€è¦å‡»è´¥çš„å¼ºå¤§å¯¹æ‰‹ã€‚è£…å¤‡ç³»ç»ŸåŒ…å«äº†ä¸°å¯Œçš„æ­¦å™¨é€‰æ‹©ï¼Œé™¤äº†è‘—åçš„å¦‚æ„é‡‘ç®æ£’ä»¥å¤–ï¼Œæ‚Ÿç©ºè¿˜å¯ä»¥ä½¿ç”¨å„ç§ç¥å™¨æ³•å®ã€‚ä¸åŒæ­¦å™¨æœ‰å…¶ç‰¹è‰²æ•ˆæœï¼Œç©å®¶éœ€è¦æ ¹æ®æˆ˜æ–—åœºæ™¯çµæ´»é€‰æ‹©ã€‚æ¸¸æˆçš„ç”»é¢è¡¨ç°æå…·ä¸œæ–¹ç¾å­¦ç‰¹è‰²ï¼Œåœºæ™¯èåˆäº†æ°´å¢¨ç”»é£æ ¼ï¼Œå°†å±±å·ã€å»ºç­‘ç­‰å…ƒç´ å®Œç¾å‘ˆç°ã€‚æˆ˜æ–—ç‰¹æ•ˆæ—¢æœ‰ä¸­å›½ä¼ ç»Ÿæ–‡åŒ–å…ƒç´ ï¼Œåˆå…·å¤‡ç°ä»£æ¸¸æˆçš„è§†è§‰éœ‡æ’¼åŠ›ã€‚éš¾åº¦è®¾è®¡ä¸Šï¼ŒBossæˆ˜å……æ»¡æŒ‘æˆ˜æ€§ï¼Œéœ€è¦ç©å®¶ç²¾å‡†æŠŠæ¡æˆ˜æ–—èŠ‚å¥å’ŒæŠ€èƒ½è¿ç”¨ã€‚åŒæ—¶æ¸¸æˆä¹Ÿæä¾›äº†å¤šç§éš¾åº¦é€‰æ‹©ï¼Œç…§é¡¾ä¸åŒæŠ€æœ¯æ°´å¹³çš„ç©å®¶ã€‚\n",
    "\n",
    "\"\"\"\n",
    "# åˆ›å»ºDocumentå¯¹è±¡\n",
    "documents = [Document(page_content=game_knowledge)]\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "# çˆ¶æ–‡æœ¬å—åˆ†å‰²å™¨ï¼ˆè¾ƒå¤§çš„æ–‡æœ¬å—ï¼‰\n",
    "parent_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=1000,\n",
    "    chunk_overlap=200,\n",
    "    separators=[\"\\n\\n\", \"\\n\", \"ã€‚\", \"ï¼\", \"ï¼Ÿ\", \"ï¼›\", \",\", \" \", \"\"]\n",
    ")\n",
    "# å­æ–‡æœ¬å—åˆ†å‰²å™¨ï¼ˆè¾ƒå°çš„æ–‡æœ¬å—ï¼‰\n",
    "child_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=200,\n",
    "    chunk_overlap=50,\n",
    "    separators=[\"\\n\\n\", \"\\n\", \"ã€‚\", \"ï¼\", \"ï¼Ÿ\", \"ï¼›\", \",\", \" \", \"\"]\n",
    ")\n",
    "# åˆ›å»ºçˆ¶å­æ–‡æœ¬å—\n",
    "parent_docs = parent_splitter.split_documents(documents)\n",
    "child_docs = child_splitter.split_documents(documents)\n",
    "# åˆ›å»ºå­˜å‚¨å’Œæ£€ç´¢å™¨ï¼Œå»ºç«‹ä¸¤å±‚å­˜å‚¨ç³»ç»Ÿ\n",
    "from langchain_classic.retrievers.parent_document_retriever import ParentDocumentRetriever # çˆ¶æ–‡æ¡£æ£€ç´¢å™¨\n",
    "from langchain_core.stores import InMemoryStore # å†…å­˜å­˜å‚¨\n",
    "from langchain_community.vectorstores import Chroma # å‘é‡å­˜å‚¨\n",
    "vectorstore = Chroma(\n",
    "    collection_name=\"game_knowledge\",\n",
    "    embedding_function=embed_model\n",
    ")\n",
    "store = InMemoryStore()\n",
    "retriever = ParentDocumentRetriever(\n",
    "    vectorstore=vectorstore, # å‘é‡å­˜å‚¨\n",
    "    docstore=store, # æ–‡æ¡£å­˜å‚¨\n",
    "    child_splitter=child_splitter, # å­æ–‡æœ¬å—åˆ†å‰²å™¨\n",
    "    parent_splitter=parent_splitter, # çˆ¶æ–‡æœ¬å—åˆ†å‰²å™¨\n",
    ")\n",
    "# æ·»åŠ æ–‡æœ¬å—\n",
    "retriever.add_documents(documents)\n",
    "# è‡ªå®šä¹‰æç¤ºæ¨¡æ¿\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_classic.chains.retrieval_qa.base import RetrievalQA\n",
    "prompt_template = \"\"\"åŸºäºä»¥ä¸‹ä¸Šä¸‹æ–‡ä¿¡æ¯å›ç­”é—®é¢˜ã€‚å¦‚æœæ— æ³•æ‰¾åˆ°ç­”æ¡ˆï¼Œè¯·è¯´â€œæˆ‘æ‰¾ä¸åˆ°ç›¸å…³ä¿¡æ¯â€ã€‚\n",
    "ä¸Šä¸‹æ–‡ï¼š\n",
    "{context}\n",
    "é—®é¢˜ï¼š{question}\n",
    "å›ç­”ï¼š\"\"\"\n",
    "PROMPT = PromptTemplate(\n",
    "    template=prompt_template,\n",
    "    input_variables=[\"context\", \"question\"]\n",
    ")\n",
    "# åˆ›å»ºé—®ç­”é“¾\n",
    "qa_chain = RetrievalQA.from_chain_type(\n",
    "    llm=llm,\n",
    "    chain_type=\"stuff\", # é—®ç­”é“¾ç±»å‹\n",
    "    retriever=retriever,# æ£€ç´¢å™¨\n",
    "    return_source_documents=True, # æ˜¯å¦è¿”å›æºæ–‡æ¡£\n",
    "    chain_type_kwargs={\"prompt\": PROMPT}\n",
    ")\n",
    "# é€šè¿‡å®é™…é—®ç­”æµ‹è¯•ç³»ç»Ÿ\n",
    "test_questions = [\n",
    "    \"æ¸¸æˆä¸­æ‚Ÿç©ºæœ‰å“ªäº›å½¢æ€å˜åŒ–ï¼Ÿ\",\n",
    "    \"æ¸¸æˆçš„ç”»é¢é£æ ¼æ˜¯æ€æ ·çš„ï¼Ÿ\",\n",
    "]\n",
    "for question in test_questions:\n",
    "    print(f\"\\né—®é¢˜ï¼š{question}\")\n",
    "    result = qa_chain({\"query\": question})    \n",
    "    print(f\"\\nå›ç­”ï¼š{result['result']}\")\n",
    "    print(\"\\nä½¿ç”¨çš„æºæ–‡æ¡£ï¼š\")\n",
    "    for i, doc in enumerate(result[\"source_documents\"], 1):\n",
    "        print(f\"\\nç›¸å…³æ–‡æ¡£ {i}:\")\n",
    "        print(f\"é•¿åº¦ï¼š{len(doc.page_content)} å­—ç¬¦\")\n",
    "        print(f\"å†…å®¹ç‰‡æ®µï¼š{doc.page_content[:150]}...\")\n",
    "        print(\"---\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ffecdc9",
   "metadata": {},
   "source": [
    "### å‰åå‘æ‰©å±•ä¸Šä¸‹æ–‡"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc6e29e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== åŸºç¡€æŸ¥è¯¢å¼•æ“çš„ç»“æœ ===\n",
      "\n",
      "é—®é¢˜ï¼šæ‚Ÿç©ºä»å¿˜å·å¯ºè·å¾—è®°å¿†åå‘ç”Ÿäº†ä»€ä¹ˆï¼Ÿ\n",
      "å›ç­”ï¼šæ‚Ÿç©ºä»å¿˜å·å¯ºè·å¾—è®°å¿†åï¼Œè€åƒ§å»ºè®®ä»–å‰å¾€è¥¿æ–¹çš„ä¸šç«å±±ï¼Œé‚£é‡Œæœ‰ä¸€æ”¯èœ•å˜çš„é­”æ—æŒæ¡æ›´å¤šçœŸç›¸ã€‚ä¸ºäº†è¿›å…¥è¢«çƒˆç«åŒ…å›´çš„ä¸šç«å±±ï¼Œæ‚Ÿç©ºéœ€è¦å…ˆæ‰¾åˆ°ä¼ è¯´ä¸­çš„ä¸‰æ˜§ç«ç”²ã€‚åœ¨å¯»æ‰¾è¿‡ç¨‹ä¸­ï¼Œä»–é‡åˆ°äº†æ˜”æ—¥å¥½å‹å¦–ç‹ï¼Œå¾—çŸ¥å¤©åº­å´©å¡Œåå…­ç•Œç§©åºå¤§ä¹±ï¼Œå„æ–¹åŠ¿åŠ›å´›èµ·ï¼Œä¸€åœºæ›´å¤§çš„åŠ«éš¾æ­£åœ¨é…é…¿ã€‚è·å¾—ä¸‰æ˜§ç«ç”²åï¼Œæ‚Ÿç©ºæ½œå…¥ä¸šç«å±±ï¼Œåœ¨ä¸é­”æ—é¦–é¢†çš„å¯¹å†³ä¸­æƒ³èµ·äº†æ›´å¤šçœŸç›¸ï¼Œäº†è§£åˆ°å¤è€åŠ¿åŠ›çš„ç›®æ ‡æ˜¯é‡å¡‘ä¸–ç•Œè§„åˆ™ã€‚å›åˆ°è€åƒ§èº«è¾¹åï¼Œæ‚Ÿç©ºè¡¨ç¤ºè¦é›†ç»“åŠ›é‡å¯¹æŠ—ï¼Œä½†è€åƒ§æé†’ä»–äº‹æƒ…å¯èƒ½æ›´å¤æ‚ï¼Œå»ºè®®ç»§ç»­å¯»æ‰¾çœŸç›¸å†åšå†³å®šã€‚æ‚Ÿç©ºéšåå†³å®šå¯ç¨‹å‰å¾€å—æ–¹çš„æ²‰æ˜Ÿæµ·ã€‚\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "é—®é¢˜ï¼šæ‚Ÿç©ºæ˜¯å¦‚ä½•åˆ°è¾¾ä¸šç«å±±çš„ï¼Ÿ\n",
      "å›ç­”ï¼šæ‚Ÿç©ºåœ¨è·å¾—ä¸‰æ˜§ç«ç”²åï¼ŒæˆåŠŸæŠµè¾¾äº†ä¸šç«å±±ã€‚\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "é—®é¢˜ï¼šæ‚Ÿç©ºä¸ºä»€ä¹ˆä¼šåœ¨å±±æ´ä¸­é†’æ¥ï¼Ÿ\n",
      "å›ç­”ï¼šæ‚Ÿç©ºåœ¨å±±æ´ä¸­é†’æ¥æ˜¯å› ä¸ºä»–åœ¨å¤©åº­æµ©åŠ«ä¸­è¢«å·å…¥ï¼Œå¤±å»äº†å¤§éƒ¨åˆ†æ³•åŠ›å’Œè®°å¿†ï¼Œéšåè¢«å°å°åœ¨å¹»ç•Œè¿™ä¸ªç‰¹æ®Šç©ºé—´é‡Œã€‚\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "=== å›ºå®šå‰åæ–‡æŸ¥è¯¢å¼•æ“çš„ç»“æœ ===\n",
      "\n",
      "é—®é¢˜ï¼šæ‚Ÿç©ºä»å¿˜å·å¯ºè·å¾—è®°å¿†åå‘ç”Ÿäº†ä»€ä¹ˆï¼Ÿ\n",
      "å›ç­”ï¼šæ‚Ÿç©ºä»å¿˜å·å¯ºè·å¾—è®°å¿†åï¼Œè€åƒ§æŒ‡å¼•ä»–å‰å¾€è¥¿æ–¹çš„ä¸šç«å±±ï¼Œé‚£é‡Œæœ‰ä¸€æ”¯é­”æ—æŒæ¡æ›´å¤šçœŸç›¸ã€‚ä¸ºäº†è¿›å…¥è¢«çƒˆç«åŒ…å›´çš„ä¸šç«å±±ï¼Œæ‚Ÿç©ºéœ€è¦å…ˆæ‰¾åˆ°ä¸‰æ˜§ç«ç”²ã€‚åœ¨å¯»æ‰¾è¿‡ç¨‹ä¸­ï¼Œä»–é‡åˆ°äº†å¦–ç‹ï¼Œå¾—çŸ¥å¤©åº­å´©å¡Œåå…­ç•Œç§©åºå¤§ä¹±ï¼Œå„æ–¹åŠ¿åŠ›å´›èµ·ï¼Œä¸€åœºæ›´å¤§çš„åŠ«éš¾æ­£åœ¨é…é…¿ã€‚è·å¾—ä¸‰æ˜§ç«ç”²åï¼Œæ‚Ÿç©ºæ½œå…¥ä¸šç«å±±ï¼Œåœ¨ä¸é­”æ—é¦–é¢†çš„å¯¹å†³ä¸­æƒ³èµ·äº†æ›´å¤šçœŸç›¸ï¼Œäº†è§£åˆ°å¹•åå¤è€åŠ¿åŠ›çš„ç›®æ ‡æ˜¯é‡å¡‘ä¸–ç•Œç§©åºã€‚å›åˆ°è€åƒ§èº«è¾¹åï¼Œæ‚Ÿç©ºæ‰“ç®—é›†ç»“åŠ›é‡å¯¹æŠ—ï¼Œä½†è€åƒ§æé†’ä»–äº‹æƒ…å¤æ‚ï¼Œé‡å¡‘ç§©åºå¹¶æ— æ ‡å‡†ç­”æ¡ˆï¼Œå»ºè®®ç»§ç»­å¯»æ‰¾çœŸç›¸ã€‚æ‚Ÿç©ºäºæ˜¯å†³å®šå‰å¾€å—æ–¹çš„æ²‰æ˜Ÿæµ·ï¼Œä½†åœ¨å‡ºå‘å‰ï¼Œå¹»ç•Œå‘ç”Ÿäº†å‰§çƒˆéœ‡åŠ¨ï¼Œä¼¼ä¹é¢„ç¤ºé‡å¤§å˜æ•…ã€‚\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "é—®é¢˜ï¼šæ‚Ÿç©ºæ˜¯å¦‚ä½•åˆ°è¾¾ä¸šç«å±±çš„ï¼Ÿ\n",
      "å›ç­”ï¼šæ‚Ÿç©ºåœ¨è·å¾—ä¸‰æ˜§ç«ç”²åï¼ŒæˆåŠŸæŠµè¾¾äº†ä¸šç«å±±ã€‚\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "é—®é¢˜ï¼šæ‚Ÿç©ºä¸ºä»€ä¹ˆä¼šåœ¨å±±æ´ä¸­é†’æ¥ï¼Ÿ\n",
      "å›ç­”ï¼šæ‚Ÿç©ºåœ¨å±±æ´ä¸­é†’æ¥æ˜¯å› ä¸ºä»–åœ¨500å¹´å‰å¤©åº­æµ©åŠ«ä¸­è¢«å·å…¥ï¼Œå¤±å»äº†å¤§éƒ¨åˆ†æ³•åŠ›å’Œè®°å¿†ï¼Œéšåè¢«å°å°åœ¨å¹»ç•Œè¿™ä¸ªä»‹äºç°å®ä¸è™šå¹»ä¹‹é—´çš„ç‰¹æ®Šç©ºé—´é‡Œã€‚\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "=== è‡ªåŠ¨å‰åæ–‡æŸ¥è¯¢å¼•æ“çš„ç»“æœ ===\n",
      "\n",
      "é—®é¢˜ï¼šæ‚Ÿç©ºä»å¿˜å·å¯ºè·å¾—è®°å¿†åå‘ç”Ÿäº†ä»€ä¹ˆï¼Ÿ\n",
      "> Postprocessor Predicted mode: next\n",
      "å›ç­”ï¼šæ‚Ÿç©ºä»å¿˜å·å¯ºè·å¾—è®°å¿†åï¼Œå‰å¾€è¥¿æ–¹çš„ä¸šç«å±±å¯»æ‰¾æ›´å¤šçœŸç›¸ï¼Œé€”ä¸­é‡åˆ°å¦–ç‹å¹¶å¾—çŸ¥å…­ç•Œç§©åºæ··ä¹±ï¼Œæ¥ç€æ‰¾åˆ°ä¸‰æ˜§ç«ç”²æ½œå…¥ä¸šç«å±±ï¼Œåœ¨ä¸é­”æ—é¦–é¢†çš„å¯¹å†³ä¸­è¿›ä¸€æ­¥äº†è§£äº†å¤è€åŠ¿åŠ›çš„æ„å›¾ã€‚\n",
      "\n",
      "\n",
      "é—®é¢˜ï¼šæ‚Ÿç©ºæ˜¯å¦‚ä½•åˆ°è¾¾ä¸šç«å±±çš„ï¼Ÿ\n",
      "> Postprocessor Predicted mode: next\n",
      "å›ç­”ï¼šæ‚Ÿç©ºåœ¨è·å¾—ä¸‰æ˜§ç«ç”²åï¼ŒæˆåŠŸæŠµè¾¾äº†ä¸šç«å±±ã€‚\n",
      "\n",
      "\n",
      "é—®é¢˜ï¼šæ‚Ÿç©ºä¸ºä»€ä¹ˆä¼šåœ¨å±±æ´ä¸­é†’æ¥ï¼Ÿ\n",
      "> Postprocessor Predicted mode: previous\n",
      "å›ç­”ï¼šæ‚Ÿç©ºåœ¨å±±æ´ä¸­é†’æ¥æ˜¯å› ä¸ºä»–åœ¨å¤©åº­æµ©åŠ«ä¸­è¢«å·å…¥ï¼Œå¤±å»äº†å¤§éƒ¨åˆ†æ³•åŠ›å’Œè®°å¿†ï¼Œéšåè¢«å°å°åœ¨å¹»ç•Œè¿™ä¸ªç‰¹æ®Šç©ºé—´é‡Œã€‚\n",
      "\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# ä¸´æ—¶ç»•è¿‡ torch.load å®‰å…¨æ£€æŸ¥ï¼ˆä»…ç”¨äºå¼€å‘ç¯å¢ƒï¼‰\n",
    "# æ³¨æ„ï¼šè¿™æ˜¯ä¸€ä¸ªä¸´æ—¶è§£å†³æ–¹æ¡ˆï¼Œç”Ÿäº§ç¯å¢ƒåº”è¯¥å‡çº§ torch åˆ° 2.6+ æˆ–ä½¿ç”¨ safetensors æ ¼å¼\n",
    "import transformers.utils.import_utils\n",
    "import transformers.modeling_utils\n",
    "\n",
    "def dummy_check():\n",
    "    pass\n",
    "\n",
    "transformers.utils.import_utils.check_torch_load_is_safe = dummy_check\n",
    "transformers.modeling_utils.check_torch_load_is_safe = dummy_check\n",
    "\n",
    "\n",
    "from llama_index.core import VectorStoreIndex, StorageContext, Document, Settings\n",
    "from llama_index.core.node_parser import SentenceSplitter\n",
    "from llama_index.core.storage.docstore import SimpleDocumentStore\n",
    "from llama_index.core.postprocessor import PrevNextNodePostprocessor, AutoPrevNextNodePostprocessor\n",
    "from llama_index.llms.deepseek import DeepSeek\n",
    "from llama_index.embeddings.huggingface import HuggingFaceEmbedding\n",
    "\n",
    "import os\n",
    "os.environ[\"DEEPSEEK_API_KEY\"] = \"sk-34b4****c05bb4f\"\n",
    "\n",
    "\n",
    "# é…ç½®å…¨å±€è®¾ç½®\n",
    "Settings.llm = DeepSeek(model=\"deepseek-chat\", temperature=0.1)\n",
    "Settings.embed_model = HuggingFaceEmbedding(model_name=\"BAAI/bge-small-zh\")\n",
    "Settings.node_parser = SentenceSplitter()\n",
    "# å‡†å¤‡æ¸¸æˆå‰§æƒ…æ–‡æœ¬\n",
    "game_story = \"\"\"æ‚Ÿç©ºåˆé†’æ—¶ï¼Œå‘ç°è‡ªå·±è¢«å›°åœ¨ä¸€åº§å¤è€çš„å±±æ´ä¸­ã€‚è®°å¿†æ¨¡ç³Šçš„ä»–åªè®°å¾—è‡ªå·±æ˜¯é½å¤©å¤§åœ£å­™æ‚Ÿç©ºï¼Œå´æƒ³ä¸èµ·ä¸ºä½•ä¼šåœ¨æ­¤å¤„ã€‚æ´ä¸­æœ‰ä¸€é¢ç ´ç¢çš„é•œå­ï¼Œé€è¿‡é•œå­ä»–çœ‹åˆ°è‡ªå·±ä¼¤ç—•ç´¯ç´¯ï¼Œæ˜”æ—¥çš„é‡‘ç®æ£’ä¹Ÿåªå‰©ä¸‹ä¸€æˆªæ–­æŸ„ã€‚ç¦»å¼€å±±æ´åï¼Œæ‚Ÿç©ºé‡åˆ°äº†ä¸€ä½ç¥ç§˜çš„è€åƒ§ã€‚è€åƒ§å‘Šè¯‰ä»–ï¼Œè¿™é‡Œæ˜¯â€œå¹»ç•Œâ€ï¼Œæ˜¯ä»‹äºç°å®ä¸è™šå¹»ä¹‹é—´çš„ç‰¹æ®Šç©ºé—´ã€‚500å¹´å‰ï¼Œå¤©åº­é­é‡äº†å‰æ‰€æœªæœ‰çš„æµ©åŠ«ï¼Œä¼—ç¥é™¨è½ï¼Œå¤©ç•Œå´©å¡Œã€‚å½“æ—¶æ­£åœ¨å¤§é—¹å¤©å®«çš„æ‚Ÿç©ºä¹Ÿè¢«å·å…¥å…¶ä¸­ï¼Œå¤±å»äº†å¤§éƒ¨åˆ†æ³•åŠ›å’Œè®°å¿†ï¼Œè¢«å°å°åœ¨è¿™ä¸ªä¸–ç•Œã€‚è€åƒ§å»ºè®®æ‚Ÿç©ºå»å¯»æ‰¾æ•£è½åœ¨å¹»ç•Œå„å¤„çš„è®°å¿†ç¢ç‰‡ã€‚ç¬¬ä¸€ç«™æ˜¯ä½äºä¸œæ–¹çš„å¿˜å·å¯ºï¼Œé‚£é‡Œä¾›å¥‰ç€ä¸€é¢è®°å¿†ä¹‹é•œï¼Œæˆ–è®¸èƒ½å¸®ä»–æ‰¾å›éƒ¨åˆ†è®°å¿†ã€‚ç„¶è€Œï¼Œå¿˜å·å¯ºå·²è¢«ä¸€ç¾¤é‚ªé­”å é¢†ï¼Œæ‚Ÿç©ºéœ€è¦å…ˆå‡»è´¥å®ƒä»¬ã€‚åœ¨å¿˜å·å¯ºï¼Œæ‚Ÿç©ºé€šè¿‡è®°å¿†ä¹‹é•œçœ‹åˆ°äº†å¤©åº­æµ©åŠ«çš„éƒ¨åˆ†åœºæ™¯ã€‚åŸæ¥æ˜¯ä¸€ä¸ªç¥ç§˜çš„å¤è€åŠ¿åŠ›åœ¨èƒŒåæ“çºµï¼Œä»–ä»¬åˆ©ç”¨äº†â€œä¼—ç”Ÿä¹‹æ„¿â€çš„åŠ›é‡ï¼Œæ‰­æ›²äº†å¤©åœ°è§„åˆ™ã€‚å½“æ—¶çš„æ‚Ÿç©ºè™½ç„¶å¼ºå¤§ï¼Œå´ä¹Ÿæ— æ³•é˜»æ­¢ç¾éš¾çš„å‘ç”Ÿã€‚è·å¾—è¿™äº›è®°å¿†åï¼Œè€åƒ§å‘Šè¯‰æ‚Ÿç©ºä¸‹ä¸€ç«™åº”è¯¥å‰å¾€è¥¿æ–¹çš„ä¸šç«å±±ã€‚é‚£é‡Œæœ‰ä¸€æ”¯èœ•å˜çš„é­”æ—ï¼Œä»–ä»¬æŒæ¡ç€æ›´å¤šçœŸç›¸ã€‚ä½†ä¸šç«å±±å¸¸å¹´è¢«ç†Šç†Šçƒˆç«åŒ…å›´ï¼Œæ™®é€šç”Ÿçµéš¾ä»¥é è¿‘ã€‚æ‚Ÿç©ºéœ€è¦å…ˆæ‰¾åˆ°ä¼ è¯´ä¸­çš„ä¸‰æ˜§ç«ç”²ï¼Œæ‰èƒ½å®‰å…¨è¿›å…¥ã€‚åœ¨å¯»æ‰¾ä¸‰æ˜§ç«ç”²çš„è¿‡ç¨‹ä¸­ï¼Œæ‚Ÿç©ºé‡åˆ°äº†æ˜”æ—¥çš„å¥½å‹å¦–ç‹ã€‚å¦–ç‹å‘Šè¯‰ä»–ï¼Œå¤©åº­å´©å¡Œåï¼Œå…­ç•Œç§©åºå¤§ä¹±ï¼Œå„æ–¹åŠ¿åŠ›çº·çº·å´›èµ·ã€‚æœ‰çš„æ‰“ç€é‡å»ºå¤©åº­çš„æ——å·ï¼Œæœ‰çš„åˆ™æƒ³å»ºç«‹å…¨æ–°çš„ç§©åºã€‚ä¸€åœºæ›´å¤§çš„åŠ«éš¾æ­£åœ¨é…é…¿ã€‚è·å¾—ä¸‰æ˜§ç«ç”²åï¼Œæ‚Ÿç©ºæˆåŠŸæ½œå…¥ä¸šç«å±±ã€‚åœ¨ä¸é­”æ—é¦–é¢†çš„å¯¹å†³ä¸­ï¼Œä»–ç»ˆäºæƒ³èµ·äº†æ›´å¤šçœŸç›¸ã€‚åŸæ¥é‚£ä¸ªå¤è€åŠ¿åŠ›çš„ç›®æ ‡å¹¶éç®€å•çš„ç ´åï¼Œè€Œæ˜¯æƒ³è¦é‡å¡‘æ•´ä¸ªä¸–ç•Œçš„è§„åˆ™ã€‚ä»–ä»¬è®¤ä¸ºç°æœ‰çš„ç§©åºå­˜åœ¨æ ¹æœ¬ç¼ºé™·ï¼Œå¯¼è‡´ä¼—ç”Ÿçš†è‹¦ã€‚å›åˆ°è€åƒ§èº«è¾¹ï¼Œæ‚Ÿç©ºè¡¨ç¤ºè¦é›†ç»“å„æ–¹åŠ›é‡å¯¹æŠ—é‚£ä¸ªå¹•ååŠ¿åŠ›ã€‚è€åƒ§å´å‘Šè¯‰ä»–ï¼Œäº‹æƒ…å¯èƒ½æ²¡æœ‰è¡¨é¢çœ‹èµ·æ¥é‚£ä¹ˆç®€å•ã€‚æ˜¯å¦åº”è¯¥é‡å¡‘ä¸–ç•Œç§©åºï¼Œè¿™ä¸ªé—®é¢˜å¹¶æ²¡æœ‰æ ‡å‡†ç­”æ¡ˆã€‚å»ºè®®æ‚Ÿç©ºç»§ç»­å¯»æ‰¾æ›´å¤šçœŸç›¸ï¼Œå†åšå†³å®šã€‚æ‚Ÿç©ºå†³å®šå¯ç¨‹å‰å¾€å—æ–¹çš„æ²‰æ˜Ÿæµ·ã€‚ä¼ è¯´é‚£é‡Œæœ‰ä¸€åº§å¤è€çš„å›¾ä¹¦é¦†ï¼Œæ”¶è—ç€å…³äºä¸–ç•Œèµ·æºçš„ä¼—å¤šå…¸ç±ã€‚ç„¶è€Œï¼Œåœ¨ä»–å‡ºå‘å‰ï¼Œå¹»ç•Œçªç„¶å‘ç”Ÿå‰§çƒˆéœ‡åŠ¨ï¼Œä¼¼ä¹æœ‰ä»€ä¹ˆå·¨å¤§çš„å˜æ•…å³å°†å‘ç”Ÿâ€¦â€¦\"\"\"\n",
    "# åˆ›å»ºDocumentå¯¹è±¡\n",
    "documents = [Document(text=game_story)]\n",
    "# æ„å»ºæ–‡æ¡£å­˜å‚¨å’Œç´¢å¼•ï¼Œå¹¶ä½¿ç”¨Settingsä¸­çš„node_parserè§£ææ–‡æ¡£\n",
    "nodes = Settings.node_parser.get_nodes_from_documents(documents)\n",
    "# åˆ›å»ºæ–‡æ¡£å­˜å‚¨å¹¶æ·»åŠ èŠ‚ç‚¹\n",
    "docstore = SimpleDocumentStore()\n",
    "docstore.add_documents(nodes)\n",
    "# åˆ›å»ºå­˜å‚¨ä¸Šä¸‹æ–‡\n",
    "storage_context = StorageContext.from_defaults(docstore=docstore)\n",
    "# æ„å»ºå‘é‡ç´¢å¼•\n",
    "index = VectorStoreIndex(nodes, storage_context=storage_context)\n",
    "# åˆ›å»ºä¸åŒçš„æŸ¥è¯¢å¼•æ“\n",
    "# åŸºç¡€æŸ¥è¯¢å¼•æ“\n",
    "base_engine = index.as_query_engine(\n",
    "    similarity_top_k=1,\n",
    "    response_mode=\"tree_summarize\"\n",
    ")\n",
    "# å¸¦å›ºå®šå‰åæ–‡çš„æŸ¥è¯¢å¼•æ“\n",
    "prev_next_engine = index.as_query_engine(\n",
    "    similarity_top_k=1,\n",
    "    node_postprocessors=[\n",
    "        PrevNextNodePostprocessor(docstore=docstore, num_nodes=2)\n",
    "    ],\n",
    "    response_mode=\"tree_summarize\"\n",
    ")\n",
    "# å¸¦è‡ªåŠ¨å‰åæ–‡çš„æŸ¥è¯¢å¼•æ“\n",
    "auto_engine = index.as_query_engine(\n",
    "    similarity_top_k=1,\n",
    "    node_postprocessors=[\n",
    "        AutoPrevNextNodePostprocessor(\n",
    "            docstore=docstore,\n",
    "            num_nodes=3,\n",
    "            verbose=True\n",
    "        )\n",
    "    ],\n",
    "    response_mode=\"tree_summarize\"\n",
    ")\n",
    "# æµ‹è¯•ä¸åŒç±»å‹çš„é—®é¢˜åŠä¸åŒçš„æŸ¥è¯¢å¼•æ“\n",
    "test_questions = [\n",
    "    \"æ‚Ÿç©ºä»å¿˜å·å¯ºè·å¾—è®°å¿†åå‘ç”Ÿäº†ä»€ä¹ˆï¼Ÿ\",  # åº”è¯¥æ‰¾åæ–‡\n",
    "    \"æ‚Ÿç©ºæ˜¯å¦‚ä½•åˆ°è¾¾ä¸šç«å±±çš„ï¼Ÿ\",  # åº”è¯¥æ‰¾å‰æ–‡\n",
    "    \"æ‚Ÿç©ºä¸ºä»€ä¹ˆä¼šåœ¨å±±æ´ä¸­é†’æ¥ï¼Ÿ\",  # åº”è¯¥æ‰¾å‰æ–‡\n",
    "]\n",
    "print(\"=== åŸºç¡€æŸ¥è¯¢å¼•æ“çš„ç»“æœ ===\")\n",
    "for question in test_questions:\n",
    "    print(f\"\\né—®é¢˜ï¼š{question}\")\n",
    "    response = base_engine.query(question)\n",
    "    print(f\"å›ç­”ï¼š{response}\\n\")\n",
    "    print(\"-\" * 50)\n",
    "print(\"\\n=== å›ºå®šå‰åæ–‡æŸ¥è¯¢å¼•æ“çš„ç»“æœ ===\")\n",
    "for question in test_questions:\n",
    "    print(f\"\\né—®é¢˜ï¼š{question}\")\n",
    "    response = prev_next_engine.query(question)\n",
    "    print(f\"å›ç­”ï¼š{response}\\n\")\n",
    "    print(\"-\" * 50)\n",
    "print(\"\\n=== è‡ªåŠ¨å‰åæ–‡æŸ¥è¯¢å¼•æ“çš„ç»“æœ ===\")\n",
    "for question in test_questions:\n",
    "    print(f\"\\né—®é¢˜ï¼š{question}\")\n",
    "    response = auto_engine.query(question)\n",
    "    print(f\"å›ç­”ï¼š{response}\\n\")\n",
    "print(\"-\" * 50)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fa86927",
   "metadata": {},
   "source": [
    "## æ„å»ºæœ‰å±‚æ¬¡çš„ç´¢å¼•"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c537d37",
   "metadata": {},
   "source": [
    "### åŒå±‚ç´¢å¼•-Milvus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "cca4b961",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "é—®é¢˜ï¼š2023å¹´ä¸–ç•Œé¦–å¯Œæ˜¯è°ï¼Ÿä»–çš„è´¢å¯Œæ˜¯å¤šå°‘ï¼Ÿ\n",
      "ç­”æ¡ˆï¼šæ ¹æ®è¡¨æ ¼ä¿¡æ¯ï¼Œ**2023å¹´ä¸–ç•Œé¦–å¯Œæ˜¯ä¼¯çº³å¾·Â·é˜¿å°”è¯ºåŠå…¶å®¶æ—ï¼ˆBernard Arnault & familyï¼‰**ï¼Œå…¶è´¢å¯Œå‡€å€¼ä¸º **2110äº¿ç¾å…ƒ**ã€‚  \n",
      "\n",
      "**è¯¦ç»†è¯´æ˜**ï¼š  \n",
      "1. è¡¨æ ¼ä¸­æ’åç¬¬ä¸€ï¼ˆNo. 1ï¼‰çš„å³ä¸ºä¼¯çº³å¾·Â·é˜¿å°”è¯ºï¼Œä»–æ˜¯æ³•å›½å¥¢ä¾ˆå“å·¨å¤´LVMHé›†å›¢çš„æŒé—¨äººã€‚  \n",
      "2. å…¶è´¢å¯Œå‡€å€¼æ˜ç¡®åˆ—ä¸ºâ€œ$211 billionâ€ï¼Œå³2110äº¿ç¾å…ƒã€‚  \n",
      "3. è¡¨æ ¼æ ‡é¢˜ä¸ºâ€œ2023å¹´10å¤§é¦–å¯Œâ€ï¼Œå› æ­¤è¯¥æ•°æ®åæ˜ çš„æ˜¯2023å¹´çš„æ’åæƒ…å†µã€‚  \n",
      "\n",
      "**ç­”æ¡ˆæ€»ç»“**ï¼š  \n",
      "- **å§“å**ï¼šä¼¯çº³å¾·Â·é˜¿å°”è¯ºåŠå…¶å®¶æ—  \n",
      "- **è´¢å¯Œ**ï¼š2110äº¿ç¾å…ƒ  \n",
      "- **å›½ç±**ï¼šæ³•å›½  \n",
      "- **è´¢å¯Œæ¥æº**ï¼šLVMHï¼ˆé…©æ‚¦Â·è½©å°¼è¯—ï¼è·¯æ˜“Â·å¨ç™»é›†å›¢ï¼‰\n"
     ]
    }
   ],
   "source": [
    "# åŒå±‚æ£€ç´¢-å¯Œè±ªæ¦œ - éœ€è¦pip install openpyxl\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import pandas as pd\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import torch\n",
    "from pymilvus import MilvusClient, DataType, FieldSchema, CollectionSchema\n",
    "import logging\n",
    "\n",
    "# è®¾ç½®æ—¥å¿—\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "\n",
    "# åŠ è½½ç¯å¢ƒå˜é‡\n",
    "load_dotenv()\n",
    "\n",
    "# åˆå§‹åŒ–åµŒå…¥æ¨¡å‹\n",
    "embedding_function = SentenceTransformer(\n",
    "    'BAAI/bge-m3',\n",
    "    device='cuda:0' if torch.cuda.is_available() else 'cpu',\n",
    "    trust_remote_code=True\n",
    ")\n",
    "\n",
    "# è¿æ¥åˆ°Milvus\n",
    "client = MilvusClient(\"richman_bge_m3_v2.db\")\n",
    "\n",
    "# 1. åˆ›å»ºsummaryå‘é‡æ•°æ®åº“\n",
    "summary_collection_name = \"billionaires_summary\"\n",
    "summary_fields = [\n",
    "    FieldSchema(name=\"id\", dtype=DataType.INT64, is_primary=True, auto_id=True),\n",
    "    FieldSchema(name=\"vector\", dtype=DataType.FLOAT_VECTOR, dim=1024),\n",
    "    FieldSchema(name=\"table_name\", dtype=DataType.VARCHAR, max_length=100)\n",
    "]\n",
    "\n",
    "summary_schema = CollectionSchema(summary_fields, \"å¯Œè±ªæ¦œå¹´ä»½æ‘˜è¦\")\n",
    "if not client.has_collection(summary_collection_name):\n",
    "    client.create_collection(\n",
    "        collection_name=summary_collection_name,\n",
    "        schema=summary_schema\n",
    "    )\n",
    "\n",
    "# 2. åˆ›å»ºdetailså‘é‡æ•°æ®åº“\n",
    "details_collection_name = \"billionaires_details\"\n",
    "details_fields = [\n",
    "    FieldSchema(name=\"id\", dtype=DataType.INT64, is_primary=True, auto_id=True),\n",
    "    FieldSchema(name=\"vector\", dtype=DataType.FLOAT_VECTOR, dim=1024),\n",
    "    FieldSchema(name=\"table_name\", dtype=DataType.VARCHAR, max_length=100),\n",
    "    FieldSchema(name=\"content\", dtype=DataType.VARCHAR, max_length=10000)  # å­˜å‚¨æ•´ä¸ªè¡¨æ ¼å†…å®¹\n",
    "]\n",
    "\n",
    "details_schema = CollectionSchema(details_fields, \"å¯Œè±ªæ¦œè¯¦ç»†ä¿¡æ¯\")\n",
    "if not client.has_collection(details_collection_name):\n",
    "    client.create_collection(\n",
    "        collection_name=details_collection_name,\n",
    "        schema=details_schema\n",
    "    )\n",
    "\n",
    "# 3. åŠ è½½Excelæ–‡ä»¶å¹¶å‡†å¤‡æ•°æ®\n",
    "excel_file = \"90-æ–‡æ¡£-Data/å¤æ‚PDF/åå¤§å¯Œè±ª/ä¸–ç•Œåå¤§å¯Œè±ª.xlsx\"\n",
    "\n",
    "# è¯»å–Excelæ–‡ä»¶ä¸­çš„æ‰€æœ‰sheetå¹¶æ’å…¥æ•°æ®\n",
    "with pd.ExcelFile(excel_file) as xls:\n",
    "    for sheet_name in xls.sheet_names:\n",
    "        try:\n",
    "            #df = pd.read_excel(xls, sheet_name=sheet_name)\n",
    "            df = pd.read_excel(xls, sheet_name=sheet_name, engine='openpyxl')\n",
    "            logging.info(f\"æ­£åœ¨å¤„ç†sheet: {sheet_name}\")\n",
    "            \n",
    "            # æ’å…¥summaryæ•°æ® - åªå­˜å‚¨è¡¨å\n",
    "            summary_embedding = embedding_function.encode([sheet_name])[0]\n",
    "            \n",
    "            client.insert(\n",
    "                collection_name=summary_collection_name,\n",
    "                data=[{\n",
    "                    \"vector\": summary_embedding.tolist(),\n",
    "                    \"table_name\": sheet_name\n",
    "                }]\n",
    "            )\n",
    "            \n",
    "            # æ’å…¥detailsæ•°æ® - å­˜å‚¨æ•´ä¸ªè¡¨æ ¼å†…å®¹\n",
    "            # å°†æ•´ä¸ªDataFrameè½¬æ¢ä¸ºå­—ç¬¦ä¸²\n",
    "            table_content = df.to_string(index=False)\n",
    "            detail_embedding = embedding_function.encode([table_content])[0]\n",
    "            \n",
    "            client.insert(\n",
    "                collection_name=details_collection_name,\n",
    "                data=[{\n",
    "                    \"vector\": detail_embedding.tolist(),\n",
    "                    \"table_name\": sheet_name,\n",
    "                    \"content\": table_content\n",
    "                }]\n",
    "            )\n",
    "            \n",
    "            logging.info(f\"æˆåŠŸå¤„ç†sheet: {sheet_name}\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            logging.error(f\"å¤„ç†sheet {sheet_name} æ—¶å‡ºé”™: {str(e)}\")\n",
    "            logging.error(f\"é”™è¯¯è¯¦æƒ…: {e.__class__.__name__}\")\n",
    "            continue\n",
    "\n",
    "# 4. åˆ›å»ºç´¢å¼•\n",
    "# åˆ é™¤å·²å­˜åœ¨çš„ç´¢å¼•ï¼ˆå¦‚æœæœ‰ï¼‰\n",
    "try:\n",
    "    client.drop_index(collection_name=summary_collection_name, index_name=\"vector\")\n",
    "except Exception as e:\n",
    "    logging.warning(f\"åˆ é™¤summaryç´¢å¼•æ—¶å‡ºé”™: {str(e)}\")\n",
    "\n",
    "try:\n",
    "    client.drop_index(collection_name=details_collection_name, index_name=\"vector\")\n",
    "except Exception as e:\n",
    "    logging.warning(f\"åˆ é™¤detailsç´¢å¼•æ—¶å‡ºé”™: {str(e)}\")\n",
    "\n",
    "# åˆ›å»ºæ–°ç´¢å¼•\n",
    "try:\n",
    "    # ä½¿ç”¨prepare_index_paramsæ–¹æ³•åˆ›å»ºç´¢å¼•å‚æ•°\n",
    "    summary_index_params = client.prepare_index_params()\n",
    "    summary_index_params.add_index(\n",
    "        field_name=\"vector\",  # æŒ‡å®šè¦ä¸ºå“ªä¸ªå­—æ®µåˆ›å»ºç´¢å¼•ï¼Œè¿™é‡Œæ˜¯å‘é‡å­—æ®µ\n",
    "        index_type=\"IVF_FLAT\",  # ç´¢å¼•ç±»å‹\n",
    "        metric_type=\"COSINE\",  # ä½¿ç”¨ä½™å¼¦ç›¸ä¼¼åº¦ä½œä¸ºå‘é‡ç›¸ä¼¼åº¦åº¦é‡æ–¹å¼\n",
    "        params={\"nlist\": 1024}  # ç´¢å¼•å‚æ•°\n",
    "    )\n",
    "    \n",
    "    client.create_index(\n",
    "        collection_name=summary_collection_name,\n",
    "        index_params=summary_index_params\n",
    "    )\n",
    "    logging.info(\"æˆåŠŸåˆ›å»ºsummaryç´¢å¼•\")\n",
    "except Exception as e:\n",
    "    logging.error(f\"åˆ›å»ºsummaryç´¢å¼•æ—¶å‡ºé”™: {str(e)}\")\n",
    "\n",
    "try:\n",
    "    # ä½¿ç”¨prepare_index_paramsæ–¹æ³•åˆ›å»ºç´¢å¼•å‚æ•°\n",
    "    details_index_params = client.prepare_index_params()\n",
    "    details_index_params.add_index(\n",
    "        field_name=\"vector\",  # æŒ‡å®šè¦ä¸ºå“ªä¸ªå­—æ®µåˆ›å»ºç´¢å¼•ï¼Œè¿™é‡Œæ˜¯å‘é‡å­—æ®µ\n",
    "        index_type=\"IVF_FLAT\",  # ç´¢å¼•ç±»å‹\n",
    "        metric_type=\"COSINE\",  # ä½¿ç”¨ä½™å¼¦ç›¸ä¼¼åº¦ä½œä¸ºå‘é‡ç›¸ä¼¼åº¦åº¦é‡æ–¹å¼\n",
    "        params={\"nlist\": 1024}  # ç´¢å¼•å‚æ•°\n",
    "    )\n",
    "    \n",
    "    client.create_index(\n",
    "        collection_name=details_collection_name,\n",
    "        index_params=details_index_params\n",
    "    )\n",
    "    logging.info(\"æˆåŠŸåˆ›å»ºdetailsç´¢å¼•\")\n",
    "except Exception as e:\n",
    "    logging.error(f\"åˆ›å»ºdetailsç´¢å¼•æ—¶å‡ºé”™: {str(e)}\")\n",
    "\n",
    "# åŠ è½½é›†åˆä»¥ä½¿ç´¢å¼•ç”Ÿæ•ˆ\n",
    "try:\n",
    "    client.load_collection(summary_collection_name)\n",
    "    client.load_collection(details_collection_name)\n",
    "    logging.info(\"æˆåŠŸåŠ è½½é›†åˆ\")\n",
    "except Exception as e:\n",
    "    logging.error(f\"åŠ è½½é›†åˆæ—¶å‡ºé”™: {str(e)}\")\n",
    "\n",
    "def search_relevant_table(question):\n",
    "    # ç¬¬ä¸€å±‚æ£€ç´¢ï¼šåœ¨summaryé›†åˆä¸­æœç´¢æœ€ç›¸å…³çš„sheet\n",
    "    query_embedding = embedding_function.encode([question])[0]\n",
    "    \n",
    "    summary_results = client.search(\n",
    "        collection_name=summary_collection_name,\n",
    "        data=[query_embedding.tolist()],\n",
    "        limit=1,\n",
    "        output_fields=[\"table_name\"],\n",
    "        search_params={\n",
    "            \"metric_type\": \"COSINE\",\n",
    "            \"params\": {\"nprobe\": 10}\n",
    "        }\n",
    "    )\n",
    "    \n",
    "    if not summary_results or not summary_results[0]:\n",
    "        return None, None\n",
    "    \n",
    "    matched_table = summary_results[0][0]['entity']['table_name']\n",
    "    \n",
    "    # ç¬¬äºŒå±‚æ£€ç´¢ï¼šåœ¨detailsé›†åˆä¸­æœç´¢å…·ä½“ä¿¡æ¯\n",
    "    details_results = client.search(\n",
    "        collection_name=details_collection_name,\n",
    "        data=[query_embedding.tolist()],\n",
    "        filter=f\"table_name == '{matched_table}'\",\n",
    "        limit=1,\n",
    "        output_fields=[\"content\"],\n",
    "        search_params={\n",
    "            \"metric_type\": \"COSINE\",\n",
    "            \"params\": {\"nprobe\": 10}\n",
    "        }\n",
    "    )\n",
    "    \n",
    "    if not details_results or not details_results[0]:\n",
    "        return None, None\n",
    "    \n",
    "    return matched_table, details_results[0][0]['entity']['content']\n",
    "\n",
    "def generate_answer(question):\n",
    "    # æ£€ç´¢ç›¸å…³ä¿¡æ¯\n",
    "    table_name, content = search_relevant_table(question)\n",
    "    \n",
    "    if not table_name or not content:\n",
    "        return \"æŠ±æ­‰ï¼Œæ²¡æœ‰æ‰¾åˆ°ç›¸å…³ä¿¡æ¯ã€‚\"\n",
    "    \n",
    "    # æ„å»ºæç¤ºè¯\n",
    "    prompt = f\"\"\"æ ¹æ®ä»¥ä¸‹è¡¨æ ¼ä¿¡æ¯å›ç­”é—®é¢˜ï¼š\n",
    "\n",
    "è¡¨æ ¼åç§°ï¼š{table_name}\n",
    "\n",
    "è¡¨æ ¼å†…å®¹ï¼š\n",
    "{content}\n",
    "\n",
    "é—®é¢˜ï¼š{question}\n",
    "\n",
    "è¯·åŸºäºä»¥ä¸Šä¿¡æ¯ç»™å‡ºè¯¦ç»†å›ç­”ï¼š\"\"\"\n",
    "\n",
    "    # ä½¿ç”¨DeepSeekç”Ÿæˆç­”æ¡ˆ\n",
    "    from openai import OpenAI\n",
    "    client = OpenAI(\n",
    "        api_key=\"sk-34b4f11441fc4182a2509ed6dc05bb4f\",\n",
    "        base_url=\"https://api.deepseek.com/v1\"\n",
    "    )\n",
    "\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"deepseek-chat\",\n",
    "        messages=[{\n",
    "            \"role\": \"user\",\n",
    "            \"content\": prompt\n",
    "        }],\n",
    "        max_tokens=1024\n",
    "    )\n",
    "    \n",
    "    return response.choices[0].message.content\n",
    "\n",
    "# æµ‹è¯•ç¤ºä¾‹\n",
    "if __name__ == \"__main__\":\n",
    "    test_question = \"2023å¹´ä¸–ç•Œé¦–å¯Œæ˜¯è°ï¼Ÿä»–çš„è´¢å¯Œæ˜¯å¤šå°‘ï¼Ÿ\"\n",
    "    answer = generate_answer(test_question)\n",
    "    print(f\"é—®é¢˜ï¼š{test_question}\")\n",
    "    print(f\"ç­”æ¡ˆï¼š{answer}\") "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ef4f99d",
   "metadata": {},
   "source": [
    "### åŒå±‚ç´¢å¼•-PandasNode"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ba15cfd",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4069b0ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;3;34mRetrieving with query id None: 2020å¹´ä¸–ç•Œé¦–å¯Œæ˜¯è°ï¼Ÿä»–çš„è´¢å¯Œæ˜¯å¤šå°‘ï¼Ÿ\n",
      "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: pandas2\n",
      "\u001b[0m\u001b[1;3;34mRetrieving with query id pandas2: 2020å¹´ä¸–ç•Œé¦–å¯Œæ˜¯è°ï¼Ÿä»–çš„è´¢å¯Œæ˜¯å¤šå°‘ï¼Ÿ\n",
      "\u001b[0m\u001b[1;3;32mGot response: Name           Jeff Bezos\n",
      "Net_Worth    $177Â billion\n",
      "Name: 0, dtype: object\n",
      "\u001b[0mé—®é¢˜ï¼š2020å¹´ä¸–ç•Œé¦–å¯Œæ˜¯è°ï¼Ÿä»–çš„è´¢å¯Œæ˜¯å¤šå°‘ï¼Ÿ\n",
      "ç­”æ¡ˆï¼š2020å¹´ä¸–ç•Œé¦–å¯Œæ˜¯æ°å¤«Â·è´ç´¢æ–¯ï¼Œä»–çš„è´¢å¯Œä¸º1770äº¿ç¾å…ƒã€‚\n"
     ]
    }
   ],
   "source": [
    "# åŒå±‚æ£€ç´¢-å¯Œè±ªæ¦œ - éœ€è¦pip install openpyxl\n",
    "\n",
    "# ä¸´æ—¶ç»•è¿‡ torch.load å®‰å…¨æ£€æŸ¥ï¼ˆä»…ç”¨äºå¼€å‘ç¯å¢ƒï¼‰\n",
    "import transformers.utils.import_utils\n",
    "import transformers.modeling_utils\n",
    "\n",
    "def dummy_check():\n",
    "    pass\n",
    "\n",
    "transformers.utils.import_utils.check_torch_load_is_safe = dummy_check\n",
    "transformers.modeling_utils.check_torch_load_is_safe = dummy_check\n",
    "\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import pandas as pd\n",
    "import logging\n",
    "from llama_index.core import Document, VectorStoreIndex\n",
    "from llama_index.core.node_parser import SentenceSplitter\n",
    "from llama_index.core.schema import IndexNode\n",
    "from llama_index.experimental.query_engine import PandasQueryEngine\n",
    "from llama_index.core.retrievers import RecursiveRetriever\n",
    "from llama_index.core.query_engine import RetrieverQueryEngine\n",
    "from llama_index.core import get_response_synthesizer\n",
    "from llama_index.llms.openai import OpenAI\n",
    "from llama_index.embeddings.openai import OpenAIEmbedding\n",
    "from llama_index.core import Settings\n",
    "\n",
    "from llama_index.llms.deepseek import DeepSeek\n",
    "from llama_index.embeddings.huggingface import HuggingFaceEmbedding\n",
    "\n",
    "# è®¾ç½®æ—¥å¿—\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "\n",
    "# åŠ è½½ç¯å¢ƒå˜é‡\n",
    "load_dotenv()\n",
    "\n",
    "import os\n",
    "os.environ[\"DEEPSEEK_API_KEY\"] = \"sk-34b***c05bb4f\"\n",
    "\n",
    "# è®¾ç½®å…¨å±€è®¾ç½® - ä½¿ç”¨ DeepSeek å’Œ HuggingFace\n",
    "Settings.llm = DeepSeek(model=\"deepseek-chat\", temperature=0.1)\n",
    "Settings.embed_model = HuggingFaceEmbedding(model_name=\"BAAI/bge-small-zh\")\n",
    "\n",
    "# 3. åŠ è½½Excelæ–‡ä»¶å¹¶å‡†å¤‡æ•°æ®\n",
    "excel_file = \"90-æ–‡æ¡£-Data/å¤æ‚PDF/åå¤§å¯Œè±ª/ä¸–ç•Œåå¤§å¯Œè±ª.xlsx\"\n",
    "\n",
    "# åˆå§‹åŒ–Node Parser\n",
    "node_parser = SentenceSplitter(\n",
    "    chunk_size=1024,  # æ¯ä¸ªchunkçš„å¤§å°\n",
    "    chunk_overlap=20,  # chunkä¹‹é—´çš„é‡å å¤§å°\n",
    "    include_metadata=True  # åŒ…å«å…ƒæ•°æ®\n",
    ")\n",
    "\n",
    "# å­˜å‚¨æ‰€æœ‰è¡¨æ ¼çš„DataFrameå’ŒæŸ¥è¯¢å¼•æ“\n",
    "table_dfs = []\n",
    "df_query_engines = []\n",
    "documents = []\n",
    "\n",
    "# è¯»å–Excelæ–‡ä»¶ä¸­çš„æ‰€æœ‰sheetå¹¶æ’å…¥æ•°æ®\n",
    "with pd.ExcelFile(excel_file) as xls:\n",
    "    for sheet_name in xls.sheet_names:\n",
    "        try:\n",
    "            df = pd.read_excel(xls, sheet_name=sheet_name)\n",
    "            logging.info(f\"æ­£åœ¨å¤„ç†sheet: {sheet_name}\")\n",
    "            \n",
    "            # å°†DataFrameè½¬æ¢ä¸ºå­—ç¬¦ä¸²\n",
    "            table_content = df.to_string(index=False)\n",
    "            \n",
    "            # åˆ›å»ºDocumentå¯¹è±¡\n",
    "            doc = Document(\n",
    "                text=table_content,\n",
    "                metadata={\"table_name\": sheet_name}\n",
    "            )\n",
    "            documents.append(doc)\n",
    "            \n",
    "            # å­˜å‚¨DataFrameå’Œåˆ›å»ºæŸ¥è¯¢å¼•æ“\n",
    "            table_dfs.append(df)\n",
    "            df_query_engine = PandasQueryEngine(df, llm=Settings.llm)\n",
    "            df_query_engines.append(df_query_engine)\n",
    "            \n",
    "            logging.info(f\"æˆåŠŸå¤„ç†sheet: {sheet_name}\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            logging.error(f\"å¤„ç†sheet {sheet_name} æ—¶å‡ºé”™: {str(e)}\")\n",
    "            logging.error(f\"é”™è¯¯è¯¦æƒ…: {e.__class__.__name__}\")\n",
    "            continue\n",
    "\n",
    "# åˆ›å»ºIndexNodeå¯¹è±¡\n",
    "summaries = [\n",
    "    f\"This node provides information about the world's richest billionaires in {sheet_name}\"\n",
    "    for sheet_name in xls.sheet_names\n",
    "]\n",
    "\n",
    "df_nodes = [\n",
    "    IndexNode(text=summary, index_id=f\"pandas{idx}\") # æ¯ä¸ªè¡¨çš„ç»†èŠ‚\n",
    "    for idx, summary in enumerate(summaries)\n",
    "]\n",
    "\n",
    "# åˆ›å»ºæŸ¥è¯¢å¼•æ“æ˜ å°„\n",
    "df_id_query_engine_mapping = {\n",
    "    f\"pandas{idx}\": df_query_engine\n",
    "    for idx, df_query_engine in enumerate(df_query_engines)\n",
    "}\n",
    "\n",
    "# åˆ›å»ºå‘é‡ç´¢å¼• - åªä½¿ç”¨ df_nodesï¼Œä¸åŒ…å«åŸå§‹æ–‡æ¡£\n",
    "vector_index = VectorStoreIndex(df_nodes)\n",
    "vector_retriever = vector_index.as_retriever(similarity_top_k=1)\n",
    "\n",
    "# åˆ›å»ºé€’å½’æ£€ç´¢å™¨\n",
    "recursive_retriever = RecursiveRetriever(\n",
    "    \"vector\",\n",
    "    retriever_dict={\"vector\": vector_retriever},\n",
    "    query_engine_dict=df_id_query_engine_mapping,\n",
    "    verbose=True,\n",
    ")\n",
    "\n",
    "# åˆ›å»ºå“åº”åˆæˆå™¨\n",
    "response_synthesizer = get_response_synthesizer(response_mode=\"compact\")\n",
    "\n",
    "# åˆ›å»ºæŸ¥è¯¢å¼•æ“\n",
    "query_engine = RetrieverQueryEngine.from_args(\n",
    "    recursive_retriever, response_synthesizer=response_synthesizer\n",
    ")\n",
    "\n",
    "def generate_answer(question):\n",
    "    # ä½¿ç”¨æŸ¥è¯¢å¼•æ“ç”Ÿæˆç­”æ¡ˆ\n",
    "    response = query_engine.query(question)\n",
    "    return str(response)\n",
    "\n",
    "# æµ‹è¯•ç¤ºä¾‹\n",
    "if __name__ == \"__main__\":\n",
    "    test_question = \"2020å¹´ä¸–ç•Œé¦–å¯Œæ˜¯è°ï¼Ÿä»–çš„è´¢å¯Œæ˜¯å¤šå°‘ï¼Ÿ\"\n",
    "    answer = generate_answer(test_question)\n",
    "    print(f\"é—®é¢˜ï¼š{test_question}\")\n",
    "    print(f\"ç­”æ¡ˆï¼š{answer}\") "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdfd2495",
   "metadata": {},
   "source": [
    "### åŒå±‚ç´¢å¼• FAISS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ae74d781",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "é—®é¢˜ï¼š2023å¹´ä¸–ç•Œé¦–å¯Œæ˜¯è°ï¼Ÿä»–çš„è´¢å¯Œæ˜¯å¤šå°‘ï¼Ÿ\n",
      "ç­”æ¡ˆï¼šæ ¹æ®æä¾›çš„2023å¹´ä¸–ç•Œåå¤§å¯Œè±ªæ¦œå•ä¿¡æ¯ï¼Œ**2023å¹´ä¸–ç•Œé¦–å¯Œæ˜¯ä¼¯çº³å¾·Â·é˜¿å°”è¯ºåŠå…¶å®¶æ—ï¼ˆBernard Arnault & familyï¼‰**ã€‚  \n",
      "\n",
      "ä»–çš„è´¢å¯Œå‡€å€¼ä¸º **2110äº¿ç¾å…ƒ**ï¼ˆ$211 billionï¼‰ï¼Œå¹´é¾„74å²ï¼Œå›½ç±ä¸ºæ³•å›½ï¼Œè´¢å¯Œä¸»è¦æ¥æºäºå¥¢ä¾ˆå“é›†å›¢LVMHã€‚  \n",
      "\n",
      "å› æ­¤ï¼Œç­”æ¡ˆæ˜¯ï¼š  \n",
      "- **é¦–å¯Œ**ï¼šä¼¯çº³å¾·Â·é˜¿å°”è¯ºåŠå…¶å®¶æ—  \n",
      "- **è´¢å¯Œ**ï¼š2110äº¿ç¾å…ƒ\n"
     ]
    }
   ],
   "source": [
    "# ä¸´æ—¶ç»•è¿‡ torch.load å®‰å…¨æ£€æŸ¥ï¼ˆä»…ç”¨äºå¼€å‘ç¯å¢ƒï¼‰\n",
    "import transformers.utils.import_utils\n",
    "import transformers.modeling_utils\n",
    "\n",
    "def dummy_check():\n",
    "    pass\n",
    "\n",
    "transformers.utils.import_utils.check_torch_load_is_safe = dummy_check\n",
    "transformers.modeling_utils.check_torch_load_is_safe = dummy_check\n",
    "\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import pandas as pd\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import faiss\n",
    "import numpy as np\n",
    "from openai import OpenAI\n",
    "\n",
    "# åŠ è½½ç¯å¢ƒå˜é‡\n",
    "load_dotenv()\n",
    "\n",
    "# 1. å‡†å¤‡è¡¨æ ¼è¯´æ˜æ•°æ®\n",
    "table_descriptions = [\n",
    "    \"2023å¹´ä¸–ç•Œåå¤§å¯Œè±ªæ¦œå•ï¼Œå±•ç¤ºäº†å½“å¹´å…¨çƒæœ€å¯Œæœ‰çš„åä½å¯Œè±ªåŠå…¶è´¢å¯Œæƒ…å†µã€‚\",\n",
    "    \"2022å¹´ä¸–ç•Œåå¤§å¯Œè±ªæ¦œå•ï¼Œè®°å½•äº†å½“å¹´å…¨çƒæœ€å¯Œæœ‰çš„åä½å¯Œè±ªåŠå…¶è´¢å¯Œæƒ…å†µã€‚\",\n",
    "    \"2021å¹´ä¸–ç•Œåå¤§å¯Œè±ªæ¦œå•ï¼Œå±•ç¤ºäº†å½“å¹´å…¨çƒæœ€å¯Œæœ‰çš„åä½å¯Œè±ªåŠå…¶è´¢å¯Œæƒ…å†µã€‚\",\n",
    "    \"2020å¹´ä¸–ç•Œåå¤§å¯Œè±ªæ¦œå•ï¼Œè®°å½•äº†å½“å¹´å…¨çƒæœ€å¯Œæœ‰çš„åä½å¯Œè±ªåŠå…¶è´¢å¯Œæƒ…å†µã€‚\",\n",
    "    \"2019å¹´ä¸–ç•Œåå¤§å¯Œè±ªæ¦œå•ï¼Œå±•ç¤ºäº†å½“å¹´å…¨çƒæœ€å¯Œæœ‰çš„åä½å¯Œè±ªåŠå…¶è´¢å¯Œæƒ…å†µã€‚\"\n",
    "]\n",
    "\n",
    "# 2. è®¾ç½®ç¬¬ä¸€å±‚åµŒå…¥æ¨¡å‹ï¼ˆç”¨äºåŒ¹é…å¹´ä»½ï¼‰\n",
    "model = SentenceTransformer('sentence-transformers/all-MiniLM-L6-v2')\n",
    "desc_embeddings = model.encode(table_descriptions)\n",
    "\n",
    "# 3. åˆ›å»ºç¬¬ä¸€å±‚å‘é‡å­˜å‚¨\n",
    "dimension = desc_embeddings.shape[1]\n",
    "desc_index = faiss.IndexFlatL2(dimension)\n",
    "desc_index.add(desc_embeddings.astype('float32'))\n",
    "\n",
    "# 4. åŠ è½½Excelæ–‡ä»¶å¹¶å‡†å¤‡ç¬¬äºŒå±‚æ•°æ®\n",
    "excel_file = \"90-æ–‡æ¡£-Data/å¤æ‚PDF/åå¤§å¯Œè±ª/ä¸–ç•Œåå¤§å¯Œè±ª.xlsx\"\n",
    "all_tables_data = {}\n",
    "sheet_names_list = []\n",
    "\n",
    "# è¯»å–Excelæ–‡ä»¶ä¸­çš„æ‰€æœ‰sheet\n",
    "with pd.ExcelFile(excel_file) as xls:\n",
    "    sheet_names_list = xls.sheet_names\n",
    "    for sheet_name in sheet_names_list:\n",
    "        df = pd.read_excel(xls, sheet_name=sheet_name)\n",
    "        # å°†DataFrameè½¬æ¢ä¸ºæ–‡æœ¬æ ¼å¼\n",
    "        table_text = df.to_string(index=False)\n",
    "        all_tables_data[sheet_name] = table_text\n",
    "\n",
    "# 5. åˆ›å»ºç¬¬äºŒå±‚å‘é‡å­˜å‚¨\n",
    "table_embeddings = model.encode(list(all_tables_data.values()))\n",
    "table_index = faiss.IndexFlatL2(dimension)\n",
    "table_index.add(table_embeddings.astype('float32'))\n",
    "\n",
    "def search_relevant_table(question):\n",
    "    # ç¬¬ä¸€å±‚æ£€ç´¢ï¼šåŒ¹é…å¹´ä»½æè¿°\n",
    "    query_embedding = model.encode([question])[0]\n",
    "    distances, indices = desc_index.search(\n",
    "        np.array([query_embedding]).astype('float32'), \n",
    "        k=1\n",
    "    )\n",
    "    matched_index = indices[0][0]\n",
    "    \n",
    "    # è·å–å¯¹åº”çš„ sheet åç§°\n",
    "    matched_sheet_name = sheet_names_list[matched_index]\n",
    "    \n",
    "    # è¿”å›åŒ¹é…çš„æè¿°å’Œè¡¨æ ¼æ•°æ®\n",
    "    return table_descriptions[matched_index], all_tables_data[matched_sheet_name]\n",
    "\n",
    "def generate_answer(question):\n",
    "    # æ£€ç´¢ç›¸å…³ä¿¡æ¯\n",
    "    year_context, table_context = search_relevant_table(question)\n",
    "    \n",
    "    # æ„å»ºæç¤ºè¯\n",
    "    prompt = f\"\"\"æ ¹æ®ä»¥ä¸‹å‚è€ƒä¿¡æ¯å›ç­”é—®é¢˜ï¼š\n",
    "    \n",
    "å¹´ä»½ä¿¡æ¯ï¼š{year_context}\n",
    "\n",
    "ç›¸å…³æ•°æ®ï¼š\n",
    "{table_context}\n",
    "\n",
    "é—®é¢˜ï¼š{question}\n",
    "\n",
    "è¯·åŸºäºä»¥ä¸Šä¿¡æ¯ç»™å‡ºè¯¦ç»†å›ç­”ï¼š\"\"\"\n",
    "\n",
    "    # ä½¿ç”¨DeepSeekç”Ÿæˆç­”æ¡ˆ\n",
    "    client = OpenAI(\n",
    "        api_key=\"sk-34b4f11441fc4182a2509ed6dc05bb4f\",\n",
    "        base_url=\"https://api.deepseek.com/v1\"\n",
    "    )\n",
    "\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"deepseek-chat\",\n",
    "        messages=[{\n",
    "            \"role\": \"user\",\n",
    "            \"content\": prompt\n",
    "        }],\n",
    "        max_tokens=1024\n",
    "    )\n",
    "    \n",
    "    return response.choices[0].message.content\n",
    "\n",
    "# æµ‹è¯•ç¤ºä¾‹\n",
    "if __name__ == \"__main__\":\n",
    "    test_question = \"2023å¹´ä¸–ç•Œé¦–å¯Œæ˜¯è°ï¼Ÿä»–çš„è´¢å¯Œæ˜¯å¤šå°‘ï¼Ÿ\"\n",
    "    answer = generate_answer(test_question)\n",
    "    print(f\"é—®é¢˜ï¼š{test_question}\")\n",
    "    print(f\"ç­”æ¡ˆï¼š{answer}\") "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
