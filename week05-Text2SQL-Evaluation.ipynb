{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "71c1e549",
   "metadata": {},
   "source": [
    "# æ„å»ºè¯„ä¼°ä½“ç³»"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22021381",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“‚ åŠ è½½è¯„ä¼°æ•°æ®é›†: 90-æ–‡æ¡£-Data/sakila/q2sql_pairs.json\n",
      "âœ“ åŠ è½½äº† 36 ä¸ªé—®ç­”å¯¹\n",
      "\n",
      "================================================================================\n",
      "å¼€å§‹è¯„ä¼° 10 ä¸ªæ ·æœ¬\n",
      "================================================================================\n",
      "\n",
      "[1/10] \n",
      "================================================================================\n",
      "é—®é¢˜: List all actors with their IDs and names.\n",
      "æ ‡å‡†SQL: SELECT actor_id, first_name, last_name FROM actor;\n",
      "ç”ŸæˆSQL: select actor_id, actor_name from actors\n",
      "\n",
      "è¯„ä¼°ç»“æœ:\n",
      "  âœ“ ç²¾ç¡®åŒ¹é…: å¦\n",
      "  âœ“ å­—ç¬¦ä¸²ç›¸ä¼¼åº¦: 79.55%\n",
      "  âœ“ SQLæœ‰æ•ˆæ€§: å¦\n",
      "  âœ“ æ‰§è¡Œç»“æœåŒ¹é…: å¦\n",
      "\n",
      "  ğŸ“Š å¬å›ç‡æŒ‡æ ‡:\n",
      "    - è¡¨åå¬å›ç‡: 0.00% (F1: 0.00%)\n",
      "    - åˆ—åå¬å›ç‡: 33.33% (F1: 40.00%)\n",
      "    - å…³é”®è¯å¬å›ç‡: 100.00% (F1: 100.00%)\n",
      "    - Tokenå¬å›ç‡: 50.00% (F1: 54.55%)\n",
      "    - ç»¼åˆå¬å›ç‡: 40.00% (F1: 43.22%)\n",
      "\n",
      "[2/10] \n",
      "================================================================================\n",
      "é—®é¢˜: Add a new actor named 'John Doe'.\n",
      "æ ‡å‡†SQL: INSERT INTO actor (first_name, last_name) VALUES ('John', 'Doe');\n",
      "ç”ŸæˆSQL: insert into actors (name) values ('john doe')\n",
      "\n",
      "è¯„ä¼°ç»“æœ:\n",
      "  âœ“ ç²¾ç¡®åŒ¹é…: å¦\n",
      "  âœ“ å­—ç¬¦ä¸²ç›¸ä¼¼åº¦: 80.73%\n",
      "  âœ“ SQLæœ‰æ•ˆæ€§: å¦\n",
      "  âœ“ æ‰§è¡Œç»“æœåŒ¹é…: å¦\n",
      "\n",
      "  ğŸ“Š å¬å›ç‡æŒ‡æ ‡:\n",
      "    - è¡¨åå¬å›ç‡: 100.00% (F1: 0.00%)\n",
      "    - åˆ—åå¬å›ç‡: 100.00% (F1: 100.00%)\n",
      "    - å…³é”®è¯å¬å›ç‡: 100.00% (F1: 100.00%)\n",
      "    - Tokenå¬å›ç‡: 62.50% (F1: 66.67%)\n",
      "    - ç»¼åˆå¬å›ç‡: 92.50% (F1: 75.85%)\n",
      "\n",
      "[3/10] \n",
      "================================================================================\n",
      "é—®é¢˜: Update the last name of actor with ID 1 to 'Smith'.\n",
      "æ ‡å‡†SQL: UPDATE actor SET last_name = 'Smith' WHERE actor_id = 1;\n",
      "ç”ŸæˆSQL: update actors set last_name = 'smith' where actor_id = 1\n",
      "\n",
      "è¯„ä¼°ç»“æœ:\n",
      "  âœ“ ç²¾ç¡®åŒ¹é…: å¦\n",
      "  âœ“ å­—ç¬¦ä¸²ç›¸ä¼¼åº¦: 99.10%\n",
      "  âœ“ SQLæœ‰æ•ˆæ€§: å¦\n",
      "  âœ“ æ‰§è¡Œç»“æœåŒ¹é…: å¦\n",
      "\n",
      "  ğŸ“Š å¬å›ç‡æŒ‡æ ‡:\n",
      "    - è¡¨åå¬å›ç‡: 100.00% (F1: 0.00%)\n",
      "    - åˆ—åå¬å›ç‡: 100.00% (F1: 100.00%)\n",
      "    - å…³é”®è¯å¬å›ç‡: 100.00% (F1: 100.00%)\n",
      "    - Tokenå¬å›ç‡: 87.50% (F1: 87.50%)\n",
      "    - ç»¼åˆå¬å›ç‡: 97.50% (F1: 79.77%)\n",
      "\n",
      "[4/10] \n",
      "================================================================================\n",
      "é—®é¢˜: Delete the actor with ID 2.\n",
      "æ ‡å‡†SQL: DELETE FROM actor WHERE actor_id = 2;\n",
      "ç”ŸæˆSQL: delete from actor where actor_id = 2\n",
      "\n",
      "è¯„ä¼°ç»“æœ:\n",
      "  âœ“ ç²¾ç¡®åŒ¹é…: æ˜¯\n",
      "  âœ“ å­—ç¬¦ä¸²ç›¸ä¼¼åº¦: 100.00%\n",
      "  âœ“ SQLæœ‰æ•ˆæ€§: å¦\n",
      "  âœ“ æ‰§è¡Œç»“æœåŒ¹é…: å¦\n",
      "\n",
      "  ğŸ“Š å¬å›ç‡æŒ‡æ ‡:\n",
      "    - è¡¨åå¬å›ç‡: 100.00% (F1: 100.00%)\n",
      "    - åˆ—åå¬å›ç‡: 100.00% (F1: 100.00%)\n",
      "    - å…³é”®è¯å¬å›ç‡: 100.00% (F1: 100.00%)\n",
      "    - Tokenå¬å›ç‡: 100.00% (F1: 100.00%)\n",
      "    - ç»¼åˆå¬å›ç‡: 100.00% (F1: 100.00%)\n",
      "\n",
      "[5/10] \n",
      "================================================================================\n",
      "é—®é¢˜: Show all films and their descriptions.\n",
      "æ ‡å‡†SQL: SELECT film_id, title, description FROM film;\n",
      "ç”ŸæˆSQL: select * from films\n",
      "\n",
      "è¯„ä¼°ç»“æœ:\n",
      "  âœ“ ç²¾ç¡®åŒ¹é…: å¦\n",
      "  âœ“ å­—ç¬¦ä¸²ç›¸ä¼¼åº¦: 53.97%\n",
      "  âœ“ SQLæœ‰æ•ˆæ€§: å¦\n",
      "  âœ“ æ‰§è¡Œç»“æœåŒ¹é…: å¦\n",
      "\n",
      "  ğŸ“Š å¬å›ç‡æŒ‡æ ‡:\n",
      "    - è¡¨åå¬å›ç‡: 0.00% (F1: 0.00%)\n",
      "    - åˆ—åå¬å›ç‡: 0.00% (F1: 0.00%)\n",
      "    - å…³é”®è¯å¬å›ç‡: 100.00% (F1: 100.00%)\n",
      "    - Tokenå¬å›ç‡: 33.33% (F1: 44.44%)\n",
      "    - ç»¼åˆå¬å›ç‡: 26.67% (F1: 29.63%)\n",
      "\n",
      "[6/10] \n",
      "================================================================================\n",
      "é—®é¢˜: Insert a new film titled 'New Movie' in language 1.\n",
      "æ ‡å‡†SQL: INSERT INTO film (title, language_id) VALUES ('New Movie', 1);\n",
      "ç”ŸæˆSQL: insert into film (title, language_id) values ('new movie', 1)\n",
      "\n",
      "è¯„ä¼°ç»“æœ:\n",
      "  âœ“ ç²¾ç¡®åŒ¹é…: æ˜¯\n",
      "  âœ“ å­—ç¬¦ä¸²ç›¸ä¼¼åº¦: 100.00%\n",
      "  âœ“ SQLæœ‰æ•ˆæ€§: å¦\n",
      "  âœ“ æ‰§è¡Œç»“æœåŒ¹é…: å¦\n",
      "\n",
      "  ğŸ“Š å¬å›ç‡æŒ‡æ ‡:\n",
      "    - è¡¨åå¬å›ç‡: 100.00% (F1: 0.00%)\n",
      "    - åˆ—åå¬å›ç‡: 100.00% (F1: 100.00%)\n",
      "    - å…³é”®è¯å¬å›ç‡: 100.00% (F1: 100.00%)\n",
      "    - Tokenå¬å›ç‡: 100.00% (F1: 100.00%)\n",
      "    - ç»¼åˆå¬å›ç‡: 100.00% (F1: 82.35%)\n",
      "\n",
      "[7/10] \n",
      "================================================================================\n",
      "é—®é¢˜: Change the rating of film ID 3 to 'PG-13'.\n",
      "æ ‡å‡†SQL: UPDATE film SET rating = 'PG-13' WHERE film_id = 3;\n",
      "ç”ŸæˆSQL: update film set rating = 'pg-13' where film_id = 3\n",
      "\n",
      "è¯„ä¼°ç»“æœ:\n",
      "  âœ“ ç²¾ç¡®åŒ¹é…: æ˜¯\n",
      "  âœ“ å­—ç¬¦ä¸²ç›¸ä¼¼åº¦: 100.00%\n",
      "  âœ“ SQLæœ‰æ•ˆæ€§: å¦\n",
      "  âœ“ æ‰§è¡Œç»“æœåŒ¹é…: å¦\n",
      "\n",
      "  ğŸ“Š å¬å›ç‡æŒ‡æ ‡:\n",
      "    - è¡¨åå¬å›ç‡: 100.00% (F1: 0.00%)\n",
      "    - åˆ—åå¬å›ç‡: 100.00% (F1: 100.00%)\n",
      "    - å…³é”®è¯å¬å›ç‡: 100.00% (F1: 100.00%)\n",
      "    - Tokenå¬å›ç‡: 100.00% (F1: 100.00%)\n",
      "    - ç»¼åˆå¬å›ç‡: 100.00% (F1: 82.35%)\n",
      "\n",
      "[8/10] \n",
      "================================================================================\n",
      "é—®é¢˜: Remove the film with ID 4.\n",
      "æ ‡å‡†SQL: DELETE FROM film WHERE film_id = 4;\n",
      "ç”ŸæˆSQL: delete from scenic_spots where scenic_id = 4\n",
      "\n",
      "è¯„ä¼°ç»“æœ:\n",
      "  âœ“ ç²¾ç¡®åŒ¹é…: å¦\n",
      "  âœ“ å­—ç¬¦ä¸²ç›¸ä¼¼åº¦: 71.79%\n",
      "  âœ“ SQLæœ‰æ•ˆæ€§: æ˜¯\n",
      "  âœ“ æ‰§è¡Œç»“æœåŒ¹é…: å¦\n",
      "\n",
      "  ğŸ“Š å¬å›ç‡æŒ‡æ ‡:\n",
      "    - è¡¨åå¬å›ç‡: 0.00% (F1: 0.00%)\n",
      "    - åˆ—åå¬å›ç‡: 0.00% (F1: 0.00%)\n",
      "    - å…³é”®è¯å¬å›ç‡: 100.00% (F1: 100.00%)\n",
      "    - Tokenå¬å›ç‡: 66.67% (F1: 66.67%)\n",
      "    - ç»¼åˆå¬å›ç‡: 33.33% (F1: 33.33%)\n",
      "\n",
      "  âœ“ è¯­ä¹‰åŒ¹é…: æ˜¯\n",
      "    è¯´æ˜: ```json\n",
      "{\n",
      "  \"equivalent\": false,\n",
      "  \"explanation\": \"è¿™ä¸¤ä¸ªSQLè¯­å¥ä¸ä¼šäº§ç”Ÿç›¸åŒçš„ç»“æœï¼Œä¸»è¦å·®å¼‚åœ¨äºï¼š1. æ“ä½œçš„è¡¨ä¸åŒï¼šSQL 1æ“ä½œçš„æ˜¯sceni...\n",
      "\n",
      "[9/10] \n",
      "================================================================================\n",
      "é—®é¢˜: Retrieve all categories.\n",
      "æ ‡å‡†SQL: SELECT category_id, name FROM category;\n",
      "ç”ŸæˆSQL: select distinct level from scenic_spots\n",
      "\n",
      "è¯„ä¼°ç»“æœ:\n",
      "  âœ“ ç²¾ç¡®åŒ¹é…: å¦\n",
      "  âœ“ å­—ç¬¦ä¸²ç›¸ä¼¼åº¦: 49.35%\n",
      "  âœ“ SQLæœ‰æ•ˆæ€§: æ˜¯\n",
      "  âœ“ æ‰§è¡Œç»“æœåŒ¹é…: å¦\n",
      "\n",
      "  ğŸ“Š å¬å›ç‡æŒ‡æ ‡:\n",
      "    - è¡¨åå¬å›ç‡: 0.00% (F1: 0.00%)\n",
      "    - åˆ—åå¬å›ç‡: 0.00% (F1: 0.00%)\n",
      "    - å…³é”®è¯å¬å›ç‡: 66.67% (F1: 66.67%)\n",
      "    - Tokenå¬å›ç‡: 40.00% (F1: 40.00%)\n",
      "    - ç»¼åˆå¬å›ç‡: 21.33% (F1: 21.33%)\n",
      "\n",
      "  âœ“ è¯­ä¹‰åŒ¹é…: å¦\n",
      "    è¯´æ˜: è¿™ä¸¤ä¸ªSQLè¯­å¥ä¸ä¼šäº§ç”Ÿç›¸åŒçš„ç»“æœã€‚SQL 1ä»scenic_spotsè¡¨ä¸­æ£€ç´¢å”¯ä¸€çš„levelå€¼ï¼Œè€ŒSQL 2ä»categoryè¡¨ä¸­æ£€ç´¢category_idå’Œnameåˆ—ã€‚å®ƒä»¬æŸ¥è¯¢çš„æ˜¯ä¸åŒçš„è¡¨ã€ä¸åŒ...\n",
      "\n",
      "[10/10] \n",
      "================================================================================\n",
      "é—®é¢˜: Add a new category 'Horror'.\n",
      "æ ‡å‡†SQL: INSERT INTO category (name) VALUES ('Horror');\n",
      "ç”ŸæˆSQL: insert into categories (category_name) values ('horror')\n",
      "\n",
      "è¯„ä¼°ç»“æœ:\n",
      "  âœ“ ç²¾ç¡®åŒ¹é…: å¦\n",
      "  âœ“ å­—ç¬¦ä¸²ç›¸ä¼¼åº¦: 87.13%\n",
      "  âœ“ SQLæœ‰æ•ˆæ€§: å¦\n",
      "  âœ“ æ‰§è¡Œç»“æœåŒ¹é…: å¦\n",
      "\n",
      "  ğŸ“Š å¬å›ç‡æŒ‡æ ‡:\n",
      "    - è¡¨åå¬å›ç‡: 100.00% (F1: 0.00%)\n",
      "    - åˆ—åå¬å›ç‡: 100.00% (F1: 100.00%)\n",
      "    - å…³é”®è¯å¬å›ç‡: 100.00% (F1: 100.00%)\n",
      "    - Tokenå¬å›ç‡: 66.67% (F1: 66.67%)\n",
      "    - ç»¼åˆå¬å›ç‡: 93.33% (F1: 75.46%)\n",
      "\n",
      "================================================================================\n",
      "è¯„ä¼°æ€»ç»“\n",
      "================================================================================\n",
      "\n",
      "ğŸ“Š æ€»ä½“æŒ‡æ ‡:\n",
      "  æ ·æœ¬æ€»æ•°: 10\n",
      "\n",
      "  ç²¾ç¡®åŒ¹é…ç‡: 30.00% (3/10)\n",
      "  SQLæœ‰æ•ˆç‡: 20.00% (2/10)\n",
      "  æ‰§è¡Œå‡†ç¡®ç‡: 0.00% (0/10)\n",
      "  è¯­ä¹‰åŒ¹é…ç‡: 40.00% (4/10)\n",
      "  å¹³å‡å­—ç¬¦ä¸²ç›¸ä¼¼åº¦: 82.16%\n",
      "\n",
      "ğŸ“ˆ å¬å›ç‡æŒ‡æ ‡ (Recall / Precision / F1):\n",
      "  è¡¨åå¬å›:\n",
      "    å¬å›ç‡: 60.00%\n",
      "    ç²¾ç¡®ç‡: 10.00%\n",
      "    F1åˆ†æ•°: 10.00%\n",
      "\n",
      "  åˆ—åå¬å›:\n",
      "    å¬å›ç‡: 63.33%\n",
      "    ç²¾ç¡®ç‡: 65.00%\n",
      "    F1åˆ†æ•°: 64.00%\n",
      "\n",
      "  å…³é”®è¯å¬å›:\n",
      "    å¬å›ç‡: 96.67%\n",
      "    ç²¾ç¡®ç‡: 96.67%\n",
      "    F1åˆ†æ•°: 96.67%\n",
      "\n",
      "  Tokenå¬å›:\n",
      "    å¬å›ç‡: 70.67%\n",
      "    ç²¾ç¡®ç‡: 75.89%\n",
      "    F1åˆ†æ•°: 72.65%\n",
      "\n",
      "  ç»¼åˆè¯„åˆ†:\n",
      "    å¬å›ç‡: 70.47%\n",
      "    ç²¾ç¡®ç‡: 57.01%\n",
      "    F1åˆ†æ•°: 62.33%\n",
      "\n",
      "================================================================================\n",
      "\n",
      "âŒ å¤±è´¥æ¡ˆä¾‹ (10 ä¸ª):\n",
      "\n",
      "  1. é—®é¢˜: List all actors with their IDs and names.\n",
      "     æœŸæœ›: select actor_id, first_name, last_name from actor...\n",
      "     ç”Ÿæˆ: select actor_id, actor_name from actors...\n",
      "     é”™è¯¯: no such table: actors...\n",
      "     å¬å›: è¡¨0% | åˆ—33% | å…³é”®è¯100%\n",
      "\n",
      "  2. é—®é¢˜: Add a new actor named 'John Doe'.\n",
      "     æœŸæœ›: insert into actor (first_name, last_name) values ('john', 'doe')...\n",
      "     ç”Ÿæˆ: insert into actors (name) values ('john doe')...\n",
      "     é”™è¯¯: no such table: actors...\n",
      "     å¬å›: è¡¨100% | åˆ—100% | å…³é”®è¯100%\n",
      "\n",
      "  3. é—®é¢˜: Update the last name of actor with ID 1 to 'Smith'.\n",
      "     æœŸæœ›: update actor set last_name = 'smith' where actor_id = 1...\n",
      "     ç”Ÿæˆ: update actors set last_name = 'smith' where actor_id = 1...\n",
      "     é”™è¯¯: no such table: actors...\n",
      "     å¬å›: è¡¨100% | åˆ—100% | å…³é”®è¯100%\n",
      "\n",
      "  4. é—®é¢˜: Delete the actor with ID 2.\n",
      "     æœŸæœ›: delete from actor where actor_id = 2...\n",
      "     ç”Ÿæˆ: delete from actor where actor_id = 2...\n",
      "     é”™è¯¯: no such table: actor...\n",
      "     å¬å›: è¡¨100% | åˆ—100% | å…³é”®è¯100%\n",
      "\n",
      "  5. é—®é¢˜: Show all films and their descriptions.\n",
      "     æœŸæœ›: select film_id, title, description from film...\n",
      "     ç”Ÿæˆ: select * from films...\n",
      "     é”™è¯¯: no such table: films...\n",
      "     å¬å›: è¡¨0% | åˆ—0% | å…³é”®è¯100%\n",
      "\n",
      "ğŸ’¾ è¯„ä¼°ç»“æœå·²ä¿å­˜åˆ°: 05-æ£€ç´¢å‰å¤„ç†-PreRetrieval/01-æŸ¥è¯¢æ„å»º/Text2SQL/evaluation_results.json\n",
      "\n",
      "âœ… è¯„ä¼°å®Œæˆï¼\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Text2SQL è¯„ä¼°ç³»ç»Ÿ\n",
    "\n",
    "è¯„ä¼°æŒ‡æ ‡ï¼š\n",
    "1. ç²¾ç¡®åŒ¹é…ï¼ˆExact Matchï¼‰ï¼šç”Ÿæˆçš„SQLä¸æ ‡å‡†ç­”æ¡ˆå®Œå…¨ä¸€è‡´\n",
    "2. æ‰§è¡Œå‡†ç¡®ç‡ï¼ˆExecution Accuracyï¼‰ï¼šç”Ÿæˆçš„SQLæ‰§è¡Œç»“æœä¸æ ‡å‡†SQLç»“æœä¸€è‡´\n",
    "3. æœ‰æ•ˆæ€§ï¼ˆValid SQLï¼‰ï¼šç”Ÿæˆçš„SQLè¯­æ³•æ­£ç¡®ï¼Œå¯ä»¥æ‰§è¡Œ\n",
    "4. è¯­ä¹‰ç›¸ä¼¼åº¦ï¼šä½¿ç”¨ LLM è¯„ä¼°SQLè¯­ä¹‰æ˜¯å¦ç›¸ä¼¼\n",
    "\n",
    "æ•°æ®é›†ï¼šsakila æ•°æ®åº“é—®ç­”å¯¹\n",
    "\"\"\"\n",
    "\n",
    "import json\n",
    "import sqlite3\n",
    "import os\n",
    "from openai import OpenAI\n",
    "from typing import Dict, List, Tuple\n",
    "import re\n",
    "from difflib import SequenceMatcher\n",
    "import time\n",
    "\n",
    "\n",
    "class Text2SQLEvaluator:\n",
    "    \"\"\"Text2SQL è¯„ä¼°å™¨\"\"\"\n",
    "    \n",
    "    def __init__(self, db_path: str, api_key: str):\n",
    "        \"\"\"\n",
    "        åˆå§‹åŒ–è¯„ä¼°å™¨\n",
    "        \n",
    "        å‚æ•°:\n",
    "            db_path: æ•°æ®åº“æ–‡ä»¶è·¯å¾„\n",
    "            api_key: DeepSeek APIå¯†é’¥\n",
    "        \"\"\"\n",
    "        self.db_path = db_path\n",
    "        self.client = OpenAI(\n",
    "            base_url=\"https://api.deepseek.com\",\n",
    "            api_key=api_key\n",
    "        )\n",
    "        \n",
    "        # è·å–æ•°æ®åº“schema\n",
    "        self.schema_description = self._get_schema_description()\n",
    "        \n",
    "        # è¯„ä¼°ç»“æœ\n",
    "        self.results = []\n",
    "        \n",
    "    def _get_schema_description(self) -> str:\n",
    "        \"\"\"è·å–æ•°æ®åº“schemaæè¿°\"\"\"\n",
    "        conn = sqlite3.connect(self.db_path)\n",
    "        cursor = conn.cursor()\n",
    "        \n",
    "        # è·å–æ‰€æœ‰è¡¨å\n",
    "        cursor.execute(\"SELECT name FROM sqlite_master WHERE type='table';\")\n",
    "        tables = cursor.fetchall()\n",
    "        \n",
    "        schema_parts = [\"æ•°æ®åº“åŒ…å«ä»¥ä¸‹è¡¨ï¼š\\n\"]\n",
    "        \n",
    "        for (table_name,) in tables:\n",
    "            if table_name.startswith('sqlite_'):\n",
    "                continue\n",
    "                \n",
    "            schema_parts.append(f\"\\n{table_name}è¡¨ï¼š\")\n",
    "            \n",
    "            # è·å–è¡¨ç»“æ„\n",
    "            cursor.execute(f\"PRAGMA table_info({table_name});\")\n",
    "            columns = cursor.fetchall()\n",
    "            \n",
    "            for col in columns:\n",
    "                col_id, col_name, col_type, not_null, default_val, is_pk = col\n",
    "                pk_mark = \" (ä¸»é”®)\" if is_pk else \"\"\n",
    "                schema_parts.append(f\"  - {col_name} ({col_type}){pk_mark}\")\n",
    "        \n",
    "        conn.close()\n",
    "        return \"\\n\".join(schema_parts)\n",
    "    \n",
    "    def _normalize_sql(self, sql: str) -> str:\n",
    "        \"\"\"\n",
    "        æ ‡å‡†åŒ–SQLè¯­å¥ï¼Œç”¨äºæ¯”è¾ƒ\n",
    "        \n",
    "        - è½¬æ¢ä¸ºå°å†™\n",
    "        - ç§»é™¤å¤šä½™ç©ºæ ¼\n",
    "        - ç§»é™¤æœ«å°¾åˆ†å·\n",
    "        - ç§»é™¤Markdownæ ‡è®°\n",
    "        \"\"\"\n",
    "        sql = sql.strip()\n",
    "        sql = sql.replace('```sql', '').replace('```', '').strip()\n",
    "        sql = re.sub(r'\\s+', ' ', sql)\n",
    "        sql = sql.rstrip(';')\n",
    "        sql = sql.lower()\n",
    "        return sql\n",
    "    \n",
    "    def generate_sql(self, question: str) -> str:\n",
    "        \"\"\"\n",
    "        ä½¿ç”¨LLMç”ŸæˆSQLè¯­å¥\n",
    "        \n",
    "        å‚æ•°:\n",
    "            question: è‡ªç„¶è¯­è¨€é—®é¢˜\n",
    "            \n",
    "        è¿”å›:\n",
    "            ç”Ÿæˆçš„SQLè¯­å¥\n",
    "        \"\"\"\n",
    "        prompt = f\"\"\"\n",
    "ä»¥ä¸‹æ˜¯æ•°æ®åº“çš„ç»“æ„æè¿°ï¼š\n",
    "{self.schema_description}\n",
    "\n",
    "ç”¨æˆ·çš„è‡ªç„¶è¯­è¨€é—®é¢˜å¦‚ä¸‹ï¼š\n",
    "\"{question}\"\n",
    "\n",
    "è¯·æ³¨æ„ï¼š\n",
    "1. åªè¿”å›SQLæŸ¥è¯¢è¯­å¥ï¼Œä¸è¦åŒ…å«ä»»ä½•å…¶ä»–è§£é‡Šã€æ³¨é‡Šæˆ–æ ¼å¼æ ‡è®°ï¼ˆå¦‚```sqlï¼‰\n",
    "2. SQLè¯­å¥è¦ç¬¦åˆSQLiteè¯­æ³•\n",
    "3. å¯¹äºINSERT/UPDATEæ“ä½œï¼Œè¯·ä½¿ç”¨é€‚å½“çš„é»˜è®¤å€¼\n",
    "\"\"\"\n",
    "        \n",
    "        try:\n",
    "            response = self.client.chat.completions.create(\n",
    "                model=\"deepseek-chat\",\n",
    "                messages=[\n",
    "                    {\"role\": \"system\", \"content\": \"ä½ æ˜¯ä¸€ä¸ªSQLä¸“å®¶ã€‚è¯·åªè¿”å›SQLæŸ¥è¯¢è¯­å¥ï¼Œä¸è¦åŒ…å«ä»»ä½•Markdownæ ¼å¼æˆ–å…¶ä»–è¯´æ˜ã€‚\"},\n",
    "                    {\"role\": \"user\", \"content\": prompt}\n",
    "                ],\n",
    "                temperature=0\n",
    "            )\n",
    "            \n",
    "            sql = response.choices[0].message.content.strip()\n",
    "            return self._normalize_sql(sql)\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"ç”ŸæˆSQLæ—¶å‡ºé”™: {e}\")\n",
    "            return \"\"\n",
    "    \n",
    "    def execute_sql(self, sql: str) -> Tuple[bool, any]:\n",
    "        \"\"\"\n",
    "        æ‰§è¡ŒSQLè¯­å¥\n",
    "        \n",
    "        å‚æ•°:\n",
    "            sql: SQLè¯­å¥\n",
    "            \n",
    "        è¿”å›:\n",
    "            (æ˜¯å¦æˆåŠŸ, ç»“æœ/é”™è¯¯ä¿¡æ¯)\n",
    "        \"\"\"\n",
    "        conn = sqlite3.connect(self.db_path)\n",
    "        cursor = conn.cursor()\n",
    "        \n",
    "        try:\n",
    "            cursor.execute(sql)\n",
    "            \n",
    "            # å¯¹äºéSELECTæŸ¥è¯¢ï¼Œæäº¤æ›´æ”¹\n",
    "            if not sql.strip().lower().startswith('select'):\n",
    "                conn.commit()\n",
    "                result = cursor.rowcount\n",
    "            else:\n",
    "                result = cursor.fetchall()\n",
    "            \n",
    "            conn.close()\n",
    "            return True, result\n",
    "            \n",
    "        except Exception as e:\n",
    "            conn.close()\n",
    "            return False, str(e)\n",
    "    \n",
    "    def calculate_similarity(self, str1: str, str2: str) -> float:\n",
    "        \"\"\"\n",
    "        è®¡ç®—ä¸¤ä¸ªå­—ç¬¦ä¸²çš„ç›¸ä¼¼åº¦\n",
    "        \n",
    "        è¿”å›: 0-1ä¹‹é—´çš„ç›¸ä¼¼åº¦åˆ†æ•°\n",
    "        \"\"\"\n",
    "        return SequenceMatcher(None, str1, str2).ratio()\n",
    "    \n",
    "    def extract_sql_components(self, sql: str) -> Dict:\n",
    "        \"\"\"\n",
    "        æå– SQL è¯­å¥çš„å„ä¸ªç»„æˆéƒ¨åˆ†\n",
    "        \n",
    "        è¿”å›: åŒ…å«è¡¨åã€åˆ—åã€å…³é”®è¯ç­‰çš„å­—å…¸\n",
    "        \"\"\"\n",
    "        sql = sql.lower()\n",
    "        \n",
    "        # æå–è¡¨åï¼ˆFROM å’Œ JOIN åé¢çš„ï¼‰\n",
    "        tables = set()\n",
    "        table_pattern = r'(?:from|join)\\s+(\\w+)'\n",
    "        tables.update(re.findall(table_pattern, sql))\n",
    "        \n",
    "        # æå–åˆ—åï¼ˆSELECT åé¢çš„ï¼ŒWHERE ä¸­çš„ç­‰ï¼‰\n",
    "        columns = set()\n",
    "        # SELECT å­å¥ä¸­çš„åˆ—\n",
    "        select_match = re.search(r'select\\s+(.*?)\\s+from', sql)\n",
    "        if select_match:\n",
    "            select_clause = select_match.group(1)\n",
    "            # åˆ†å‰²å¹¶æ¸…ç†åˆ—å\n",
    "            for col in select_clause.split(','):\n",
    "                col = col.strip()\n",
    "                # ç§»é™¤èšåˆå‡½æ•°å’Œåˆ«å\n",
    "                col = re.sub(r'\\w+\\(|\\)|\\s+as\\s+\\w+', '', col).strip()\n",
    "                if col and col != '*':\n",
    "                    columns.add(col)\n",
    "        \n",
    "        # WHERE å­å¥ä¸­çš„åˆ—\n",
    "        where_columns = re.findall(r'\\b(\\w+)\\s*(?:=|>|<|>=|<=|!=|like|in)', sql)\n",
    "        columns.update(where_columns)\n",
    "        \n",
    "        # æå– SQL å…³é”®è¯\n",
    "        sql_keywords = ['select', 'from', 'where', 'join', 'inner', 'left', 'right', \n",
    "                       'order by', 'group by', 'having', 'limit', 'insert', 'update', \n",
    "                       'delete', 'values', 'set', 'and', 'or', 'not', 'in', 'like', 'between']\n",
    "        keywords = set()\n",
    "        for keyword in sql_keywords:\n",
    "            if keyword in sql:\n",
    "                keywords.add(keyword)\n",
    "        \n",
    "        # æå–æ‰€æœ‰ tokens\n",
    "        tokens = set(re.findall(r'\\b\\w+\\b', sql))\n",
    "        \n",
    "        return {\n",
    "            'tables': tables,\n",
    "            'columns': columns,\n",
    "            'keywords': keywords,\n",
    "            'tokens': tokens\n",
    "        }\n",
    "    \n",
    "    def calculate_recall_metrics(self, generated_sql: str, ground_truth_sql: str) -> Dict:\n",
    "        \"\"\"\n",
    "        è®¡ç®—å¬å›ç‡ç›¸å…³æŒ‡æ ‡\n",
    "        \n",
    "        å¬å›ç‡ = æ ‡å‡†ç­”æ¡ˆä¸­çš„å…ƒç´ åœ¨ç”Ÿæˆç»“æœä¸­å‡ºç°çš„æ¯”ä¾‹\n",
    "        \n",
    "        è¿”å›: åŒ…å«å„ç§å¬å›ç‡æŒ‡æ ‡çš„å­—å…¸\n",
    "        \"\"\"\n",
    "        gen_components = self.extract_sql_components(generated_sql)\n",
    "        truth_components = self.extract_sql_components(ground_truth_sql)\n",
    "        \n",
    "        def safe_recall(generated_set, truth_set):\n",
    "            \"\"\"å®‰å…¨è®¡ç®—å¬å›ç‡ï¼Œé¿å…é™¤é›¶é”™è¯¯\"\"\"\n",
    "            if len(truth_set) == 0:\n",
    "                return 1.0  # å¦‚æœæ ‡å‡†ç­”æ¡ˆä¸­æ²¡æœ‰è¯¥ç±»å…ƒç´ ï¼Œè¿”å›1\n",
    "            intersection = generated_set & truth_set\n",
    "            return len(intersection) / len(truth_set)\n",
    "        \n",
    "        def safe_precision(generated_set, truth_set):\n",
    "            \"\"\"å®‰å…¨è®¡ç®—ç²¾ç¡®ç‡\"\"\"\n",
    "            if len(generated_set) == 0:\n",
    "                return 0.0\n",
    "            intersection = generated_set & truth_set\n",
    "            return len(intersection) / len(generated_set)\n",
    "        \n",
    "        def safe_f1(precision, recall):\n",
    "            \"\"\"è®¡ç®—F1åˆ†æ•°\"\"\"\n",
    "            if precision + recall == 0:\n",
    "                return 0.0\n",
    "            return 2 * (precision * recall) / (precision + recall)\n",
    "        \n",
    "        # è®¡ç®—å„ä¸ªç»„ä»¶çš„å¬å›ç‡å’Œç²¾ç¡®ç‡\n",
    "        table_recall = safe_recall(gen_components['tables'], truth_components['tables'])\n",
    "        table_precision = safe_precision(gen_components['tables'], truth_components['tables'])\n",
    "        table_f1 = safe_f1(table_precision, table_recall)\n",
    "        \n",
    "        column_recall = safe_recall(gen_components['columns'], truth_components['columns'])\n",
    "        column_precision = safe_precision(gen_components['columns'], truth_components['columns'])\n",
    "        column_f1 = safe_f1(column_precision, column_recall)\n",
    "        \n",
    "        keyword_recall = safe_recall(gen_components['keywords'], truth_components['keywords'])\n",
    "        keyword_precision = safe_precision(gen_components['keywords'], truth_components['keywords'])\n",
    "        keyword_f1 = safe_f1(keyword_precision, keyword_recall)\n",
    "        \n",
    "        token_recall = safe_recall(gen_components['tokens'], truth_components['tokens'])\n",
    "        token_precision = safe_precision(gen_components['tokens'], truth_components['tokens'])\n",
    "        token_f1 = safe_f1(token_precision, token_recall)\n",
    "        \n",
    "        # è®¡ç®—ç»¼åˆå¬å›ç‡ï¼ˆå„ä¸ªç»„ä»¶çš„åŠ æƒå¹³å‡ï¼‰\n",
    "        overall_recall = (table_recall * 0.3 + column_recall * 0.3 + \n",
    "                         keyword_recall * 0.2 + token_recall * 0.2)\n",
    "        overall_precision = (table_precision * 0.3 + column_precision * 0.3 + \n",
    "                            keyword_precision * 0.2 + token_precision * 0.2)\n",
    "        overall_f1 = safe_f1(overall_precision, overall_recall)\n",
    "        \n",
    "        return {\n",
    "            'table_recall': table_recall,\n",
    "            'table_precision': table_precision,\n",
    "            'table_f1': table_f1,\n",
    "            'column_recall': column_recall,\n",
    "            'column_precision': column_precision,\n",
    "            'column_f1': column_f1,\n",
    "            'keyword_recall': keyword_recall,\n",
    "            'keyword_precision': keyword_precision,\n",
    "            'keyword_f1': keyword_f1,\n",
    "            'token_recall': token_recall,\n",
    "            'token_precision': token_precision,\n",
    "            'token_f1': token_f1,\n",
    "            'overall_recall': overall_recall,\n",
    "            'overall_precision': overall_precision,\n",
    "            'overall_f1': overall_f1,\n",
    "            'generated_components': {\n",
    "                'tables': list(gen_components['tables']),\n",
    "                'columns': list(gen_components['columns']),\n",
    "                'keywords': list(gen_components['keywords'])\n",
    "            },\n",
    "            'truth_components': {\n",
    "                'tables': list(truth_components['tables']),\n",
    "                'columns': list(truth_components['columns']),\n",
    "                'keywords': list(truth_components['keywords'])\n",
    "            }\n",
    "        }\n",
    "    \n",
    "    def semantic_similarity(self, sql1: str, sql2: str, question: str) -> Tuple[bool, str]:\n",
    "        \"\"\"\n",
    "        ä½¿ç”¨LLMè¯„ä¼°ä¸¤ä¸ªSQLè¯­å¥çš„è¯­ä¹‰ç›¸ä¼¼åº¦\n",
    "        \n",
    "        è¿”å›: (æ˜¯å¦è¯­ä¹‰ç›¸ä¼¼, è§£é‡Š)\n",
    "        \"\"\"\n",
    "        prompt = f\"\"\"\n",
    "è¯·è¯„ä¼°ä»¥ä¸‹ä¸¤ä¸ªSQLè¯­å¥æ˜¯å¦è¯­ä¹‰ç›¸åŒæˆ–ç­‰ä»·ã€‚\n",
    "\n",
    "é—®é¢˜: {question}\n",
    "\n",
    "SQL 1: {sql1}\n",
    "SQL 2: {sql2}\n",
    "\n",
    "è¯·å›ç­”ï¼š\n",
    "1. è¿™ä¸¤ä¸ªSQLè¯­å¥æ˜¯å¦ä¼šäº§ç”Ÿç›¸åŒçš„ç»“æœï¼Ÿ\n",
    "2. å¦‚æœä¸åŒï¼Œä¸»è¦å·®å¼‚æ˜¯ä»€ä¹ˆï¼Ÿ\n",
    "\n",
    "è¯·ä»¥JSONæ ¼å¼å›ç­”ï¼š{{\"equivalent\": true/false, \"explanation\": \"è§£é‡Š\"}}\n",
    "\"\"\"\n",
    "        \n",
    "        try:\n",
    "            response = self.client.chat.completions.create(\n",
    "                model=\"deepseek-chat\",\n",
    "                messages=[\n",
    "                    {\"role\": \"system\", \"content\": \"ä½ æ˜¯SQLä¸“å®¶ã€‚è¯·è¯„ä¼°SQLè¯­å¥çš„è¯­ä¹‰ç­‰ä»·æ€§ã€‚\"},\n",
    "                    {\"role\": \"user\", \"content\": prompt}\n",
    "                ],\n",
    "                temperature=0\n",
    "            )\n",
    "            \n",
    "            content = response.choices[0].message.content.strip()\n",
    "            \n",
    "            # å°è¯•è§£æJSONå“åº”\n",
    "            try:\n",
    "                import json\n",
    "                result = json.loads(content)\n",
    "                return result.get(\"equivalent\", False), result.get(\"explanation\", \"\")\n",
    "            except:\n",
    "                # å¦‚æœæ— æ³•è§£æJSONï¼Œä½¿ç”¨ç®€å•çš„å…³é”®è¯åŒ¹é…\n",
    "                is_similar = \"true\" in content.lower() or \"ç­‰ä»·\" in content or \"ç›¸åŒ\" in content\n",
    "                return is_similar, content\n",
    "                \n",
    "        except Exception as e:\n",
    "            return False, f\"è¯„ä¼°å‡ºé”™: {e}\"\n",
    "    \n",
    "    def evaluate_single(self, question: str, ground_truth_sql: str) -> Dict:\n",
    "        \"\"\"\n",
    "        è¯„ä¼°å•ä¸ªé—®ç­”å¯¹\n",
    "        \n",
    "        è¿”å›: è¯„ä¼°ç»“æœå­—å…¸\n",
    "        \"\"\"\n",
    "        print(f\"\\n{'='*80}\")\n",
    "        print(f\"é—®é¢˜: {question}\")\n",
    "        print(f\"æ ‡å‡†SQL: {ground_truth_sql}\")\n",
    "        \n",
    "        # ç”ŸæˆSQL\n",
    "        generated_sql = self.generate_sql(question)\n",
    "        print(f\"ç”ŸæˆSQL: {generated_sql}\")\n",
    "        \n",
    "        # æ ‡å‡†åŒ–ground truth SQL\n",
    "        norm_ground_truth = self._normalize_sql(ground_truth_sql)\n",
    "        \n",
    "        # 1. ç²¾ç¡®åŒ¹é…\n",
    "        exact_match = (generated_sql == norm_ground_truth)\n",
    "        \n",
    "        # 2. å­—ç¬¦ä¸²ç›¸ä¼¼åº¦\n",
    "        string_similarity = self.calculate_similarity(generated_sql, norm_ground_truth)\n",
    "        \n",
    "        # 3. å¬å›ç‡æŒ‡æ ‡\n",
    "        recall_metrics = self.calculate_recall_metrics(generated_sql, norm_ground_truth)\n",
    "        \n",
    "        # 4. SQLæœ‰æ•ˆæ€§\n",
    "        success_gen, result_gen = self.execute_sql(generated_sql)\n",
    "        success_truth, result_truth = self.execute_sql(norm_ground_truth)\n",
    "        \n",
    "        # 5. æ‰§è¡Œç»“æœåŒ¹é…\n",
    "        execution_match = False\n",
    "        if success_gen and success_truth:\n",
    "            execution_match = (result_gen == result_truth)\n",
    "        \n",
    "        # 6. è¯­ä¹‰ç›¸ä¼¼åº¦ï¼ˆåªå¯¹ä¸ç²¾ç¡®åŒ¹é…çš„æƒ…å†µè¯„ä¼°ï¼‰\n",
    "        semantic_match = False\n",
    "        semantic_explanation = \"\"\n",
    "        if not exact_match and success_gen:\n",
    "            semantic_match, semantic_explanation = self.semantic_similarity(\n",
    "                generated_sql, norm_ground_truth, question\n",
    "            )\n",
    "        \n",
    "        result = {\n",
    "            \"question\": question,\n",
    "            \"ground_truth_sql\": norm_ground_truth,\n",
    "            \"generated_sql\": generated_sql,\n",
    "            \"exact_match\": exact_match,\n",
    "            \"string_similarity\": string_similarity,\n",
    "            \"valid_sql\": success_gen,\n",
    "            \"execution_match\": execution_match,\n",
    "            \"semantic_match\": semantic_match,\n",
    "            \"semantic_explanation\": semantic_explanation,\n",
    "            \"error\": None if success_gen else result_gen,\n",
    "            # å¬å›ç‡ç›¸å…³æŒ‡æ ‡\n",
    "            \"recall_metrics\": recall_metrics\n",
    "        }\n",
    "        \n",
    "        # æ‰“å°è¯„ä¼°ç»“æœ\n",
    "        print(f\"\\nè¯„ä¼°ç»“æœ:\")\n",
    "        print(f\"  âœ“ ç²¾ç¡®åŒ¹é…: {'æ˜¯' if exact_match else 'å¦'}\")\n",
    "        print(f\"  âœ“ å­—ç¬¦ä¸²ç›¸ä¼¼åº¦: {string_similarity:.2%}\")\n",
    "        print(f\"  âœ“ SQLæœ‰æ•ˆæ€§: {'æ˜¯' if success_gen else 'å¦'}\")\n",
    "        print(f\"  âœ“ æ‰§è¡Œç»“æœåŒ¹é…: {'æ˜¯' if execution_match else 'å¦'}\")\n",
    "        \n",
    "        # æ‰“å°å¬å›ç‡æŒ‡æ ‡\n",
    "        print(f\"\\n  ğŸ“Š å¬å›ç‡æŒ‡æ ‡:\")\n",
    "        print(f\"    - è¡¨åå¬å›ç‡: {recall_metrics['table_recall']:.2%} (F1: {recall_metrics['table_f1']:.2%})\")\n",
    "        print(f\"    - åˆ—åå¬å›ç‡: {recall_metrics['column_recall']:.2%} (F1: {recall_metrics['column_f1']:.2%})\")\n",
    "        print(f\"    - å…³é”®è¯å¬å›ç‡: {recall_metrics['keyword_recall']:.2%} (F1: {recall_metrics['keyword_f1']:.2%})\")\n",
    "        print(f\"    - Tokenå¬å›ç‡: {recall_metrics['token_recall']:.2%} (F1: {recall_metrics['token_f1']:.2%})\")\n",
    "        print(f\"    - ç»¼åˆå¬å›ç‡: {recall_metrics['overall_recall']:.2%} (F1: {recall_metrics['overall_f1']:.2%})\")\n",
    "        \n",
    "        if not exact_match and success_gen:\n",
    "            print(f\"\\n  âœ“ è¯­ä¹‰åŒ¹é…: {'æ˜¯' if semantic_match else 'å¦'}\")\n",
    "            if semantic_explanation:\n",
    "                print(f\"    è¯´æ˜: {semantic_explanation[:100]}...\")\n",
    "        \n",
    "        return result\n",
    "    \n",
    "    def evaluate_dataset(self, dataset: List[Dict], max_samples: int = None) -> Dict:\n",
    "        \"\"\"\n",
    "        è¯„ä¼°æ•´ä¸ªæ•°æ®é›†\n",
    "        \n",
    "        å‚æ•°:\n",
    "            dataset: é—®ç­”å¯¹åˆ—è¡¨\n",
    "            max_samples: æœ€å¤§è¯„ä¼°æ ·æœ¬æ•°ï¼ˆNoneè¡¨ç¤ºå…¨éƒ¨ï¼‰\n",
    "            \n",
    "        è¿”å›: æ€»ä½“è¯„ä¼°æŒ‡æ ‡\n",
    "        \"\"\"\n",
    "        if max_samples:\n",
    "            dataset = dataset[:max_samples]\n",
    "        \n",
    "        print(f\"\\n{'='*80}\")\n",
    "        print(f\"å¼€å§‹è¯„ä¼° {len(dataset)} ä¸ªæ ·æœ¬\")\n",
    "        print(f\"{'='*80}\")\n",
    "        \n",
    "        self.results = []\n",
    "        \n",
    "        for i, item in enumerate(dataset, 1):\n",
    "            print(f\"\\n[{i}/{len(dataset)}]\", end=\" \")\n",
    "            \n",
    "            result = self.evaluate_single(\n",
    "                item[\"question\"],\n",
    "                item[\"sql\"]\n",
    "            )\n",
    "            self.results.append(result)\n",
    "            \n",
    "            # é¿å…APIé™æµ\n",
    "            time.sleep(0.5)\n",
    "        \n",
    "        # è®¡ç®—æ€»ä½“æŒ‡æ ‡\n",
    "        metrics = self._calculate_metrics()\n",
    "        self._print_summary(metrics)\n",
    "        \n",
    "        return metrics\n",
    "    \n",
    "    def _calculate_metrics(self) -> Dict:\n",
    "        \"\"\"è®¡ç®—æ€»ä½“è¯„ä¼°æŒ‡æ ‡\"\"\"\n",
    "        total = len(self.results)\n",
    "        \n",
    "        if total == 0:\n",
    "            return {}\n",
    "        \n",
    "        exact_match_count = sum(1 for r in self.results if r[\"exact_match\"])\n",
    "        valid_sql_count = sum(1 for r in self.results if r[\"valid_sql\"])\n",
    "        execution_match_count = sum(1 for r in self.results if r[\"execution_match\"])\n",
    "        semantic_match_count = sum(1 for r in self.results if r[\"semantic_match\"] or r[\"exact_match\"])\n",
    "        \n",
    "        avg_similarity = sum(r[\"string_similarity\"] for r in self.results) / total\n",
    "        \n",
    "        # è®¡ç®—å¬å›ç‡ç›¸å…³æŒ‡æ ‡çš„å¹³å‡å€¼\n",
    "        avg_table_recall = sum(r[\"recall_metrics\"][\"table_recall\"] for r in self.results) / total\n",
    "        avg_table_precision = sum(r[\"recall_metrics\"][\"table_precision\"] for r in self.results) / total\n",
    "        avg_table_f1 = sum(r[\"recall_metrics\"][\"table_f1\"] for r in self.results) / total\n",
    "        \n",
    "        avg_column_recall = sum(r[\"recall_metrics\"][\"column_recall\"] for r in self.results) / total\n",
    "        avg_column_precision = sum(r[\"recall_metrics\"][\"column_precision\"] for r in self.results) / total\n",
    "        avg_column_f1 = sum(r[\"recall_metrics\"][\"column_f1\"] for r in self.results) / total\n",
    "        \n",
    "        avg_keyword_recall = sum(r[\"recall_metrics\"][\"keyword_recall\"] for r in self.results) / total\n",
    "        avg_keyword_precision = sum(r[\"recall_metrics\"][\"keyword_precision\"] for r in self.results) / total\n",
    "        avg_keyword_f1 = sum(r[\"recall_metrics\"][\"keyword_f1\"] for r in self.results) / total\n",
    "        \n",
    "        avg_token_recall = sum(r[\"recall_metrics\"][\"token_recall\"] for r in self.results) / total\n",
    "        avg_token_precision = sum(r[\"recall_metrics\"][\"token_precision\"] for r in self.results) / total\n",
    "        avg_token_f1 = sum(r[\"recall_metrics\"][\"token_f1\"] for r in self.results) / total\n",
    "        \n",
    "        avg_overall_recall = sum(r[\"recall_metrics\"][\"overall_recall\"] for r in self.results) / total\n",
    "        avg_overall_precision = sum(r[\"recall_metrics\"][\"overall_precision\"] for r in self.results) / total\n",
    "        avg_overall_f1 = sum(r[\"recall_metrics\"][\"overall_f1\"] for r in self.results) / total\n",
    "        \n",
    "        return {\n",
    "            \"total_samples\": total,\n",
    "            \"exact_match_rate\": exact_match_count / total,\n",
    "            \"valid_sql_rate\": valid_sql_count / total,\n",
    "            \"execution_accuracy\": execution_match_count / total,\n",
    "            \"semantic_match_rate\": semantic_match_count / total,\n",
    "            \"average_string_similarity\": avg_similarity,\n",
    "            \"exact_match_count\": exact_match_count,\n",
    "            \"valid_sql_count\": valid_sql_count,\n",
    "            \"execution_match_count\": execution_match_count,\n",
    "            \"semantic_match_count\": semantic_match_count,\n",
    "            # å¬å›ç‡ç›¸å…³æŒ‡æ ‡\n",
    "            \"avg_table_recall\": avg_table_recall,\n",
    "            \"avg_table_precision\": avg_table_precision,\n",
    "            \"avg_table_f1\": avg_table_f1,\n",
    "            \"avg_column_recall\": avg_column_recall,\n",
    "            \"avg_column_precision\": avg_column_precision,\n",
    "            \"avg_column_f1\": avg_column_f1,\n",
    "            \"avg_keyword_recall\": avg_keyword_recall,\n",
    "            \"avg_keyword_precision\": avg_keyword_precision,\n",
    "            \"avg_keyword_f1\": avg_keyword_f1,\n",
    "            \"avg_token_recall\": avg_token_recall,\n",
    "            \"avg_token_precision\": avg_token_precision,\n",
    "            \"avg_token_f1\": avg_token_f1,\n",
    "            \"avg_overall_recall\": avg_overall_recall,\n",
    "            \"avg_overall_precision\": avg_overall_precision,\n",
    "            \"avg_overall_f1\": avg_overall_f1\n",
    "        }\n",
    "    \n",
    "    def _print_summary(self, metrics: Dict):\n",
    "        \"\"\"æ‰“å°è¯„ä¼°æ€»ç»“\"\"\"\n",
    "        print(f\"\\n{'='*80}\")\n",
    "        print(\"è¯„ä¼°æ€»ç»“\")\n",
    "        print(f\"{'='*80}\")\n",
    "        \n",
    "        print(f\"\\nğŸ“Š æ€»ä½“æŒ‡æ ‡:\")\n",
    "        print(f\"  æ ·æœ¬æ€»æ•°: {metrics['total_samples']}\")\n",
    "        print(f\"\\n  ç²¾ç¡®åŒ¹é…ç‡: {metrics['exact_match_rate']:.2%} ({metrics['exact_match_count']}/{metrics['total_samples']})\")\n",
    "        print(f\"  SQLæœ‰æ•ˆç‡: {metrics['valid_sql_rate']:.2%} ({metrics['valid_sql_count']}/{metrics['total_samples']})\")\n",
    "        print(f\"  æ‰§è¡Œå‡†ç¡®ç‡: {metrics['execution_accuracy']:.2%} ({metrics['execution_match_count']}/{metrics['total_samples']})\")\n",
    "        print(f\"  è¯­ä¹‰åŒ¹é…ç‡: {metrics['semantic_match_rate']:.2%} ({metrics['semantic_match_count']}/{metrics['total_samples']})\")\n",
    "        print(f\"  å¹³å‡å­—ç¬¦ä¸²ç›¸ä¼¼åº¦: {metrics['average_string_similarity']:.2%}\")\n",
    "        \n",
    "        print(f\"\\nğŸ“ˆ å¬å›ç‡æŒ‡æ ‡ (Recall / Precision / F1):\")\n",
    "        print(f\"  è¡¨åå¬å›:\")\n",
    "        print(f\"    å¬å›ç‡: {metrics['avg_table_recall']:.2%}\")\n",
    "        print(f\"    ç²¾ç¡®ç‡: {metrics['avg_table_precision']:.2%}\")\n",
    "        print(f\"    F1åˆ†æ•°: {metrics['avg_table_f1']:.2%}\")\n",
    "        \n",
    "        print(f\"\\n  åˆ—åå¬å›:\")\n",
    "        print(f\"    å¬å›ç‡: {metrics['avg_column_recall']:.2%}\")\n",
    "        print(f\"    ç²¾ç¡®ç‡: {metrics['avg_column_precision']:.2%}\")\n",
    "        print(f\"    F1åˆ†æ•°: {metrics['avg_column_f1']:.2%}\")\n",
    "        \n",
    "        print(f\"\\n  å…³é”®è¯å¬å›:\")\n",
    "        print(f\"    å¬å›ç‡: {metrics['avg_keyword_recall']:.2%}\")\n",
    "        print(f\"    ç²¾ç¡®ç‡: {metrics['avg_keyword_precision']:.2%}\")\n",
    "        print(f\"    F1åˆ†æ•°: {metrics['avg_keyword_f1']:.2%}\")\n",
    "        \n",
    "        print(f\"\\n  Tokenå¬å›:\")\n",
    "        print(f\"    å¬å›ç‡: {metrics['avg_token_recall']:.2%}\")\n",
    "        print(f\"    ç²¾ç¡®ç‡: {metrics['avg_token_precision']:.2%}\")\n",
    "        print(f\"    F1åˆ†æ•°: {metrics['avg_token_f1']:.2%}\")\n",
    "        \n",
    "        print(f\"\\n  ç»¼åˆè¯„åˆ†:\")\n",
    "        print(f\"    å¬å›ç‡: {metrics['avg_overall_recall']:.2%}\")\n",
    "        print(f\"    ç²¾ç¡®ç‡: {metrics['avg_overall_precision']:.2%}\")\n",
    "        print(f\"    F1åˆ†æ•°: {metrics['avg_overall_f1']:.2%}\")\n",
    "        \n",
    "        print(f\"\\n{'='*80}\")\n",
    "        \n",
    "        # åˆ†æå¤±è´¥æ¡ˆä¾‹\n",
    "        failed_cases = [r for r in self.results if not r[\"execution_match\"]]\n",
    "        if failed_cases:\n",
    "            print(f\"\\nâŒ å¤±è´¥æ¡ˆä¾‹ ({len(failed_cases)} ä¸ª):\")\n",
    "            for i, case in enumerate(failed_cases[:5], 1):  # åªæ˜¾ç¤ºå‰5ä¸ª\n",
    "                print(f\"\\n  {i}. é—®é¢˜: {case['question']}\")\n",
    "                print(f\"     æœŸæœ›: {case['ground_truth_sql'][:80]}...\")\n",
    "                print(f\"     ç”Ÿæˆ: {case['generated_sql'][:80]}...\")\n",
    "                if case['error']:\n",
    "                    print(f\"     é”™è¯¯: {case['error'][:80]}...\")\n",
    "                # æ˜¾ç¤ºå¬å›æƒ…å†µ\n",
    "                rm = case['recall_metrics']\n",
    "                print(f\"     å¬å›: è¡¨{rm['table_recall']:.0%} | åˆ—{rm['column_recall']:.0%} | å…³é”®è¯{rm['keyword_recall']:.0%}\")\n",
    "    \n",
    "    def save_results(self, output_file: str):\n",
    "        \"\"\"ä¿å­˜è¯„ä¼°ç»“æœåˆ°JSONæ–‡ä»¶\"\"\"\n",
    "        output_data = {\n",
    "            \"metrics\": self._calculate_metrics(),\n",
    "            \"details\": self.results\n",
    "        }\n",
    "        \n",
    "        with open(output_file, 'w', encoding='utf-8') as f:\n",
    "            json.dump(output_data, f, ensure_ascii=False, indent=2)\n",
    "        \n",
    "        print(f\"\\nğŸ’¾ è¯„ä¼°ç»“æœå·²ä¿å­˜åˆ°: {output_file}\")\n",
    "\n",
    "\n",
    "def main():\n",
    "    \"\"\"ä¸»å‡½æ•°\"\"\"\n",
    "    \n",
    "    # é…ç½®\n",
    "    DB_PATH = \"90-æ–‡æ¡£-Data/tourism.db\"\n",
    "    DATASET_PATH = \"90-æ–‡æ¡£-Data/sakila/q2sql_pairs.json\"\n",
    "    API_KEY = \"sk-34b4f***05bb4f\"\n",
    "    OUTPUT_FILE = \"05-æ£€ç´¢å‰å¤„ç†-PreRetrieval/01-æŸ¥è¯¢æ„å»º/Text2SQL/evaluation_results.json\"\n",
    "    \n",
    "    # æ£€æŸ¥æ•°æ®åº“æ–‡ä»¶\n",
    "    if not os.path.exists(DB_PATH):\n",
    "        print(f\"âŒ æ•°æ®åº“æ–‡ä»¶ä¸å­˜åœ¨: {DB_PATH}\")\n",
    "        print(\"è¯·ç¡®ä¿ sakila.db æ–‡ä»¶å­˜åœ¨\")\n",
    "        return\n",
    "    \n",
    "    # åŠ è½½æ•°æ®é›†\n",
    "    print(f\"ğŸ“‚ åŠ è½½è¯„ä¼°æ•°æ®é›†: {DATASET_PATH}\")\n",
    "    with open(DATASET_PATH, 'r', encoding='utf-8') as f:\n",
    "        dataset = json.load(f)\n",
    "    \n",
    "    print(f\"âœ“ åŠ è½½äº† {len(dataset)} ä¸ªé—®ç­”å¯¹\")\n",
    "    \n",
    "    # åˆ›å»ºè¯„ä¼°å™¨\n",
    "    evaluator = Text2SQLEvaluator(DB_PATH, API_KEY)\n",
    "    \n",
    "    # è¿è¡Œè¯„ä¼°ï¼ˆå¯ä»¥è®¾ç½® max_samples æ¥é™åˆ¶è¯„ä¼°æ•°é‡ï¼ŒåŠ å¿«æµ‹è¯•ï¼‰\n",
    "    # å®Œæ•´è¯„ä¼°: metrics = evaluator.evaluate_dataset(dataset)\n",
    "    # å¿«é€Ÿæµ‹è¯•: metrics = evaluator.evaluate_dataset(dataset, max_samples=5)\n",
    "    \n",
    "    metrics = evaluator.evaluate_dataset(dataset, max_samples=10)  # å…ˆæµ‹è¯•10ä¸ªæ ·æœ¬\n",
    "    \n",
    "    # ä¿å­˜ç»“æœ\n",
    "    evaluator.save_results(OUTPUT_FILE)\n",
    "    \n",
    "    print(f\"\\nâœ… è¯„ä¼°å®Œæˆï¼\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
